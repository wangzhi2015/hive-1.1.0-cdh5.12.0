From d4ff8aba0ecfa48c393b01161d8e328f1d5aaf8b Mon Sep 17 00:00:00 2001
From: Xuefu Zhang <xzhang@Cloudera.com>
Date: Fri, 20 Nov 2015 11:49:38 -0800
Subject: [PATCH 0400/1164] CDH-34715: Undo CDH-26623 : Add new Hive config
 option to enable/disable running queries on Spark

Change-Id: Ibf3680c7164c0023c4c4f5994c7f2b5d7dfdbdd1
---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    1 -
 data/conf/spark/standalone/hive-site.xml           |    5 -----
 data/conf/spark/yarn-client/hive-site.xml          |    5 -----
 .../hadoop/hive/ql/exec/spark/SparkUtilities.java  |    4 ----
 4 files changed, 15 deletions(-)

diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 023688d..575e56b 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -2074,7 +2074,6 @@ public void setSparkConfigUpdated(boolean isSparkConfigUpdated) {
       "Channel logging level for remote Spark driver.  One of {DEBUG, ERROR, INFO, TRACE, WARN}."),
     SPARK_RPC_SASL_MECHANISM("hive.spark.client.rpc.sasl.mechanisms", "DIGEST-MD5",
       "Name of the SASL mechanism to use for authentication."),
-    SPARK_ENABLED("hive.enable.spark.execution.engine", false, "Whether Spark is allowed as an execution engine"),
     NWAYJOINREORDER("hive.reorder.nway.joins", true,
       "Runs reordering of tables within single n-way join (i.e.: picks streamtable)");
 
diff --git a/data/conf/spark/standalone/hive-site.xml b/data/conf/spark/standalone/hive-site.xml
index ca3ae94..016f568 100644
--- a/data/conf/spark/standalone/hive-site.xml
+++ b/data/conf/spark/standalone/hive-site.xml
@@ -230,9 +230,4 @@
   <value>hive_admin_user</value>
 </property>
 
-<property>
-  <name>hive.enable.spark.execution.engine</name>
-  <value>true</value>
-</property>
-
 </configuration>
diff --git a/data/conf/spark/yarn-client/hive-site.xml b/data/conf/spark/yarn-client/hive-site.xml
index 5765272..39ba20e 100644
--- a/data/conf/spark/yarn-client/hive-site.xml
+++ b/data/conf/spark/yarn-client/hive-site.xml
@@ -250,9 +250,4 @@
   <value>hive_admin_user</value>
 </property>
 
-<property>
-  <name>hive.enable.spark.execution.engine</name>
-  <value>true</value>
-</property>
-
 </configuration>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java
index f4dd5bc..974d457 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java
@@ -111,10 +111,6 @@ public static SparkSession getSparkSession(HiveConf conf,
       SparkSessionManager sparkSessionManager) throws HiveException {
     SparkSession sparkSession = SessionState.get().getSparkSession();
 
-    if (!conf.getBoolVar(HiveConf.ConfVars.SPARK_ENABLED)) {
-      throw new HiveException("Unsupported execution engine: Spark.  Please set hive.execution.engine=mr");
-    }
-
     // Spark configurations are updated close the existing session
     if (conf.getSparkConfigUpdated()) {
       sparkSessionManager.closeSession(sparkSession);
-- 
1.7.9.5

