From 14d8b195fd60bdea8c9cbc0d7b5139f24d057550 Mon Sep 17 00:00:00 2001
From: stakiar <stakiar@cloudera.com>
Date: Wed, 10 May 2017 12:52:54 -0700
Subject: [PATCH 1111/1164] CDH-53149: HIVE-11418: Dropping a database in an
 encryption zone with CASCADE and trash enabled
 fails (Sahil Takiar, reviewed by Sergio Pena)

(cherry picked from commit 5c018a5d98d634287d2d6d709f7d26676484c6e9)

Change-Id: I7ccaa94f1674fd0be408977f34c28a4b2fb73f46
---
 .../test/resources/testconfiguration.properties    |    3 +-
 .../hadoop/hive/metastore/HiveMetaStore.java       |   49 ------------------
 .../clientpositive/encryption_drop_partition.q     |    6 +--
 .../queries/clientpositive/encryption_drop_table.q |    5 +-
 .../encryption_drop_table_in_encrypted_db.q        |   20 ++++++++
 .../encrypted/encryption_drop_partition.q.out      |   33 +-----------
 .../encrypted/encryption_drop_table.q.out          |   17 ++-----
 .../encryption_drop_table_in_encrypted_db.q.out    |   53 ++++++++++++++++++++
 8 files changed, 82 insertions(+), 104 deletions(-)
 create mode 100644 ql/src/test/queries/clientpositive/encryption_drop_table_in_encrypted_db.q
 create mode 100644 ql/src/test/results/clientpositive/encrypted/encryption_drop_table_in_encrypted_db.q.out

diff --git a/itests/src/test/resources/testconfiguration.properties b/itests/src/test/resources/testconfiguration.properties
index 152d427..c0f2a21 100644
--- a/itests/src/test/resources/testconfiguration.properties
+++ b/itests/src/test/resources/testconfiguration.properties
@@ -329,7 +329,8 @@ encrypted.query.files=encryption_join_unencrypted_tbl.q,\
   encryption_insert_values.q,\
   encryption_drop_partition.q,\
   encryption_with_trash.q,\
-  encryption_ctas.q
+  encryption_ctas.q,\
+  encryption_drop_table_in_encrypted_db.q
 
 beeline.positive.include=drop_with_concurrency.q,\
   escape_comments.q,\
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 3a5ae3d..c09f1bf 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -1635,7 +1635,6 @@ private boolean drop_table_core(final RawStore ms, final String dbname, final St
           }
         }
 
-        checkTrashPurgeCombination(tblPath, dbname + "." + name, ifPurge, deleteData && !isExternal);
         // Drop the partitions and get a list of locations which need to be deleted
         partPaths = dropPartitionsAndGetLocations(ms, dbname, name, tblPath,
             tbl.getPartitionKeys(), deleteData && !isExternal);
@@ -1677,46 +1676,6 @@ private boolean drop_table_core(final RawStore ms, final String dbname, final St
     }
 
     /**
-     * Will throw MetaException if combination of trash policy/purge can't be satisfied
-     * @param pathToData path to data which may potentially be moved to trash
-     * @param objectName db.table, or db.table.part
-     * @param ifPurge if PURGE options is specified
-     */
-    private void checkTrashPurgeCombination(Path pathToData, String objectName, boolean ifPurge,
-        boolean deleteData) throws MetaException {
-      // There is no need to check TrashPurgeCombination in following cases since Purge/Trash
-      // is not applicable:
-      // a) deleteData is false -- drop an external table
-      // b) pathToData is null -- a view
-      // c) ifPurge is true -- force delete without Trash
-      if (!deleteData || pathToData == null || ifPurge) {
-        return;
-      }
-
-      boolean trashEnabled = false;
-      try {
-        trashEnabled = 0 < hiveConf.getFloat("fs.trash.interval", -1);
-      } catch(NumberFormatException ex) {
-	// nothing to do
-      }
-
-      if (trashEnabled) {
-        try {
-          HadoopShims.HdfsEncryptionShim shim =
-            ShimLoader.getHadoopShims().createHdfsEncryptionShim(pathToData.getFileSystem(hiveConf), hiveConf);
-          if (shim.isPathEncrypted(pathToData)) {
-            throw new MetaException("Unable to drop " + objectName + " because it is in an encryption zone" +
-              " and trash is enabled.  Use PURGE option to skip trash.");
-          }
-        } catch (IOException ex) {
-          MetaException e = new MetaException(ex.getMessage());
-          e.initCause(ex);
-          throw e;
-        }
-      }
-    }
-
-    /**
      * Deletes the data in a table's location, if it fails logs an error
      *
      * @param tablePath
@@ -2975,15 +2934,11 @@ private boolean drop_partition_common(RawStore ms, String db_name, String tbl_na
         if (isArchived) {
           archiveParentDir = MetaStoreUtils.getOriginalLocation(part);
           verifyIsWritablePath(archiveParentDir);
-          checkTrashPurgeCombination(archiveParentDir, db_name + "." + tbl_name + "." + part_vals,
-              mustPurge, deleteData && !isExternalTbl);
         }
 
         if ((part.getSd() != null) && (part.getSd().getLocation() != null)) {
           partPath = new Path(part.getSd().getLocation());
           verifyIsWritablePath(partPath);
-          checkTrashPurgeCombination(partPath, db_name + "." + tbl_name + "." + part_vals,
-              mustPurge, deleteData && !isExternalTbl);
         }
 
         if (!ms.dropPartition(db_name, tbl_name, part_vals)) {
@@ -3162,15 +3117,11 @@ public DropPartitionsResult drop_partitions_req(
           if (MetaStoreUtils.isArchived(part)) {
             Path archiveParentDir = MetaStoreUtils.getOriginalLocation(part);
             verifyIsWritablePath(archiveParentDir);
-            checkTrashPurgeCombination(archiveParentDir, dbName + "." + tblName + "." +
-                part.getValues(), mustPurge, deleteData && !isExternalTbl);
             archToDelete.add(archiveParentDir);
           }
           if ((part.getSd() != null) && (part.getSd().getLocation() != null)) {
             Path partPath = new Path(part.getSd().getLocation());
             verifyIsWritablePath(partPath);
-            checkTrashPurgeCombination(partPath, dbName + "." + tblName + "." + part.getValues(),
-                mustPurge, deleteData && !isExternalTbl);
             dirsToDelete.add(new PathAndPartValSize(partPath, part.getValues().size()));
           }
         }
diff --git a/ql/src/test/queries/clientpositive/encryption_drop_partition.q b/ql/src/test/queries/clientpositive/encryption_drop_partition.q
index f4a1d50..b7706e2 100644
--- a/ql/src/test/queries/clientpositive/encryption_drop_partition.q
+++ b/ql/src/test/queries/clientpositive/encryption_drop_partition.q
@@ -1,11 +1,10 @@
 -- SORT_QUERY_RESULTS;
 
--- we're setting this so that TestNegaiveCliDriver.vm doesn't stop processing after DROP TABLE fails;
+-- we're setting this so that TestNegativeCliDriver.vm doesn't stop processing after DROP TABLE fails;
 
 set hive.cli.errors.ignore=true;
 set hive.exec.dynamic.partition.mode=nonstrict;
 
-DROP TABLE IF EXISTS encrypted_table_dp PURGE;
 CREATE TABLE encrypted_table_dp (key INT, value STRING) partitioned by (p STRING) LOCATION '${hiveconf:hive.metastore.warehouse.dir}/default/encrypted_table_dp';
 CRYPTO CREATE_KEY --keyName key_128 --bitLength 128;
 CRYPTO CREATE_ZONE --keyName key_128 --path ${hiveconf:hive.metastore.warehouse.dir}/default/encrypted_table_dp;
@@ -23,8 +22,5 @@ DROP TABLE encrypted_ext_table_dp;
 SELECT * FROM encrypted_table_dp;
 ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23');
 SELECT * FROM encrypted_table_dp;
-ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23') PURGE;
-SELECT * FROM encrypted_table_dp;
 ALTER TABLE encrypted_table_dp ADD PARTITION (p='2014-09-23');
 SELECT * FROM encrypted_table_dp;
-DROP TABLE encrypted_table_dp PURGE;
diff --git a/ql/src/test/queries/clientpositive/encryption_drop_table.q b/ql/src/test/queries/clientpositive/encryption_drop_table.q
index 2ae3c69..b5716c3 100644
--- a/ql/src/test/queries/clientpositive/encryption_drop_table.q
+++ b/ql/src/test/queries/clientpositive/encryption_drop_table.q
@@ -4,7 +4,8 @@
 
 set hive.cli.errors.ignore=true;
 
-DROP TABLE IF EXISTS encrypted_table PURGE;
+DROP TABLE IF EXISTS encrypted_table;
+
 CREATE TABLE encrypted_table (key INT, value STRING) LOCATION '${hiveconf:hive.metastore.warehouse.dir}/default/encrypted_table';
 CRYPTO CREATE_KEY --keyName key_128 --bitLength 128;
 CRYPTO CREATE_ZONE --keyName key_128 --path ${hiveconf:hive.metastore.warehouse.dir}/default/encrypted_table;
@@ -20,6 +21,4 @@ SHOW TABLES;
 DROP TABLE default.encrypted_table;
 SHOW TABLES;
 
-DROP TABLE default.encrypted_table PURGE;
-SHOW TABLES;
 CRYPTO DELETE_KEY --keyName key_128;
diff --git a/ql/src/test/queries/clientpositive/encryption_drop_table_in_encrypted_db.q b/ql/src/test/queries/clientpositive/encryption_drop_table_in_encrypted_db.q
new file mode 100644
index 0000000..f6c48e3
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/encryption_drop_table_in_encrypted_db.q
@@ -0,0 +1,20 @@
+-- SORT_QUERY_RESULTS;
+
+set hive.cli.errors.ignore=true;
+
+DROP TABLE IF EXISTS encrypted_table;
+DROP DATABASE IF EXISTS encrypted_db;
+
+-- create database encrypted_db in its default warehouse location {hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db
+CREATE DATABASE encrypted_db LOCATION '${hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db';
+CRYPTO CREATE_KEY --keyName key_128 --bitLength 128;
+CRYPTO CREATE_ZONE --keyName key_128 --path ${hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db;
+
+CREATE TABLE encrypted_db.encrypted_table (key INT, value STRING) LOCATION '${hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db/encrypted_table';;
+
+INSERT OVERWRITE TABLE encrypted_db.encrypted_table SELECT * FROM src;
+
+DROP TABLE encrypted_db.encrypted_table;
+
+DROP DATABASE encrypted_db;
+CRYPTO DELETE_KEY --keyName key_128;
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_drop_partition.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_drop_partition.q.out
index 0985de3..38a284e 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_drop_partition.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_drop_partition.q.out
@@ -1,7 +1,3 @@
-PREHOOK: query: DROP TABLE IF EXISTS encrypted_table_dp PURGE
-PREHOOK: type: DROPTABLE
-POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table_dp PURGE
-POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
 #### A masked pattern was here ####
@@ -111,26 +107,7 @@ PREHOOK: query: ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23')
 PREHOOK: type: ALTERTABLE_DROPPARTS
 PREHOOK: Input: default@encrypted_table_dp
 PREHOOK: Output: default@encrypted_table_dp@p=2014-09-23
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Unable to drop default.encrypted_table_dp.[2014-09-23] because it is in an encryption zone and trash is enabled.  Use PURGE option to skip trash.
-PREHOOK: query: SELECT * FROM encrypted_table_dp
-PREHOOK: type: QUERY
-PREHOOK: Input: default@encrypted_table_dp
-PREHOOK: Input: default@encrypted_table_dp@p=2014-09-23
-PREHOOK: Input: default@encrypted_table_dp@p=2014-09-24
-#### A PARTIAL masked pattern was here #### data/warehouse/default/encrypted_table_dp/.hive-staging
-POSTHOOK: query: SELECT * FROM encrypted_table_dp
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@encrypted_table_dp
-POSTHOOK: Input: default@encrypted_table_dp@p=2014-09-23
-POSTHOOK: Input: default@encrypted_table_dp@p=2014-09-24
-#### A PARTIAL masked pattern was here #### data/warehouse/default/encrypted_table_dp/.hive-staging
-1	foo	2014-09-23
-2	bar	2014-09-24
-PREHOOK: query: ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23') PURGE
-PREHOOK: type: ALTERTABLE_DROPPARTS
-PREHOOK: Input: default@encrypted_table_dp
-PREHOOK: Output: default@encrypted_table_dp@p=2014-09-23
-POSTHOOK: query: ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23') PURGE
+POSTHOOK: query: ALTER TABLE encrypted_table_dp DROP PARTITION (p='2014-09-23')
 POSTHOOK: type: ALTERTABLE_DROPPARTS
 POSTHOOK: Input: default@encrypted_table_dp
 POSTHOOK: Output: default@encrypted_table_dp@p=2014-09-23
@@ -165,11 +142,3 @@ POSTHOOK: Input: default@encrypted_table_dp@p=2014-09-23
 POSTHOOK: Input: default@encrypted_table_dp@p=2014-09-24
 #### A PARTIAL masked pattern was here #### data/warehouse/default/encrypted_table_dp/.hive-staging
 2	bar	2014-09-24
-PREHOOK: query: DROP TABLE encrypted_table_dp PURGE
-PREHOOK: type: DROPTABLE
-PREHOOK: Input: default@encrypted_table_dp
-PREHOOK: Output: default@encrypted_table_dp
-POSTHOOK: query: DROP TABLE encrypted_table_dp PURGE
-POSTHOOK: type: DROPTABLE
-POSTHOOK: Input: default@encrypted_table_dp
-POSTHOOK: Output: default@encrypted_table_dp
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_drop_table.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_drop_table.q.out
index 8248abd..4753e20 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_drop_table.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_drop_table.q.out
@@ -1,6 +1,6 @@
-PREHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
+PREHOOK: query: DROP TABLE IF EXISTS encrypted_table
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
+POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -59,18 +59,7 @@ PREHOOK: query: DROP TABLE default.encrypted_table
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@encrypted_table
 PREHOOK: Output: default@encrypted_table
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:Unable to drop default.encrypted_table because it is in an encryption zone and trash is enabled.  Use PURGE option to skip trash.)
-PREHOOK: query: SHOW TABLES
-PREHOOK: type: SHOWTABLES
-POSTHOOK: query: SHOW TABLES
-POSTHOOK: type: SHOWTABLES
-encrypted_table
-src
-PREHOOK: query: DROP TABLE default.encrypted_table PURGE
-PREHOOK: type: DROPTABLE
-PREHOOK: Input: default@encrypted_table
-PREHOOK: Output: default@encrypted_table
-POSTHOOK: query: DROP TABLE default.encrypted_table PURGE
+POSTHOOK: query: DROP TABLE default.encrypted_table
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@encrypted_table
 POSTHOOK: Output: default@encrypted_table
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_drop_table_in_encrypted_db.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_drop_table_in_encrypted_db.q.out
new file mode 100644
index 0000000..1287d01
--- /dev/null
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_drop_table_in_encrypted_db.q.out
@@ -0,0 +1,53 @@
+PREHOOK: query: DROP TABLE IF EXISTS encrypted_table
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: DROP DATABASE IF EXISTS encrypted_db
+PREHOOK: type: DROPDATABASE
+POSTHOOK: query: DROP DATABASE IF EXISTS encrypted_db
+POSTHOOK: type: DROPDATABASE
+#### A masked pattern was here ####
+PREHOOK: type: CREATEDATABASE
+PREHOOK: Output: database:encrypted_db
+#### A masked pattern was here ####
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Output: database:encrypted_db
+#### A masked pattern was here ####
+Encryption key created: 'key_128'
+Encryption zone created: '/build/ql/test/data/warehouse/encrypted_db.db' using key: 'key_128'
+#### A masked pattern was here ####
+PREHOOK: type: CREATETABLE
+#### A masked pattern was here ####
+PREHOOK: Output: database:encrypted_db
+PREHOOK: Output: encrypted_db@encrypted_table
+#### A masked pattern was here ####
+POSTHOOK: type: CREATETABLE
+#### A masked pattern was here ####
+POSTHOOK: Output: database:encrypted_db
+POSTHOOK: Output: encrypted_db@encrypted_table
+PREHOOK: query: INSERT OVERWRITE TABLE encrypted_db.encrypted_table SELECT * FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: encrypted_db@encrypted_table
+POSTHOOK: query: INSERT OVERWRITE TABLE encrypted_db.encrypted_table SELECT * FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: encrypted_db@encrypted_table
+POSTHOOK: Lineage: encrypted_table.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: encrypted_table.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: DROP TABLE encrypted_db.encrypted_table
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: encrypted_db@encrypted_table
+PREHOOK: Output: encrypted_db@encrypted_table
+POSTHOOK: query: DROP TABLE encrypted_db.encrypted_table
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: encrypted_db@encrypted_table
+POSTHOOK: Output: encrypted_db@encrypted_table
+PREHOOK: query: DROP DATABASE encrypted_db
+PREHOOK: type: DROPDATABASE
+PREHOOK: Input: database:encrypted_db
+PREHOOK: Output: database:encrypted_db
+POSTHOOK: query: DROP DATABASE encrypted_db
+POSTHOOK: type: DROPDATABASE
+POSTHOOK: Input: database:encrypted_db
+POSTHOOK: Output: database:encrypted_db
-- 
1.7.9.5

