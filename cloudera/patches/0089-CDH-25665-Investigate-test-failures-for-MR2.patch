From f51f5015e5f7fe9aef2f3f3ad91c43ef88188d06 Mon Sep 17 00:00:00 2001
From: Chao Sun <sunchao.chris@gmail.com>
Date: Thu, 12 Mar 2015 21:41:31 -0700
Subject: [PATCH 0089/1164] CDH-25665 - Investigate test failures for MR2

---
 itests/pom.xml                                     |    4 +-
 pom.xml                                            |    2 +-
 .../clientpositive/spark/cbo_gby_empty.q.out       |   77 ++++++++++++++++++++
 3 files changed, 80 insertions(+), 3 deletions(-)
 create mode 100644 ql/src/test/results/clientpositive/spark/cbo_gby_empty.q.out

diff --git a/itests/pom.xml b/itests/pom.xml
index 709e9b2..3a61fd1 100644
--- a/itests/pom.xml
+++ b/itests/pom.xml
@@ -88,10 +88,10 @@
                      curl -Sso $DOWNLOAD_DIR/$tarName $url
                     fi
                     tar -zxf $DOWNLOAD_DIR/$tarName -C $BASE_DIR
-                    mv $BASE_DIR/spark-1.3.0-bin-hadoop2-without-hive $BASE_DIR/$finalName
+                    mv $BASE_DIR/spark-${spark.version}-bin-hadoop2-without-hive $BASE_DIR/$finalName
                   }
                   mkdir -p $DOWNLOAD_DIR
-                  download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.3.0-bin-hadoop2-without-hive.tgz" "spark"
+                  download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-${spark.version}-bin-hadoop2-without-hive.tgz" "spark"
                   cp -f $HIVE_ROOT/data/conf/spark/log4j.properties $BASE_DIR/spark/conf/
                 </echo>
               </target>
diff --git a/pom.xml b/pom.xml
index 9c3bb48..190c658 100644
--- a/pom.xml
+++ b/pom.xml
@@ -855,7 +855,7 @@
             <LANG>en_US.UTF-8</LANG>
             <HADOOP_CLASSPATH>${test.tmp.dir}/conf:${basedir}/${hive.path.to.root}/conf</HADOOP_CLASSPATH>
             <HIVE_HADOOP_TEST_CLASSPATH>${test.hive.hadoop.classpath}</HIVE_HADOOP_TEST_CLASSPATH>
-            <SPARK_SUBMIT_CLASSPATH>${spark.home}/lib/spark-assembly-1.2.0-hadoop2.4.0.jar:${test.hive.hadoop.classpath}</SPARK_SUBMIT_CLASSPATH>
+            <SPARK_SUBMIT_CLASSPATH>${spark.home}/lib/spark-assembly-${spark.version}-hadoop2.4.0.jar:${test.hive.hadoop.classpath}</SPARK_SUBMIT_CLASSPATH>
             <SPARK_OSX_TEST_OPTS>-Dorg.xerial.snappy.tempdir=/tmp -Dorg.xerial.snappy.lib.name=libsnappyjava.jnilib</SPARK_OSX_TEST_OPTS>
             <PATH>${env.PATH}${test.extra.path}</PATH>
           </environmentVariables>
diff --git a/ql/src/test/results/clientpositive/spark/cbo_gby_empty.q.out b/ql/src/test/results/clientpositive/spark/cbo_gby_empty.q.out
new file mode 100644
index 0000000..68f0255
--- /dev/null
+++ b/ql/src/test/results/clientpositive/spark/cbo_gby_empty.q.out
@@ -0,0 +1,77 @@
+PREHOOK: query: -- 21. Test groupby is empty and there is no other cols in aggr
+select unionsrc.key FROM (select 'tst1' as key, count(1) as value from src) unionsrc
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: -- 21. Test groupby is empty and there is no other cols in aggr
+select unionsrc.key FROM (select 'tst1' as key, count(1) as value from src) unionsrc
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+tst1
+PREHOOK: query: select unionsrc.key, unionsrc.value FROM (select 'tst1' as key, count(1) as value from src) unionsrc
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select unionsrc.key, unionsrc.value FROM (select 'tst1' as key, count(1) as value from src) unionsrc
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+tst1	500
+PREHOOK: query: select unionsrc.key FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+	UNION  ALL
+    	select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc order by unionsrc.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+POSTHOOK: query: select unionsrc.key FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+	UNION  ALL
+    	select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc order by unionsrc.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+avg
+max
+min
+PREHOOK: query: select unionsrc.key, unionsrc.value FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+	UNION  ALL
+    	select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc order by unionsrc.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+POSTHOOK: query: select unionsrc.key, unionsrc.value FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+	UNION  ALL
+    	select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc order by unionsrc.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+avg	1.5
+max	3.0
+min	1.0
+PREHOOK: query: select unionsrc.key, count(1) FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+    UNION  ALL
+        select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc group by unionsrc.key order by unionsrc.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+POSTHOOK: query: select unionsrc.key, count(1) FROM (select 'max' as key, max(c_int) as value from cbo_t3 s1
+    UNION  ALL
+        select 'min' as key,  min(c_int) as value from cbo_t3 s2
+    UNION ALL
+        select 'avg' as key,  avg(c_int) as value from cbo_t3 s3) unionsrc group by unionsrc.key order by unionsrc.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@cbo_t3
+#### A masked pattern was here ####
+avg	1
+max	1
+min	1
-- 
1.7.9.5

