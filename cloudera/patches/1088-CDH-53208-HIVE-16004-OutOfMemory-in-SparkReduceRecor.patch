From bedee97f2c37e9dee0f93c0316452ca016a26d2e Mon Sep 17 00:00:00 2001
From: Ferdinand Xu <cheng.a.xu@intel.com>
Date: Fri, 24 Feb 2017 02:41:19 +0800
Subject: [PATCH 1088/1164] CDH-53208 HIVE-16004: OutOfMemory in
 SparkReduceRecordHandler with vectorization mode
 (Colin Ma, reviewed by Ferdinand Xu, Xuefu Zhang)

Change-Id: I35487bf963b588da7095d7c25bfe8484b6d458f6
---
 .../ql/exec/spark/SparkReduceRecordHandler.java    |    1 +
 1 file changed, 1 insertion(+)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java
index 9f375f0..b7e79d6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java
@@ -353,6 +353,7 @@ public void processRow(Object key, Object value) throws IOException {
   private <E> boolean processVectors(Iterator<E> values, byte tag) throws HiveException {
     VectorizedRowBatch batch = batches[tag];
     batch.reset();
+    buffer.reset();
 
     /* deserialize key into columns */
     VectorizedBatchUtil.addRowToBatchFrom(keyObject, keyStructInspector, 0, 0, batch, buffer);
-- 
1.7.9.5

