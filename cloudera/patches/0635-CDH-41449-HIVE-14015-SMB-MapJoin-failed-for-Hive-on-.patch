From 68fcdb8e9b7719e0863c3de56865d96f3b80a1f3 Mon Sep 17 00:00:00 2001
From: Yongzhi Chen <ychena@apache.org>
Date: Wed, 15 Jun 2016 10:07:48 -0400
Subject: [PATCH 0635/1164] CDH-41449 HIVE-14015: SMB MapJoin failed for Hive
 on Spark when kerberized (Yongzhi Chen, reviewed
 by Chaoyu Tang)

Change-Id: I6da8512011952aa469c000c91f1f1aaa5fcb2d65
---
 .../hadoop/hive/ql/exec/SMBMapJoinOperator.java    |    7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
index 8073cb4..5611c5a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
@@ -48,6 +48,7 @@
 import org.apache.hadoop.io.WritableComparable;
 import org.apache.hadoop.io.WritableComparator;
 import org.apache.hadoop.mapred.JobConf;
+import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hadoop.util.PriorityQueue;
 import org.apache.hadoop.util.ReflectionUtils;
 
@@ -188,6 +189,12 @@ public void initializeMapredLocalWork(MapJoinDesc mjConf, Configuration hconf,
       FetchWork fetchWork = entry.getValue();
 
       JobConf jobClone = new JobConf(hconf);
+      if (UserGroupInformation.isSecurityEnabled()) {
+        String hadoopAuthToken = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);
+        if(hadoopAuthToken != null){
+          jobClone.set("mapreduce.job.credentials.binary", hadoopAuthToken);
+        }
+      }
 
       TableScanOperator ts = (TableScanOperator)aliasToWork.get(alias);
       // push down projections
-- 
1.7.9.5

