From 593d87a94fff8bbec2c07a9b0e395bee0ef74d31 Mon Sep 17 00:00:00 2001
From: Rui Li <rui.li@intel.com>
Date: Thu, 2 Jun 2016 11:17:00 +0800
Subject: [PATCH 0871/1164] CDH-44336 HIVE-13895: HoS start-up overhead in
 yarn-client mode (Rui reviewed by Xuefu and
 Szehon)

(cherry picked from commit 442a1d728f3293d09c35a75a848bbd6d5c170adb)

Change-Id: Ib65941869ff13bb4c0f4b8335929015e722d99e8
---
 .../hive/ql/exec/spark/HiveSparkClientFactory.java |   11 ++++-------
 1 file changed, 4 insertions(+), 7 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
index 501d833..f173719 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
@@ -54,7 +54,7 @@
   private static final String SPARK_DEFAULT_APP_NAME = "Hive on Spark";
   private static final String SPARK_DEFAULT_SERIALIZER = "org.apache.spark.serializer.KryoSerializer";
   private static final String SPARK_DEFAULT_REFERENCE_TRACKING = "false";
-  private static final String SPARK_YARN_REPORT_INTERVAL = "spark.yarn.report.interval";
+  private static final String SPARK_WAIT_APP_COMPLETE = "spark.yarn.submit.waitAppCompletion";
 
   public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Exception {
     Map<String, String> sparkConf = initiateSparkConf(hiveconf);
@@ -189,12 +189,9 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
       }
     }
 
-    //The application reports tend to spam the hive logs.  This is controlled by spark, and the default seems to be 1s.
-    //If it is not specified, set it to a much higher number.  It can always be overriden by user.
-    String sparkYarnReportInterval = sparkConf.get(SPARK_YARN_REPORT_INTERVAL);
-    if (sparkMaster.startsWith("yarn") && sparkYarnReportInterval == null) {
-      //the new version of spark also takes time-units, but old versions do not.
-      sparkConf.put(SPARK_YARN_REPORT_INTERVAL, "60000");
+    // Disable it to avoid verbose app state report in yarn-cluster mode
+    if (sparkMaster.equals("yarn-cluster") && sparkConf.get(SPARK_WAIT_APP_COMPLETE) == null) {
+      sparkConf.put(SPARK_WAIT_APP_COMPLETE, "false");
     }
 
     // Set the credential provider passwords if found, if there is job specific password
-- 
1.7.9.5

