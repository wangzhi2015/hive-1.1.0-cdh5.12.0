From e15dc09a936e26f54c88a4ea2efc43f38b34012a Mon Sep 17 00:00:00 2001
From: Peter Vary <pvary@cloudera.com>
Date: Tue, 23 May 2017 17:12:11 +0200
Subject: [PATCH 1144/1164] CLOUDERA-BUILD: CDH-54123 Parallel Order By from
 Parquet wrong Output file number                
 Partial backport of HIVE-10975 Parquet: Bump the
 parquet version up to 1.8.1

Change-Id: Idb53bf4bdd2796b22353d489f4592c5895579d0c
---
 .../io/parquet/read/DataWritableReadSupport.java   |   10 +++++++---
 1 file changed, 7 insertions(+), 3 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java b/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java
index 6735b83..cf2f56d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java
@@ -247,9 +247,13 @@ public ReadContext init(final Configuration configuration, final Map<String, Str
       this.hiveTypeInfo = TypeInfoFactory.getStructTypeInfo(columnNamesList, columnTypesList);
 
       List<Integer> indexColumnsWanted = ColumnProjectionUtils.getReadColumnIDs(configuration);
-      MessageType requestedSchemaByUser = getSchemaByIndex(tableSchema, columnNamesList, indexColumnsWanted);
-
-      return new ReadContext(requestedSchemaByUser, contextMetadata);
+      if (!ColumnProjectionUtils.isReadAllColumns(configuration) && !indexColumnsWanted.isEmpty()) {
+        MessageType requestedSchemaByUser =
+            getSchemaByIndex(tableSchema, columnNamesList, indexColumnsWanted);
+        return new ReadContext(requestedSchemaByUser, contextMetadata);
+      } else {
+        return new ReadContext(tableSchema, contextMetadata);
+      }
     } else {
       contextMetadata.put(HIVE_TABLE_AS_PARQUET_SCHEMA, fileSchema.toString());
       return new ReadContext(fileSchema, contextMetadata);
-- 
1.7.9.5

