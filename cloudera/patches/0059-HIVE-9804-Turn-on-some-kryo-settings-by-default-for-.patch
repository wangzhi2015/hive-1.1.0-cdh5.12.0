From e509fb23f2f9dfaffd84909ae71cf9f718d971b2 Mon Sep 17 00:00:00 2001
From: sunchao <sunchao@unknown>
Date: Sat, 28 Feb 2015 00:18:39 +0000
Subject: [PATCH 0059/1164] HIVE-9804 - Turn on some kryo settings by default
 for Spark [Spark Branch] (Jimmy via Chao)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1662861 13f79535-47bb-0310-9956-ffa450edef68
---
 .../hive/ql/exec/spark/HiveSparkClientFactory.java |   23 +++++++++++++++++---
 1 file changed, 20 insertions(+), 3 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
index a0938a0..400fea5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
@@ -21,21 +21,27 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
-import java.util.Arrays;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.Properties;
-import java.util.concurrent.TimeUnit;
+import java.util.Set;
 
 import org.apache.commons.compress.utils.CharsetNames;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;
+import org.apache.hadoop.hive.ql.io.HiveKey;
+import org.apache.hadoop.io.BytesWritable;
 import org.apache.hive.spark.client.rpc.RpcConfiguration;
 import org.apache.spark.SparkConf;
 import org.apache.spark.SparkException;
 
+import com.google.common.base.Joiner;
+import com.google.common.base.Splitter;
+import com.google.common.base.Strings;
+import com.google.common.collect.Sets;
+
 public class HiveSparkClientFactory {
   protected static final transient Log LOG = LogFactory.getLog(HiveSparkClientFactory.class);
 
@@ -43,6 +49,7 @@
   private static final String SPARK_DEFAULT_MASTER = "local";
   private static final String SPARK_DEFAULT_APP_NAME = "Hive on Spark";
   private static final String SPARK_DEFAULT_SERIALIZER = "org.apache.spark.serializer.KryoSerializer";
+  private static final String SPARK_DEFAULT_REFERENCE_TRACKING = "false";
 
   public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf)
     throws IOException, SparkException {
@@ -66,6 +73,7 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf)
     sparkConf.put("spark.master", SPARK_DEFAULT_MASTER);
     sparkConf.put("spark.app.name", SPARK_DEFAULT_APP_NAME);
     sparkConf.put("spark.serializer", SPARK_DEFAULT_SERIALIZER);
+    sparkConf.put("spark.kryo.referenceTracking", SPARK_DEFAULT_REFERENCE_TRACKING);
 
     // load properties from spark-defaults.conf.
     InputStream inputStream = null;
@@ -133,6 +141,15 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf)
       }
     }
 
+    Set<String> classes = Sets.newHashSet(
+      Splitter.on(",").trimResults().omitEmptyStrings().split(
+        Strings.nullToEmpty(sparkConf.get("spark.kryo.classesToRegister"))));
+    classes.add(VectorizedRowBatch.class.getName());
+    classes.add(BytesWritable.class.getName());
+    classes.add(HiveKey.class.getName());
+    sparkConf.put(
+      "spark.kryo.classesToRegister", Joiner.on(",").join(classes));
+
     return sparkConf;
   }
 
-- 
1.7.9.5

