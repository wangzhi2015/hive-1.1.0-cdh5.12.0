From 046cf01503aa30aa1a90acd0fcda6ad155139806 Mon Sep 17 00:00:00 2001
From: Barna Zsombor Klara <zsombor.klara@cloudera.com>
Date: Mon, 7 Nov 2016 20:33:27 +0800
Subject: [PATCH 0861/1164] HIVE-14910: Flaky test:
 TestSparkClient.testJobSubmission (Barna Zsombor
 Klara, reviewed by Xuefu, via Rui)

Change-Id: I78618d00c9a011473fb80ceb3194a1af4b5b6ced
---
 .../org/apache/hive/spark/client/JobHandle.java    |    8 --
 .../apache/hive/spark/client/JobHandleImpl.java    |   80 ++++++++++----------
 .../org/apache/hive/spark/client/SparkClient.java  |   10 +++
 .../apache/hive/spark/client/SparkClientImpl.java  |   13 +++-
 .../apache/hive/spark/client/TestJobHandle.java    |   18 ++---
 .../apache/hive/spark/client/TestSparkClient.java  |   18 +++--
 6 files changed, 80 insertions(+), 67 deletions(-)

diff --git a/spark-client/src/main/java/org/apache/hive/spark/client/JobHandle.java b/spark-client/src/main/java/org/apache/hive/spark/client/JobHandle.java
index 44aa255..c02c403 100644
--- a/spark-client/src/main/java/org/apache/hive/spark/client/JobHandle.java
+++ b/spark-client/src/main/java/org/apache/hive/spark/client/JobHandle.java
@@ -61,14 +61,6 @@
   State getState();
 
   /**
-   * Add a listener to the job handle. If the job's state is not SENT, a callback for the
-   * corresponding state will be invoked immediately.
-   *
-   * @param l The listener to add.
-   */
-  void addListener(Listener<T> l);
-
-  /**
    * The current state of the submitted job.
    */
   static enum State {
diff --git a/spark-client/src/main/java/org/apache/hive/spark/client/JobHandleImpl.java b/spark-client/src/main/java/org/apache/hive/spark/client/JobHandleImpl.java
index 17c8f40..7645702 100644
--- a/spark-client/src/main/java/org/apache/hive/spark/client/JobHandleImpl.java
+++ b/spark-client/src/main/java/org/apache/hive/spark/client/JobHandleImpl.java
@@ -24,8 +24,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
-import com.google.common.base.Throwables;
-import com.google.common.collect.Lists;
+import com.google.common.collect.ImmutableList;
 import io.netty.util.concurrent.Promise;
 
 import org.apache.hive.spark.counter.SparkCounters;
@@ -40,19 +39,26 @@
   private final MetricsCollection metrics;
   private final Promise<T> promise;
   private final List<Integer> sparkJobIds;
-  private final List<Listener> listeners;
+  private final List<Listener<T>> listeners;
   private volatile State state;
   private volatile SparkCounters sparkCounters;
 
-  JobHandleImpl(SparkClientImpl client, Promise<T> promise, String jobId) {
+  JobHandleImpl(SparkClientImpl client, Promise<T> promise, String jobId,
+                    List<Listener<T>> listeners) {
     this.client = client;
     this.jobId = jobId;
     this.promise = promise;
-    this.listeners = Lists.newLinkedList();
+    this.listeners = ImmutableList.copyOf(listeners);
     this.metrics = new MetricsCollection();
     this.sparkJobIds = new CopyOnWriteArrayList<Integer>();
     this.state = State.SENT;
     this.sparkCounters = null;
+
+    synchronized (this.listeners) {
+      for (Listener<T> listener : this.listeners) {
+        initializeListener(listener);
+      }
+    }
   }
 
   /** Requests a running job to be cancelled. */
@@ -122,29 +128,6 @@ public State getState() {
     return state;
   }
 
-  @Override
-  public void addListener(Listener l) {
-    synchronized (listeners) {
-      listeners.add(l);
-      // If current state is a final state, notify of Spark job IDs before notifying about the
-      // state transition.
-      if (state.ordinal() >= State.CANCELLED.ordinal()) {
-        for (Integer i : sparkJobIds) {
-          l.onSparkJobStarted(this, i);
-        }
-      }
-
-      fireStateChange(state, l);
-
-      // Otherwise, notify about Spark jobs after the state notification.
-      if (state.ordinal() < State.CANCELLED.ordinal()) {
-        for (Integer i : sparkJobIds) {
-          l.onSparkJobStarted(this, i);
-        }
-      }
-    }
-  }
-
   public void setSparkCounters(SparkCounters sparkCounters) {
     this.sparkCounters = sparkCounters;
   }
@@ -179,8 +162,8 @@ boolean changeState(State newState) {
     synchronized (listeners) {
       if (newState.ordinal() > state.ordinal() && state.ordinal() < State.CANCELLED.ordinal()) {
         state = newState;
-        for (Listener l : listeners) {
-          fireStateChange(newState, l);
+        for (Listener<T> listener : listeners) {
+          fireStateChange(newState, listener);
         }
         return true;
       }
@@ -191,31 +174,50 @@ boolean changeState(State newState) {
   void addSparkJobId(int sparkJobId) {
     synchronized (listeners) {
       sparkJobIds.add(sparkJobId);
-      for (Listener l : listeners) {
-        l.onSparkJobStarted(this, sparkJobId);
+      for (Listener<T> listener : listeners) {
+        listener.onSparkJobStarted(this, sparkJobId);
+      }
+    }
+  }
+
+  private void initializeListener(Listener<T> listener) {
+    // If current state is a final state, notify of Spark job IDs before notifying about the
+    // state transition.
+    if (state.ordinal() >= State.CANCELLED.ordinal()) {
+      for (Integer id : sparkJobIds) {
+        listener.onSparkJobStarted(this, id);
+      }
+    }
+
+    fireStateChange(state, listener);
+
+    // Otherwise, notify about Spark jobs after the state notification.
+    if (state.ordinal() < State.CANCELLED.ordinal()) {
+      for (Integer id : sparkJobIds) {
+        listener.onSparkJobStarted(this, id);
       }
     }
   }
 
-  private void fireStateChange(State s, Listener l) {
-    switch (s) {
+  private void fireStateChange(State newState, Listener<T> listener) {
+    switch (newState) {
     case SENT:
       break;
     case QUEUED:
-      l.onJobQueued(this);
+      listener.onJobQueued(this);
       break;
     case STARTED:
-      l.onJobStarted(this);
+      listener.onJobStarted(this);
       break;
     case CANCELLED:
-      l.onJobCancelled(this);
+      listener.onJobCancelled(this);
       break;
     case FAILED:
-      l.onJobFailed(this, promise.cause());
+      listener.onJobFailed(this, promise.cause());
       break;
     case SUCCEEDED:
       try {
-        l.onJobSucceeded(this, promise.get());
+        listener.onJobSucceeded(this, promise.get());
       } catch (Exception e) {
         // Shouldn't really happen.
         throw new IllegalStateException(e);
diff --git a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClient.java b/spark-client/src/main/java/org/apache/hive/spark/client/SparkClient.java
index 3e921a5..e952f27 100644
--- a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClient.java
+++ b/spark-client/src/main/java/org/apache/hive/spark/client/SparkClient.java
@@ -19,6 +19,7 @@
 
 import java.io.Serializable;
 import java.net.URI;
+import java.util.List;
 import java.util.concurrent.Future;
 
 import org.apache.hadoop.hive.common.classification.InterfaceAudience;
@@ -38,6 +39,15 @@
   <T extends Serializable> JobHandle<T> submit(Job<T> job);
 
   /**
+   * Submits a job for asynchronous execution.
+   *
+   * @param job The job to execute.
+   * @param listeners jobhandle listeners to invoke during the job processing
+   * @return A handle that be used to monitor the job.
+   */
+  <T extends Serializable> JobHandle<T> submit(Job<T> job, List<JobHandle.Listener<T>> listeners);
+
+  /**
    * Asks the remote context to run a job immediately.
    * <p/>
    * Normally, the remote context will queue jobs and execute them based on how many worker
diff --git a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java b/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java
index f3c401e..56a3ae4 100644
--- a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java
+++ b/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java
@@ -45,6 +45,7 @@
 import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
@@ -137,7 +138,12 @@ public void rpcClosed(Rpc rpc) {
 
   @Override
   public <T extends Serializable> JobHandle<T> submit(Job<T> job) {
-    return protocol.submit(job);
+    return protocol.submit(job, Collections.<JobHandle.Listener<T>>emptyList());
+  }
+
+  @Override
+  public <T extends Serializable> JobHandle<T> submit(Job<T> job, List<JobHandle.Listener<T>> listeners) {
+    return protocol.submit(job, listeners);
   }
 
   @Override
@@ -510,10 +516,11 @@ private void redirect(String name, Redirector redirector) {
 
   private class ClientProtocol extends BaseProtocol {
 
-    <T extends Serializable> JobHandleImpl<T> submit(Job<T> job) {
+    <T extends Serializable> JobHandleImpl<T> submit(Job<T> job, List<JobHandle.Listener<T>> listeners) {
       final String jobId = UUID.randomUUID().toString();
       final Promise<T> promise = driverRpc.createPromise();
-      final JobHandleImpl<T> handle = new JobHandleImpl<T>(SparkClientImpl.this, promise, jobId);
+      final JobHandleImpl<T> handle =
+          new JobHandleImpl<T>(SparkClientImpl.this, promise, jobId, listeners);
       jobs.put(jobId, handle);
 
       final io.netty.util.concurrent.Future<Void> rpc = driverRpc.call(new JobRequest(jobId, job));
diff --git a/spark-client/src/test/java/org/apache/hive/spark/client/TestJobHandle.java b/spark-client/src/test/java/org/apache/hive/spark/client/TestJobHandle.java
index e8f352d..d6b627b 100644
--- a/spark-client/src/test/java/org/apache/hive/spark/client/TestJobHandle.java
+++ b/spark-client/src/test/java/org/apache/hive/spark/client/TestJobHandle.java
@@ -19,6 +19,7 @@
 
 import java.io.Serializable;
 
+import com.google.common.collect.Lists;
 import io.netty.util.concurrent.Promise;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -38,8 +39,8 @@
 
   @Test
   public void testStateChanges() throws Exception {
-    JobHandleImpl<Serializable> handle = new JobHandleImpl<Serializable>(client, promise, "job");
-    handle.addListener(listener);
+    JobHandleImpl<Serializable> handle =
+        new JobHandleImpl<Serializable>(client, promise, "job", Lists.newArrayList(listener));
 
     assertTrue(handle.changeState(JobHandle.State.QUEUED));
     verify(listener).onJobQueued(handle);
@@ -60,8 +61,8 @@ public void testStateChanges() throws Exception {
 
   @Test
   public void testFailedJob() throws Exception {
-    JobHandleImpl<Serializable> handle = new JobHandleImpl<Serializable>(client, promise, "job");
-    handle.addListener(listener);
+    JobHandleImpl<Serializable> handle =
+        new JobHandleImpl<Serializable>(client, promise, "job", Lists.newArrayList(listener));
 
     Throwable cause = new Exception();
     when(promise.cause()).thenReturn(cause);
@@ -73,8 +74,8 @@ public void testFailedJob() throws Exception {
 
   @Test
   public void testSucceededJob() throws Exception {
-    JobHandleImpl<Serializable> handle = new JobHandleImpl<Serializable>(client, promise, "job");
-    handle.addListener(listener);
+    JobHandleImpl<Serializable> handle =
+        new JobHandleImpl<Serializable>(client, promise, "job", Lists.newArrayList(listener));
 
     Serializable result = new Exception();
     when(promise.get()).thenReturn(result);
@@ -86,16 +87,15 @@ public void testSucceededJob() throws Exception {
 
   @Test
   public void testImmediateCallback() throws Exception {
-    JobHandleImpl<Serializable> handle = new JobHandleImpl<Serializable>(client, promise, "job");
+    JobHandleImpl<Serializable> handle =
+        new JobHandleImpl<Serializable>(client, promise, "job", Lists.newArrayList(listener, listener2));
     assertTrue(handle.changeState(JobHandle.State.QUEUED));
-    handle.addListener(listener);
     verify(listener).onJobQueued(handle);
 
     handle.changeState(JobHandle.State.STARTED);
     handle.addSparkJobId(1);
     handle.changeState(JobHandle.State.CANCELLED);
 
-    handle.addListener(listener2);
     InOrder inOrder = inOrder(listener2);
     inOrder.verify(listener2).onSparkJobStarted(same(handle), eq(1));
     inOrder.verify(listener2).onJobCancelled(same(handle));
diff --git a/spark-client/src/test/java/org/apache/hive/spark/client/TestSparkClient.java b/spark-client/src/test/java/org/apache/hive/spark/client/TestSparkClient.java
index 0020c20..344579c 100644
--- a/spark-client/src/test/java/org/apache/hive/spark/client/TestSparkClient.java
+++ b/spark-client/src/test/java/org/apache/hive/spark/client/TestSparkClient.java
@@ -17,6 +17,7 @@
 
 package org.apache.hive.spark.client;
 
+import com.google.common.collect.Lists;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
@@ -25,6 +26,7 @@
 import java.net.URI;
 import java.util.Arrays;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
@@ -80,8 +82,8 @@ public void testJobSubmission() throws Exception {
       @Override
       public void call(SparkClient client) throws Exception {
         JobHandle.Listener<String> listener = newListener();
-        JobHandle<String> handle = client.submit(new SimpleJob());
-        handle.addListener(listener);
+        List<JobHandle.Listener<String>> listeners = Lists.newArrayList(listener);;
+        JobHandle<String> handle = client.submit(new SimpleJob(), listeners);
         assertEquals("hello", handle.get(TIMEOUT, TimeUnit.SECONDS));
 
         // Try an invalid state transition on the handle. This ensures that the actual state
@@ -113,8 +115,8 @@ public void testErrorJob() throws Exception {
       @Override
       public void call(SparkClient client) throws Exception {
         JobHandle.Listener<String> listener = newListener();
-        JobHandle<String> handle = client.submit(new ErrorJob());
-        handle.addListener(listener);
+        List<JobHandle.Listener<String>> listeners = Lists.newArrayList(listener);
+        JobHandle<String> handle = client.submit(new ErrorJob(), listeners);
         try {
           handle.get(TIMEOUT, TimeUnit.SECONDS);
           fail("Should have thrown an exception.");
@@ -163,8 +165,8 @@ public void testMetricsCollection() throws Exception {
       @Override
       public void call(SparkClient client) throws Exception {
         JobHandle.Listener<Integer> listener = newListener();
-        JobHandle<Integer> future = client.submit(new AsyncSparkJob());
-        future.addListener(listener);
+        List<JobHandle.Listener<Integer>> listeners = Lists.newArrayList(listener);
+        JobHandle<Integer> future = client.submit(new AsyncSparkJob(), listeners);
         future.get(TIMEOUT, TimeUnit.SECONDS);
         MetricsCollection metrics = future.getMetrics();
         assertEquals(1, metrics.getJobIds().size());
@@ -173,8 +175,8 @@ public void call(SparkClient client) throws Exception {
           eq(metrics.getJobIds().iterator().next()));
 
         JobHandle.Listener<Integer> listener2 = newListener();
-        JobHandle<Integer> future2 = client.submit(new AsyncSparkJob());
-        future2.addListener(listener2);
+        List<JobHandle.Listener<Integer>> listeners2 = Lists.newArrayList(listener2);
+        JobHandle<Integer> future2 = client.submit(new AsyncSparkJob(), listeners2);
         future2.get(TIMEOUT, TimeUnit.SECONDS);
         MetricsCollection metrics2 = future2.getMetrics();
         assertEquals(1, metrics2.getJobIds().size());
-- 
1.7.9.5

