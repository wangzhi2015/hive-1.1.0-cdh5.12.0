From 717d9f3de634de194f7c61b6747347c4f5d5a79a Mon Sep 17 00:00:00 2001
From: Pengcheng Xiong <pxiong@apache.org>
Date: Tue, 5 Jan 2016 13:06:33 -0800
Subject: [PATCH 0463/1164] CDH-36243: HIVE-12782: update the golden files for
 some tests that fail (Pengcheng Xiong, via by
 Ashutosh Chauhan)

Change-Id: I9ac024853b6eb1da62d22164050cbc73e803c637
---
 .../encryption_insert_partition_dynamic.q          |   12 -
 ql/src/test/queries/clientpositive/order2.q        |    5 -
 .../encryption_insert_partition_dynamic.q.out      |  748 +-------------------
 ql/src/test/results/clientpositive/order2.q.out    |   55 --
 .../test/results/clientpositive/spark/order2.q.out |   61 --
 5 files changed, 13 insertions(+), 868 deletions(-)

diff --git a/ql/src/test/queries/clientpositive/encryption_insert_partition_dynamic.q b/ql/src/test/queries/clientpositive/encryption_insert_partition_dynamic.q
index 9556eed..ccb814d 100644
--- a/ql/src/test/queries/clientpositive/encryption_insert_partition_dynamic.q
+++ b/ql/src/test/queries/clientpositive/encryption_insert_partition_dynamic.q
@@ -19,10 +19,6 @@ create table unencryptedTable(value string)
     partitioned by (key string) clustered by (value) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true');
 
 -- insert encrypted table from values
-explain extended insert into table encryptedTable partition (key) values
-    ('val_501', '501'),
-    ('val_502', '502');
-
 insert into table encryptedTable partition (key) values
     ('val_501', '501'),
     ('val_502', '502');
@@ -30,10 +26,6 @@ insert into table encryptedTable partition (key) values
 select * from encryptedTable order by key;
 
 -- insert encrypted table from unencrypted source
-explain extended from src
-insert into table encryptedTable partition (key)
-    select value, key limit 2;
-
 from src
 insert into table encryptedTable partition (key)
     select value, key limit 2;
@@ -41,10 +33,6 @@ insert into table encryptedTable partition (key)
 select * from encryptedTable order by key;
 
 -- insert unencrypted table from encrypted source
-explain extended from encryptedTable
-insert into table unencryptedTable partition (key)
-    select value, key;
-
 from encryptedTable
 insert into table unencryptedTable partition (key)
     select value, key;
diff --git a/ql/src/test/queries/clientpositive/order2.q b/ql/src/test/queries/clientpositive/order2.q
index 6c16fe3..1d4104e 100644
--- a/ql/src/test/queries/clientpositive/order2.q
+++ b/ql/src/test/queries/clientpositive/order2.q
@@ -1,10 +1,5 @@
 set hive.optimize.ppd=true;
 
-EXPLAIN
-SELECT subq.key, subq.value FROM 
-(SELECT x.* FROM SRC x ORDER BY key limit 10) subq
-where subq.key < 10;
-
 SELECT subq.key, subq.value FROM 
 (SELECT x.* FROM SRC x ORDER BY key limit 10) subq
 where subq.key < 10;
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
index 6a43649..6aa3ab0 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
@@ -39,180 +39,22 @@ POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@unencryptedTable
 PREHOOK: query: -- insert encrypted table from values
-explain extended insert into table encryptedTable partition (key) values
+insert into table encryptedTable partition (key) values
     ('val_501', '501'),
     ('val_502', '502')
 PREHOOK: type: QUERY
-POSTHOOK: query: -- insert encrypted table from values
-explain extended insert into table encryptedTable partition (key) values
-    ('val_501', '501'),
-    ('val_502', '502')
-POSTHOOK: type: QUERY
-ABSTRACT SYNTAX TREE:
-  
-TOK_QUERY
-   TOK_FROM
-      null
-         null
-            Values__Tmp__Table__1
-   TOK_INSERT
-      TOK_INSERT_INTO
-         TOK_TAB
-            TOK_TABNAME
-               encryptedTable
-            TOK_PARTSPEC
-               TOK_PARTVAL
-                  key
-      TOK_SELECT
-         TOK_SELEXPR
-            TOK_ALLCOLREF
-
-
-STAGE DEPENDENCIES:
-  Stage-1 is a root stage
-  Stage-0 depends on stages: Stage-1
-  Stage-2 depends on stages: Stage-0
-
-STAGE PLANS:
-  Stage: Stage-1
-    Map Reduce
-      Map Operator Tree:
-          TableScan
-            alias: values__tmp__table__1
-            Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: NONE
-            GatherStats: false
-            Select Operator
-              expressions: tmp_values_col1 (type: string), tmp_values_col2 (type: string)
-              outputColumnNames: _col0, _col1
-              Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: NONE
-              Reduce Output Operator
-                sort order: 
-                Map-reduce partition columns: _col0 (type: string)
-                Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: NONE
-                tag: -1
-                value expressions: _col0 (type: string), _col1 (type: string)
-                auto parallelism: false
-      Path -> Alias:
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-      Path -> Partition:
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-          Partition
-            base file name: Values__Tmp__Table__1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns tmp_values_col1,tmp_values_col2
-              columns.comments 
-              columns.types string:string
-#### A masked pattern was here ####
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-              name default.values__tmp__table__1
-              serialization.ddl struct values__tmp__table__1 { string tmp_values_col1, string tmp_values_col2}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns tmp_values_col1,tmp_values_col2
-                columns.comments 
-                columns.types string:string
-#### A masked pattern was here ####
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-                name default.values__tmp__table__1
-                serialization.ddl struct values__tmp__table__1 { string tmp_values_col1, string tmp_values_col2}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.values__tmp__table__1
-            name: default.values__tmp__table__1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
-      Reduce Operator Tree:
-        Extract
-          Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: NONE
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-            NumFilesPerFileSink: 1
-            Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: NONE
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-            table:
-                input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-                output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-                properties:
-                  bucket_count 2
-                  bucket_field_name value
-                  columns value
-                  columns.comments 
-                  columns.types string
-#### A masked pattern was here ####
-                  name default.encryptedtable
-                  partition_columns key
-                  partition_columns.types string
-                  serialization.ddl struct encryptedtable { string value}
-                  serialization.format 1
-                  serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                  transactional true
-#### A masked pattern was here ####
-                serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                name: default.encryptedtable
-            TotalFiles: 1
-            GatherStats: true
-            MultiFileSpray: false
-
-  Stage: Stage-0
-    Move Operator
-      tables:
-          partition:
-            key 
-          replace: false
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-          table:
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-
-  Stage: Stage-2
-    Stats-Aggr Operator
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-
-PREHOOK: query: insert into table encryptedTable partition (key) values
-    ('val_501', '501'),
-    ('val_502', '502')
-PREHOOK: type: QUERY
-PREHOOK: Input: default@values__tmp__table__2
+PREHOOK: Input: default@values__tmp__table__1
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: insert into table encryptedTable partition (key) values
+POSTHOOK: query: -- insert encrypted table from values
+insert into table encryptedTable partition (key) values
     ('val_501', '501'),
     ('val_502', '502')
 POSTHOOK: type: QUERY
-POSTHOOK: Input: default@values__tmp__table__2
+POSTHOOK: Input: default@values__tmp__table__1
 POSTHOOK: Output: default@encryptedtable@key=501
 POSTHOOK: Output: default@encryptedtable@key=502
-POSTHOOK: Lineage: encryptedtable PARTITION(key=501).value SIMPLE [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
-POSTHOOK: Lineage: encryptedtable PARTITION(key=502).value SIMPLE [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
+POSTHOOK: Lineage: encryptedtable PARTITION(key=501).value SIMPLE [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
+POSTHOOK: Lineage: encryptedtable PARTITION(key=502).value SIMPLE [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
 PREHOOK: query: select * from encryptedTable order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@encryptedtable
@@ -228,255 +70,14 @@ POSTHOOK: Input: default@encryptedtable@key=502
 val_501	501
 val_502	502
 PREHOOK: query: -- insert encrypted table from unencrypted source
-explain extended from src
-insert into table encryptedTable partition (key)
-    select value, key limit 2
-PREHOOK: type: QUERY
-POSTHOOK: query: -- insert encrypted table from unencrypted source
-explain extended from src
-insert into table encryptedTable partition (key)
-    select value, key limit 2
-POSTHOOK: type: QUERY
-ABSTRACT SYNTAX TREE:
-  
-TOK_QUERY
-   TOK_FROM
-      TOK_TABREF
-         TOK_TABNAME
-            src
-   TOK_INSERT
-      TOK_INSERT_INTO
-         TOK_TAB
-            TOK_TABNAME
-               encryptedTable
-            TOK_PARTSPEC
-               TOK_PARTVAL
-                  key
-      TOK_SELECT
-         TOK_SELEXPR
-            TOK_TABLE_OR_COL
-               value
-         TOK_SELEXPR
-            TOK_TABLE_OR_COL
-               key
-      TOK_LIMIT
-         2
-
-
-STAGE DEPENDENCIES:
-  Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1
-  Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-0
-
-STAGE PLANS:
-  Stage: Stage-1
-    Map Reduce
-      Map Operator Tree:
-          TableScan
-            alias: src
-            Statistics: Num rows: 29 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
-            GatherStats: false
-            Select Operator
-              expressions: value (type: string), key (type: string)
-              outputColumnNames: _col0, _col1
-              Statistics: Num rows: 29 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
-              Limit
-                Number of rows: 2
-                Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-                Reduce Output Operator
-                  sort order: 
-                  Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-                  tag: -1
-                  value expressions: _col0 (type: string), _col1 (type: string)
-                  auto parallelism: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: src
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              COLUMN_STATS_ACCURATE true
-              bucket_count -1
-              columns key,value
-              columns.comments 'default','default'
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.src
-              numFiles 1
-              numRows 0
-              rawDataSize 0
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 5812
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                COLUMN_STATS_ACCURATE true
-                bucket_count -1
-                columns key,value
-                columns.comments 'default','default'
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.src
-                numFiles 1
-                numRows 0
-                rawDataSize 0
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 5812
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.src
-            name: default.src
-      Truncated Path -> Alias:
-        /src [$hdt$_0:src]
-      Needs Tagging: false
-      Reduce Operator Tree:
-        Select Operator
-          expressions: VALUE._col0 (type: string), VALUE._col1 (type: string)
-          outputColumnNames: _col0, _col1
-          Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-          Limit
-            Number of rows: 2
-            Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-            File Output Operator
-              compressed: false
-              GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-              table:
-                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                  properties:
-                    columns _col0,_col1
-                    columns.types string,string
-                    escape.delim \
-                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-
-  Stage: Stage-2
-    Map Reduce
-      Map Operator Tree:
-          TableScan
-            GatherStats: false
-            Reduce Output Operator
-              sort order: 
-              Map-reduce partition columns: _col0 (type: string)
-              Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-              tag: -1
-              value expressions: _col0 (type: string), _col1 (type: string)
-              auto parallelism: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10001
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1
-              columns.types string,string
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1
-                columns.types string,string
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
-      Reduce Operator Tree:
-        Extract
-          Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-            NumFilesPerFileSink: 1
-            Statistics: Num rows: 2 Data size: 400 Basic stats: COMPLETE Column stats: NONE
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-            table:
-                input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-                output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-                properties:
-                  bucket_count 2
-                  bucket_field_name value
-                  columns value
-                  columns.comments 
-                  columns.types string
-#### A masked pattern was here ####
-                  name default.encryptedtable
-                  partition_columns key
-                  partition_columns.types string
-                  serialization.ddl struct encryptedtable { string value}
-                  serialization.format 1
-                  serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                  transactional true
-#### A masked pattern was here ####
-                serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                name: default.encryptedtable
-            TotalFiles: 1
-            GatherStats: true
-            MultiFileSpray: false
-
-  Stage: Stage-0
-    Move Operator
-      tables:
-          partition:
-            key 
-          replace: false
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-          table:
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-
-  Stage: Stage-3
-    Stats-Aggr Operator
-#### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
-
-PREHOOK: query: from src
+from src
 insert into table encryptedTable partition (key)
     select value, key limit 2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: from src
+POSTHOOK: query: -- insert encrypted table from unencrypted source
+from src
 insert into table encryptedTable partition (key)
     select value, key limit 2
 POSTHOOK: type: QUERY
@@ -506,331 +107,7 @@ val_501	501
 val_502	502
 val_86	86
 PREHOOK: query: -- insert unencrypted table from encrypted source
-explain extended from encryptedTable
-insert into table unencryptedTable partition (key)
-    select value, key
-PREHOOK: type: QUERY
-POSTHOOK: query: -- insert unencrypted table from encrypted source
-explain extended from encryptedTable
-insert into table unencryptedTable partition (key)
-    select value, key
-POSTHOOK: type: QUERY
-ABSTRACT SYNTAX TREE:
-  
-TOK_QUERY
-   TOK_FROM
-      TOK_TABREF
-         TOK_TABNAME
-            encryptedTable
-   TOK_INSERT
-      TOK_INSERT_INTO
-         TOK_TAB
-            TOK_TABNAME
-               unencryptedTable
-            TOK_PARTSPEC
-               TOK_PARTVAL
-                  key
-      TOK_SELECT
-         TOK_SELEXPR
-            TOK_TABLE_OR_COL
-               value
-         TOK_SELEXPR
-            TOK_TABLE_OR_COL
-               key
-
-
-STAGE DEPENDENCIES:
-  Stage-1 is a root stage
-  Stage-0 depends on stages: Stage-1
-  Stage-2 depends on stages: Stage-0
-
-STAGE PLANS:
-  Stage: Stage-1
-    Map Reduce
-      Map Operator Tree:
-          TableScan
-            alias: encryptedtable
-            Statistics: Num rows: 21 Data size: 2372 Basic stats: COMPLETE Column stats: NONE
-            GatherStats: false
-            Select Operator
-              expressions: value (type: string), key (type: string)
-              outputColumnNames: _col0, _col1
-              Statistics: Num rows: 21 Data size: 2372 Basic stats: COMPLETE Column stats: NONE
-              Reduce Output Operator
-                sort order: 
-                Map-reduce partition columns: _col0 (type: string)
-                Statistics: Num rows: 21 Data size: 2372 Basic stats: COMPLETE Column stats: NONE
-                tag: -1
-                value expressions: _col0 (type: string), _col1 (type: string)
-                auto parallelism: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: key=238
-            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-            partition values:
-              key 238
-            properties:
-              COLUMN_STATS_ACCURATE true
-              bucket_count 2
-              bucket_field_name value
-              columns value
-              columns.comments 
-              columns.types string
-#### A masked pattern was here ####
-              name default.encryptedtable
-              numFiles 1
-              numRows 0
-              partition_columns key
-              partition_columns.types string
-              rawDataSize 0
-              serialization.ddl struct encryptedtable { string value}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              totalSize 600
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-          
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-            name: default.encryptedtable
-#### A masked pattern was here ####
-          Partition
-            base file name: key=501
-            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-            partition values:
-              key 501
-            properties:
-              COLUMN_STATS_ACCURATE true
-              bucket_count 2
-              bucket_field_name value
-              columns value
-              columns.comments 
-              columns.types string
-#### A masked pattern was here ####
-              name default.encryptedtable
-              numFiles 1
-              numRows 0
-              partition_columns key
-              partition_columns.types string
-              rawDataSize 0
-              serialization.ddl struct encryptedtable { string value}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              totalSize 592
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-          
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-            name: default.encryptedtable
-#### A masked pattern was here ####
-          Partition
-            base file name: key=502
-            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-            partition values:
-              key 502
-            properties:
-              COLUMN_STATS_ACCURATE true
-              bucket_count 2
-              bucket_field_name value
-              columns value
-              columns.comments 
-              columns.types string
-#### A masked pattern was here ####
-              name default.encryptedtable
-              numFiles 1
-              numRows 0
-              partition_columns key
-              partition_columns.types string
-              rawDataSize 0
-              serialization.ddl struct encryptedtable { string value}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              totalSize 592
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-          
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-            name: default.encryptedtable
-#### A masked pattern was here ####
-          Partition
-            base file name: key=86
-            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-            partition values:
-              key 86
-            properties:
-              COLUMN_STATS_ACCURATE true
-              bucket_count 2
-              bucket_field_name value
-              columns value
-              columns.comments 
-              columns.types string
-#### A masked pattern was here ####
-              name default.encryptedtable
-              numFiles 1
-              numRows 0
-              partition_columns key
-              partition_columns.types string
-              rawDataSize 0
-              serialization.ddl struct encryptedtable { string value}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              totalSize 588
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-          
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.encryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct encryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.encryptedtable
-            name: default.encryptedtable
-      Truncated Path -> Alias:
-        /encryptedTable/key=238 [encryptedtable]
-        /encryptedTable/key=501 [encryptedtable]
-        /encryptedTable/key=502 [encryptedtable]
-        /encryptedTable/key=86 [encryptedtable]
-      Needs Tagging: false
-      Reduce Operator Tree:
-        Extract
-          Statistics: Num rows: 21 Data size: 2372 Basic stats: COMPLETE Column stats: NONE
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-#### A PARTIAL masked pattern was here #### data/warehouse/unencryptedtable/.hive-staging
-            NumFilesPerFileSink: 1
-            Statistics: Num rows: 21 Data size: 2372 Basic stats: COMPLETE Column stats: NONE
-#### A PARTIAL masked pattern was here #### data/warehouse/unencryptedtable/.hive-staging
-            table:
-                input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-                output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-                properties:
-                  bucket_count 2
-                  bucket_field_name value
-                  columns value
-                  columns.comments 
-                  columns.types string
-#### A masked pattern was here ####
-                  name default.unencryptedtable
-                  partition_columns key
-                  partition_columns.types string
-                  serialization.ddl struct unencryptedtable { string value}
-                  serialization.format 1
-                  serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                  transactional true
-#### A masked pattern was here ####
-                serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                name: default.unencryptedtable
-            TotalFiles: 1
-            GatherStats: true
-            MultiFileSpray: false
-
-  Stage: Stage-0
-    Move Operator
-      tables:
-          partition:
-            key 
-          replace: false
-#### A PARTIAL masked pattern was here #### data/warehouse/unencryptedtable/.hive-staging
-          table:
-              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
-              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
-              properties:
-                bucket_count 2
-                bucket_field_name value
-                columns value
-                columns.comments 
-                columns.types string
-#### A masked pattern was here ####
-                name default.unencryptedtable
-                partition_columns key
-                partition_columns.types string
-                serialization.ddl struct unencryptedtable { string value}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
-                transactional true
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
-              name: default.unencryptedtable
-
-  Stage: Stage-2
-    Stats-Aggr Operator
-#### A PARTIAL masked pattern was here #### data/warehouse/unencryptedtable/.hive-staging
-
-PREHOOK: query: from encryptedTable
+from encryptedTable
 insert into table unencryptedTable partition (key)
     select value, key
 PREHOOK: type: QUERY
@@ -840,7 +117,8 @@ PREHOOK: Input: default@encryptedtable@key=501
 PREHOOK: Input: default@encryptedtable@key=502
 PREHOOK: Input: default@encryptedtable@key=86
 PREHOOK: Output: default@unencryptedtable
-POSTHOOK: query: from encryptedTable
+POSTHOOK: query: -- insert unencrypted table from encrypted source
+from encryptedTable
 insert into table unencryptedTable partition (key)
     select value, key
 POSTHOOK: type: QUERY
diff --git a/ql/src/test/results/clientpositive/order2.q.out b/ql/src/test/results/clientpositive/order2.q.out
index 3a38b46..5ec10fe 100644
--- a/ql/src/test/results/clientpositive/order2.q.out
+++ b/ql/src/test/results/clientpositive/order2.q.out
@@ -1,58 +1,3 @@
-PREHOOK: query: EXPLAIN
-SELECT subq.key, subq.value FROM 
-(SELECT x.* FROM SRC x ORDER BY key limit 10) subq
-where subq.key < 10
-PREHOOK: type: QUERY
-POSTHOOK: query: EXPLAIN
-SELECT subq.key, subq.value FROM 
-(SELECT x.* FROM SRC x ORDER BY key limit 10) subq
-where subq.key < 10
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-1 is a root stage
-  Stage-0 depends on stages: Stage-1
-
-STAGE PLANS:
-  Stage: Stage-1
-    Map Reduce
-      Map Operator Tree:
-          TableScan
-            alias: x
-            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-            Select Operator
-              expressions: key (type: string), value (type: string)
-              outputColumnNames: _col0, _col1
-              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-              Reduce Output Operator
-                key expressions: _col0 (type: string)
-                sort order: +
-                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-                value expressions: _col1 (type: string)
-      Reduce Operator Tree:
-        Select Operator
-          expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
-          outputColumnNames: _col0, _col1
-          Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-          Limit
-            Number of rows: 10
-            Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
-            Filter Operator
-              predicate: (UDFToDouble(_col0) < 10.0) (type: boolean)
-              Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
-              File Output Operator
-                compressed: false
-                Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        ListSink
-
 PREHOOK: query: SELECT subq.key, subq.value FROM 
 (SELECT x.* FROM SRC x ORDER BY key limit 10) subq
 where subq.key < 10
diff --git a/ql/src/test/results/clientpositive/spark/order2.q.out b/ql/src/test/results/clientpositive/spark/order2.q.out
index 22b1ddc..5ec10fe 100644
--- a/ql/src/test/results/clientpositive/spark/order2.q.out
+++ b/ql/src/test/results/clientpositive/spark/order2.q.out
@@ -1,64 +1,3 @@
-PREHOOK: query: EXPLAIN
-SELECT subq.key, subq.value FROM 
-(SELECT x.* FROM SRC x ORDER BY key limit 10) subq
-where subq.key < 10
-PREHOOK: type: QUERY
-POSTHOOK: query: EXPLAIN
-SELECT subq.key, subq.value FROM 
-(SELECT x.* FROM SRC x ORDER BY key limit 10) subq
-where subq.key < 10
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-1 is a root stage
-  Stage-0 depends on stages: Stage-1
-
-STAGE PLANS:
-  Stage: Stage-1
-    Spark
-      Edges:
-        Reducer 2 <- Map 1 (SORT, 1)
-#### A masked pattern was here ####
-      Vertices:
-        Map 1 
-            Map Operator Tree:
-                TableScan
-                  alias: x
-                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-                  Select Operator
-                    expressions: key (type: string), value (type: string)
-                    outputColumnNames: _col0, _col1
-                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: _col0 (type: string)
-                      sort order: +
-                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: _col1 (type: string)
-        Reducer 2 
-            Reduce Operator Tree:
-              Select Operator
-                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
-                outputColumnNames: _col0, _col1
-                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-                Limit
-                  Number of rows: 10
-                  Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
-                  Filter Operator
-                    predicate: (_col0 < 10) (type: boolean)
-                    Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
-                    File Output Operator
-                      compressed: false
-                      Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
-                      table:
-                          input format: org.apache.hadoop.mapred.TextInputFormat
-                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        ListSink
-
 PREHOOK: query: SELECT subq.key, subq.value FROM 
 (SELECT x.* FROM SRC x ORDER BY key limit 10) subq
 where subq.key < 10
-- 
1.7.9.5

