From 5b4c7f700220c650fbb1ad06e7719774a2edcd08 Mon Sep 17 00:00:00 2001
From: Ashutosh Chauhan <hashutosh@apache.org>
Date: Fri, 21 Aug 2015 10:10:52 -0700
Subject: [PATCH 0297/1164] CDH-31826 : HIVE-11607 : Export tables broken for
 data > 32 MB (Ashutosh Chauhan via Sushanth
 Sowmyan, Sergio Pena)

Conflicts:
	shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
---
 shims/0.20S/pom.xml                                |    8 ++++-
 .../apache/hadoop/hive/shims/Hadoop20SShims.java   |   35 +++++++++-----------
 shims/0.23/pom.xml                                 |   21 ++++--------
 .../apache/hadoop/hive/shims/Hadoop23Shims.java    |   35 ++++++--------------
 4 files changed, 40 insertions(+), 59 deletions(-)

diff --git a/shims/0.20S/pom.xml b/shims/0.20S/pom.xml
index e5149a1..3af764e 100644
--- a/shims/0.20S/pom.xml
+++ b/shims/0.20S/pom.xml
@@ -60,5 +60,11 @@
       <version>${hadoop-20S.version}</version>
       <optional>true</optional>
     </dependency>
-  </dependencies>
+    <dependency>
+      <groupId>org.apache.hadoop</groupId>
+      <artifactId>hadoop-tools</artifactId>
+      <version>${hadoop-20S.version}</version>
+      <scope>provided</scope>
+    </dependency>
+ </dependencies>
 </project>
diff --git a/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java b/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
index 49ae0c2..8575567 100644
--- a/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
+++ b/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
@@ -19,13 +19,13 @@
 
 import java.io.IOException;
 import java.lang.Override;
-import java.lang.reflect.Constructor;
 import java.net.InetSocketAddress;
 import java.net.MalformedURLException;
 import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.List;
@@ -68,6 +68,8 @@
 import org.apache.hadoop.mapreduce.TaskID;
 import org.apache.hadoop.security.KerberosName;
 import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.tools.distcp2.DistCp;
+import org.apache.hadoop.tools.distcp2.DistCpOptions;
 import org.apache.hadoop.util.Progressable;
 import org.apache.hadoop.util.Tool;
 import org.apache.hadoop.util.VersionInfo;
@@ -500,7 +502,7 @@ public void setFullFileStatus(Configuration conf, HdfsFileStatus sourceStatus,
   }
 
   public class Hadoop20SFileStatus implements HdfsFileStatus {
-    private FileStatus fileStatus;
+    private final FileStatus fileStatus;
     public Hadoop20SFileStatus(FileStatus fileStatus) {
       this.fileStatus = fileStatus;
     }
@@ -626,28 +628,33 @@ public KerberosNameShim getKerberosNameShim(String name) throws IOException {
    */
   public class KerberosNameShim implements HadoopShimsSecure.KerberosNameShim {
 
-    private KerberosName kerberosName;
+    private final KerberosName kerberosName;
 
     public KerberosNameShim(String name) {
       kerberosName = new KerberosName(name);
     }
 
+    @Override
     public String getDefaultRealm() {
       return kerberosName.getDefaultRealm();
     }
 
+    @Override
     public String getServiceName() {
       return kerberosName.getServiceName();
     }
 
+    @Override
     public String getHostName() {
       return kerberosName.getHostName();
     }
 
+    @Override
     public String getRealm() {
       return kerberosName.getRealm();
     }
 
+    @Override
     public String getShortName() throws IOException {
       return kerberosName.getShortName();
     }
@@ -655,27 +662,17 @@ public String getShortName() throws IOException {
 
   @Override
   public boolean runDistCp(Path src, Path dst, Configuration conf) throws IOException {
-    int rc;
-
-    // Creates the command-line parameters for distcp
-    String[] params = {"-update", "-skipcrccheck", src.toString(), dst.toString()};
 
+    DistCpOptions options = new DistCpOptions(Collections.singletonList(src), dst);
+    options.setSkipCRC(true);
+    options.setSyncFolder(true);
     try {
-      Class clazzDistCp = Class.forName("org.apache.hadoop.tools.distcp2");
-      Constructor c = clazzDistCp.getConstructor();
-      c.setAccessible(true);
-      Tool distcp = (Tool)c.newInstance();
-      distcp.setConf(conf);
-      rc = distcp.run(params);
-    } catch (ClassNotFoundException e) {
-      throw new IOException("Cannot find DistCp class package: " + e.getMessage());
-    } catch (NoSuchMethodException e) {
-      throw new IOException("Cannot get DistCp constructor: " + e.getMessage());
+      DistCp distcp = new DistCp(conf, options);
+      distcp.execute();
+      return true;
     } catch (Exception e) {
       throw new IOException("Cannot execute DistCp process: " + e, e);
     }
-
-    return (0 == rc) ? true : false;
   }
 
   @Override
diff --git a/shims/0.23/pom.xml b/shims/0.23/pom.xml
index 4e22830..43da6d2 100644
--- a/shims/0.23/pom.xml
+++ b/shims/0.23/pom.xml
@@ -144,18 +144,11 @@
       <optional>true</optional>
      <type>test-jar</type>
    </dependency>
-  </dependencies>
-
-  <profiles>
-    <profile>
-      <id>hadoop-2</id>
-      <dependencies>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-distcp</artifactId>
-          <version>${hadoop-23.version}</version>
-        </dependency>
-      </dependencies>
-    </profile>
-  </profiles>
+   <dependency>
+     <groupId>org.apache.hadoop</groupId>
+     <artifactId>hadoop-distcp</artifactId>
+     <version>${hadoop-23.version}</version>
+     <scope>provided</scope>
+   </dependency>
+   </dependencies>
 </project>
diff --git a/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java b/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
index aff334f..7a84a63 100644
--- a/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
+++ b/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
@@ -27,6 +27,7 @@
 import java.security.AccessControlException;
 import java.security.NoSuchAlgorithmException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.Iterator;
@@ -85,6 +86,8 @@
 import org.apache.hadoop.net.NetUtils;
 import org.apache.hadoop.security.authentication.util.KerberosName;
 import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.tools.DistCp;
+import org.apache.hadoop.tools.DistCpOptions;
 import org.apache.hadoop.util.Progressable;
 import org.apache.hadoop.util.Tool;
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
@@ -1135,35 +1138,17 @@ public String getShortName() throws IOException {
 
   @Override
   public boolean runDistCp(Path src, Path dst, Configuration conf) throws IOException {
-    int rc;
-
-    // Creates the command-line parameters for distcp
-    String[] params = {"-update", "-skipcrccheck", src.toString(), dst.toString()};
-
+    DistCpOptions options = new DistCpOptions(Collections.singletonList(src), dst);
+    options.setSyncFolder(true);
+    options.setSkipCRC(true);
+    options.preserve(DistCpOptions.FileAttribute.BLOCKSIZE);
     try {
-      Class clazzDistCp = Class.forName("org.apache.hadoop.tools.DistCp");
-      Tool distcp;
-      if (org.apache.hadoop.mapred.MRVersion.isMR2()) {
-        Constructor c = clazzDistCp.getConstructor();
-        c.setAccessible(true);
-        distcp = (Tool)c.newInstance();
-        distcp.setConf(conf);
-      } else {
-        Constructor c = clazzDistCp.getConstructor(Configuration.class);
-        c.setAccessible(true);
-        distcp = (Tool)c.newInstance(conf);
-      }
-
-      rc = distcp.run(params);
-    } catch (ClassNotFoundException e) {
-      throw new IOException("Cannot find DistCp class package: " + e.getMessage());
-    } catch (NoSuchMethodException e) {
-      throw new IOException("Cannot get DistCp constructor: " + e.getMessage());
+      DistCp distcp = new DistCp(conf, options);
+      distcp.execute();
+      return true;
     } catch (Exception e) {
       throw new IOException("Cannot execute DistCp process: " + e, e);
     }
-
-    return (0 == rc);
   }
 
   public class HdfsEncryptionShim implements HadoopShims.HdfsEncryptionShim {
-- 
1.7.9.5

