From bb9d26acf456370029f82e2c25e87a942d53212d Mon Sep 17 00:00:00 2001
From: Marta Kuczora <kuczoram@cloudera.com>
Date: Thu, 4 May 2017 13:40:01 +0200
Subject: [PATCH 1093/1164] CDH-52465: Remove the comments from the Blobstore
 q test outputs

Change-Id: Id9f414dcfaff847c25ce4d88c5891bf40eab774f
---
 .../test/results/clientpositive/create_like.q.out  |    6 ++---
 .../ctas_blobstore_to_blobstore.q.out              |   10 ++------
 .../clientpositive/ctas_blobstore_to_hdfs.q.out    |   10 ++------
 .../clientpositive/ctas_hdfs_to_blobstore.q.out    |   10 ++------
 .../insert_into_dynamic_partitions.q.out           |   12 ++++------
 .../results/clientpositive/insert_into_table.q.out |    6 ++---
 .../insert_overwrite_directory.q.out               |   24 +++++++-------------
 .../insert_overwrite_dynamic_partitions.q.out      |   12 ++++------
 .../clientpositive/insert_overwrite_table.q.out    |   16 ++++---------
 .../write_final_output_blobstore.q.out             |   22 +++++-------------
 10 files changed, 36 insertions(+), 92 deletions(-)

diff --git a/itests/hive-blobstore/src/test/results/clientpositive/create_like.q.out b/itests/hive-blobstore/src/test/results/clientpositive/create_like.q.out
index c684a41..969f50b 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/create_like.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/create_like.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Create external table like should not result in data loss upon dropping the table
-DROP TABLE blobstore_partitioned_source_table
+PREHOOK: query: DROP TABLE blobstore_partitioned_source_table
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Create external table like should not result in data loss upon dropping the table
-DROP TABLE blobstore_partitioned_source_table
+POSTHOOK: query: DROP TABLE blobstore_partitioned_source_table
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE blobstore_partitioned_source_table (
   a int, b int, c string
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_blobstore.q.out b/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_blobstore.q.out
index 1fa3186..4044edb 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_blobstore.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_blobstore.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- Check we can create a table located in a blobstore
--- with CTAS from a table in a blobstore
-
-DROP TABLE IF EXISTS blobstore_source
+PREHOOK: query: DROP TABLE IF EXISTS blobstore_source
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Check we can create a table located in a blobstore
--- with CTAS from a table in a blobstore
-
-DROP TABLE IF EXISTS blobstore_source
+POSTHOOK: query: DROP TABLE IF EXISTS blobstore_source
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE blobstore_source(a string, b string, c double)
 ROW FORMAT DELIMITED 
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_hdfs.q.out b/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_hdfs.q.out
index 276338d..90eaec5 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_hdfs.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/ctas_blobstore_to_hdfs.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- Check we can create a table located in HDFS
--- with CTAS from a table a blobstore
-
-DROP TABLE IF EXISTS blobstore_source
+PREHOOK: query: DROP TABLE IF EXISTS blobstore_source
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Check we can create a table located in HDFS
--- with CTAS from a table a blobstore
-
-DROP TABLE IF EXISTS blobstore_source
+POSTHOOK: query: DROP TABLE IF EXISTS blobstore_source
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE blobstore_source(a string, b string, c double)
 ROW FORMAT DELIMITED 
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/ctas_hdfs_to_blobstore.q.out b/itests/hive-blobstore/src/test/results/clientpositive/ctas_hdfs_to_blobstore.q.out
index e2cc602..e64142d 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/ctas_hdfs_to_blobstore.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/ctas_hdfs_to_blobstore.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- Check we can create a table located in a blobstore
--- with CTAS from a table in HDFS
-
-DROP TABLE IF EXISTS hdfs_source
+PREHOOK: query: DROP TABLE IF EXISTS hdfs_source
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Check we can create a table located in a blobstore
--- with CTAS from a table in HDFS
-
-DROP TABLE IF EXISTS hdfs_source
+POSTHOOK: query: DROP TABLE IF EXISTS hdfs_source
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE hdfs_source(a string, b string, c double)
 ROW FORMAT DELIMITED 
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
index e6f3e69..65916d7 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -235,13 +233,11 @@ POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: default@table1
-PREHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+PREHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@table1
-POSTHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+POSTHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@table1
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
index 6726c23..ec5e0f9 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
index 8152ccb..a3ddb3d 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Create a simple source table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Create a simple source table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE table1 (id int, key string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
 PREHOOK: type: CREATETABLE
@@ -28,28 +26,24 @@ POSTHOOK: type: QUERY
 POSTHOOK: Output: default@table1
 POSTHOOK: Lineage: table1.id EXPRESSION [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
 POSTHOOK: Lineage: table1.key SIMPLE [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col2, type:string, comment:), ]
-PREHOOK: query: -- Write and verify data on the directory;
-INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+PREHOOK: query: INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
 PREHOOK: Output: ### test.blobstore.path ###/table1.dir
-POSTHOOK: query: -- Write and verify data on the directory;
-INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+POSTHOOK: query: INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: ### test.blobstore.path ###/table1.dir
 1k1
 2k2
-PREHOOK: query: -- Write and verify data using FROM ... INSERT OVERWRITE DIRECTORY;
-FROM table1
+PREHOOK: query: FROM table1
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT id
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table2.dir/' SELECT key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
 PREHOOK: Output: ### test.blobstore.path ###/table1.dir
 PREHOOK: Output: ### test.blobstore.path ###/table2.dir
-POSTHOOK: query: -- Write and verify data using FROM ... INSERT OVERWRITE DIRECTORY;
-FROM table1
+POSTHOOK: query: FROM table1
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT id
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table2.dir/' SELECT key
 POSTHOOK: type: QUERY
@@ -60,11 +54,9 @@ POSTHOOK: Output: ### test.blobstore.path ###/table2.dir
 2
 k1
 k2
-PREHOOK: query: -- Verify plan is optimizedl
-EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+PREHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Verify plan is optimizedl
-EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+POSTHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 POSTHOOK: type: QUERY
 ABSTRACT SYNTAX TREE:
   
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
index 4ba69a7..cbf54ce 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -253,13 +251,11 @@ POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: default@table1
-PREHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+PREHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@table1
-POSTHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+POSTHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@table1
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
index acbcdd3..a7528d5 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -409,13 +407,11 @@ POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: default@table1
-PREHOOK: query: -- Insert dynamic partitions;
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
 PREHOOK: Input: ### test.blobstore.path ###/table1
 PREHOOK: Output: database:default
 PREHOOK: Output: default@table1
-POSTHOOK: query: -- Insert dynamic partitions;
 #### A masked pattern was here ####
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Input: ### test.blobstore.path ###/table1
@@ -459,13 +455,9 @@ POSTHOOK: Input: default@table1@key=505
 3	303
 4	404
 5	505
-PREHOOK: query: --INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505');
---SELECT * FROM table1;
-EXPLAIN EXTENDED INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505')
+PREHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505')
 PREHOOK: type: QUERY
-POSTHOOK: query: --INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505');
---SELECT * FROM table1;
-EXPLAIN EXTENDED INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505')
+POSTHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE TABLE table1 PARTITION (key) VALUES (1, '101'), (2, '202'), (3, '303'), (4, '404'), (5, '505')
 POSTHOOK: type: QUERY
 ABSTRACT SYNTAX TREE:
   
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out b/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
index 8aa901e..07052dc 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
@@ -1,24 +1,16 @@
-PREHOOK: query: -- Test that the when multiple MR jobs are created for a query, that only the FSOP from the last job writes to S3
-
--- Drop tables
-DROP TABLE IF EXISTS hdfs_table
+PREHOOK: query: DROP TABLE IF EXISTS hdfs_table
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Test that the when multiple MR jobs are created for a query, that only the FSOP from the last job writes to S3
-
--- Drop tables
-DROP TABLE IF EXISTS hdfs_table
+POSTHOOK: query: DROP TABLE IF EXISTS hdfs_table
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: DROP TABLE IF EXISTS blobstore_table
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS blobstore_table
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: -- Create a table one table on HDFS and another on S3
-CREATE TABLE hdfs_table(key INT)
+PREHOOK: query: CREATE TABLE hdfs_table(key INT)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@hdfs_table
-POSTHOOK: query: -- Create a table one table on HDFS and another on S3
-CREATE TABLE hdfs_table(key INT)
+POSTHOOK: query: CREATE TABLE hdfs_table(key INT)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@hdfs_table
@@ -484,13 +476,11 @@ STAGE PLANS:
     Stats-Aggr Operator
       Stats Aggregation Key Prefix: ### BLOBSTORE_STAGING_PATH ###
 
-PREHOOK: query: -- Drop tables
-DROP TABLE hdfs_table
+PREHOOK: query: DROP TABLE hdfs_table
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@hdfs_table
 PREHOOK: Output: default@hdfs_table
-POSTHOOK: query: -- Drop tables
-DROP TABLE hdfs_table
+POSTHOOK: query: DROP TABLE hdfs_table
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@hdfs_table
 POSTHOOK: Output: default@hdfs_table
-- 
1.7.9.5

