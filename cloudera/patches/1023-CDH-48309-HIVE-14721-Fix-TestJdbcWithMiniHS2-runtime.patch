From c4eabc1e9f360ba9fd9ec6e613e082e3d72926e0 Mon Sep 17 00:00:00 2001
From: Vaibhav Gumashta <vgumashta@hortonworks.com>
Date: Tue, 11 Oct 2016 22:52:39 -0700
Subject: [PATCH 1023/1164] CDH-48309: HIVE-14721: Fix TestJdbcWithMiniHS2
 runtime (Vaibhav Gumashta reviewed by Siddharth
 Seth)

(cherry picked from commit 42d997a298a82410ee17e874b934a4953380bbc5)

Change-Id: I786157c8faac6db7503b062956c1725491212959
---
 .../hive/minikdc/JdbcWithMiniKdcSQLAuthTest.java   |    2 +
 .../org/apache/hive/jdbc/TestJdbcWithMiniHS2.java  |  725 +++++++++++++-------
 2 files changed, 476 insertions(+), 251 deletions(-)

diff --git a/itests/hive-minikdc/src/test/java/org/apache/hive/minikdc/JdbcWithMiniKdcSQLAuthTest.java b/itests/hive-minikdc/src/test/java/org/apache/hive/minikdc/JdbcWithMiniKdcSQLAuthTest.java
index 1ff0795..0f0ae54 100644
--- a/itests/hive-minikdc/src/test/java/org/apache/hive/minikdc/JdbcWithMiniKdcSQLAuthTest.java
+++ b/itests/hive-minikdc/src/test/java/org/apache/hive/minikdc/JdbcWithMiniKdcSQLAuthTest.java
@@ -97,6 +97,8 @@ public void testAuthorization1() throws Exception {
 
       Statement stmt = hs2Conn.createStatement();
 
+      stmt.execute("drop table if exists " + tableName1);
+      stmt.execute("drop table if exists " + tableName2);
       // create tables
       stmt.execute("create table " + tableName1 + "(i int) ");
       stmt.execute("create table " + tableName2 + "(i int) ");
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
index 4e7d865..2b26e86 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
@@ -24,13 +24,16 @@
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
-import java.io.IOException;
-import java.lang.reflect.Method;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Field;
+import java.lang.reflect.Modifier;
 import java.sql.Connection;
+import java.sql.DatabaseMetaData;
 import java.sql.DriverManager;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
+import java.sql.Types;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
@@ -47,19 +50,19 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
+import com.google.common.cache.Cache;
+import com.google.common.cache.CacheBuilder;
+
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
-import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.util.ReflectionUtils;
 import org.apache.hive.jdbc.miniHS2.MiniHS2;
-import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Assert;
-import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -68,107 +71,162 @@
   private static String dataFileDir;
   private static Path kvDataFilePath;
   private static final String tmpDir = System.getProperty("test.tmp.dir");
-
-  private Connection hs2Conn = null;
+  private static final String testDbName = "testjdbcminihs2";
+  private static final String defaultDbName = "default";
+  private static final String tableName = "testjdbcminihs2tbl";
+  private static final String tableComment = "Simple table";
+  private static Connection conDefault = null;
+  private static Connection conTestDb = null;
+  private static String testUdfClassName =
+      "org.apache.hadoop.hive.contrib.udf.example.UDFExampleAdd";
 
   @BeforeClass
-  public static void beforeTest() throws Exception {
-    Class.forName(MiniHS2.getJdbcDriverName());
-    MiniHS2.cleanupLocalDir();
+  public static void setupBeforeClass() throws Exception {
     HiveConf conf = new HiveConf();
-    conf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY, false);
-    miniHS2 = new MiniHS2(conf);
     dataFileDir = conf.get("test.data.files").replace('\\', '/').replace("c:", "");
     kvDataFilePath = new Path(dataFileDir, "kv1.txt");
-    Map<String, String> confOverlay = new HashMap<String, String>();
-    miniHS2.start(confOverlay);
+    try {
+      startMiniHS2(conf);
+    } catch (Exception e) {
+     System.out.println("Unable to start MiniHS2: " + e);
+     throw e;
+    }
+    // Open default connections which will be used throughout the tests
+    try {
+      openDefaultConnections();
+    } catch (Exception e) {
+      System.out.println("Unable to open default connections to MiniHS2: " + e);
+      throw e;
+    }
+    Statement stmt = conDefault.createStatement();
+    stmt.execute("drop database if exists " + testDbName + " cascade");
+    stmt.execute("create database " + testDbName);
+    stmt.close();
+    // tables in test db
+    createTestTables(conTestDb, testDbName);
   }
 
-  private Connection getConnection() throws Exception {
+  private static Connection getConnection() throws Exception {
     return getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
   }
 
-  private Connection getConnection(String jdbcURL, String user, String pwd) throws SQLException {
+  private static Connection getConnection(String dbName) throws Exception {
+    return getConnection(miniHS2.getJdbcURL(dbName), System.getProperty("user.name"), "bar");
+  }
+
+  private static Connection getConnection(String jdbcURL, String user, String pwd)
+      throws SQLException {
     Connection conn = DriverManager.getConnection(jdbcURL, user, pwd);
-    conn.createStatement().execute("set hive.support.concurrency = false");
+    assertNotNull(conn);
     return conn;
   }
 
-  @After
-  public void tearDown() throws Exception {
-    if (hs2Conn != null) {
-      hs2Conn.close();
-    }
+  private static void createTestTables(Connection conn, String dbName) throws SQLException {
+    Statement stmt = conn.createStatement();
+    Path dataFilePath = new Path(dataFileDir, "kv1.txt");
+    // We've already dropped testDbName in constructor & we also drop it in tearDownAfterClass
+    String prefix = dbName + ".";
+    String tableName = prefix + TestJdbcWithMiniHS2.tableName;
+
+    // create a table
+    stmt.execute("create table " + tableName
+        + " (int_col int comment 'the int column', value string) comment '" + tableComment + "'");
+    // load data
+    stmt.execute("load data local inpath '" + dataFilePath.toString() + "' into table " + tableName);
+
+    stmt.close();
   }
 
   @AfterClass
-  public static void afterTest() throws Exception {
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
+  public static void tearDownAfterClass() throws Exception {
+    // drop test db and its tables and views
+    Statement stmt = conDefault.createStatement();
+    stmt.execute("set hive.support.concurrency = false");
+    stmt.execute("drop database if exists " + testDbName + " cascade");
+    stmt.close();
+    if (conTestDb != null) {
+      conTestDb.close();
+    }
+    if (conDefault != null) {
+      conDefault.close();
     }
+    stopMiniHS2();
     cleanupMiniHS2();
   }
 
-  private static void cleanupMiniHS2() throws IOException {
+  private static void restoreMiniHS2AndConnections()  throws Exception {
+    if (conTestDb != null) {
+      try {
+        conTestDb.close();
+      } catch (SQLException e) {
+        // Do nothing
+      }
+    }
+    if (conDefault != null) {
+      try {
+        conDefault.close();
+      } catch (SQLException e) {
+        // Do nothing
+      }
+    }
+    stopMiniHS2();
+    HiveConf conf = new HiveConf();
+    startMiniHS2(conf);
+    openDefaultConnections();
+  }
+
+  private static void startMiniHS2(HiveConf conf) throws Exception {
+    conf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY, false);
+    conf.setBoolVar(ConfVars.HIVE_SERVER2_LOGGING_OPERATION_ENABLED, false);
+    miniHS2 = new MiniHS2(conf);
+    Map<String, String> confOverlay = new HashMap<String, String>();
+    miniHS2.start(confOverlay);
+  }
+
+  private static void stopMiniHS2() {
+    if ((miniHS2 != null) && (miniHS2.isStarted())) {
+      miniHS2.stop();
+    }
+  }
+
+  private static void cleanupMiniHS2() {
     if (miniHS2 != null) {
       miniHS2.cleanup();
     }
-    MiniHS2.cleanupLocalDir();
+  }
+
+  private static void openDefaultConnections() throws Exception {
+    conDefault = getConnection();
+    conTestDb = getConnection(testDbName);
   }
 
   @Test
   public void testConnection() throws Exception {
-    String tableName = "testTab1";
-    hs2Conn = getConnection();
-    Statement stmt = hs2Conn.createStatement();
-
-    // create table
-    stmt.execute("DROP TABLE IF EXISTS " + tableName);
-    stmt.execute("CREATE TABLE " + tableName
-        + " (under_col INT COMMENT 'the under column', value STRING) COMMENT ' test table'");
-
-    // load data
-    stmt.execute("load data local inpath '"
-        + kvDataFilePath.toString() + "' into table " + tableName);
-
-    ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
+    Statement stmt = conTestDb.createStatement();
+    ResultSet res = stmt.executeQuery("select * from " + tableName + " limit 5");
     assertTrue(res.next());
-    assertEquals("val_238", res.getString(2));
     res.close();
     stmt.close();
   }
 
   @Test
   public void testConcurrentStatements() throws Exception {
-    String tableName = "testConcurrentStatements";
-    hs2Conn = getConnection();
-    Statement stmt = hs2Conn.createStatement();
-
-    // create table
-    stmt.execute("DROP TABLE IF EXISTS " + tableName);
-    stmt.execute("CREATE TABLE " + tableName
-        + " (under_col INT COMMENT 'the under column', value STRING) COMMENT ' test table'");
-
-    // load data
-    stmt.execute("load data local inpath '"
-        + kvDataFilePath.toString() + "' into table " + tableName);
-
-    ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
-    assertTrue(res.next());
-    res.close();
-    stmt.close();
+    startConcurrencyTest(conTestDb, tableName, 50);
+  }
 
+  private static void startConcurrencyTest(Connection conn, String tableName, int numTasks) {
     // Start concurrent testing
     int POOL_SIZE = 100;
-    int TASK_COUNT = 300;
+    int TASK_COUNT = numTasks;
 
     SynchronousQueue<Runnable> executorQueue = new SynchronousQueue<Runnable>();
-    ExecutorService workers = new ThreadPoolExecutor(1, POOL_SIZE, 20, TimeUnit.SECONDS, executorQueue);
+    ExecutorService workers =
+        new ThreadPoolExecutor(1, POOL_SIZE, 20, TimeUnit.SECONDS, executorQueue);
     List<Future<Boolean>> list = new ArrayList<Future<Boolean>>();
     int i = 0;
-    while(i < TASK_COUNT) {
+    while (i < TASK_COUNT) {
       try {
-        Future<Boolean> future = workers.submit(new JDBCTask(hs2Conn, i, tableName));
+        Future<Boolean> future = workers.submit(new JDBCTask(conn, i, tableName));
         list.add(future);
         i++;
       } catch (RejectedExecutionException ree) {
@@ -252,7 +310,7 @@ public Boolean call() throws SQLException {
   }
 
   /**   This test is to connect to any database without using the command "Use <<DB>>"
-   *  1)connect to default database.
+   *  1) connect to default database.
    *  2) Create a new DB test_default.
    *  3) Connect to test_default database.
    *  4) Connect and create table under test_default_test.
@@ -267,22 +325,22 @@ public void testURIDatabaseName() throws Exception{
 
     String  jdbcUri  = miniHS2.getJdbcURL().substring(0, miniHS2.getJdbcURL().indexOf("default"));
 
-    hs2Conn= getConnection(jdbcUri+"default", System.getProperty("user.name"),"bar");
+    Connection conn= getConnection(jdbcUri+"default", System.getProperty("user.name"),"bar");
     String dbName="test_connection_non_default_db";
     String tableInNonDefaultSchema="table_in_non_default_schema";
-    Statement stmt = hs2Conn.createStatement();
+    Statement stmt = conn.createStatement();
     stmt.execute("create database  if not exists "+dbName);
     stmt.close();
-    hs2Conn.close();
+    conn.close();
 
-    hs2Conn = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
-    stmt = hs2Conn .createStatement();
+    conn = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
+    stmt = conn .createStatement();
     boolean expected = stmt.execute(" create table "+tableInNonDefaultSchema +" (x int)");
     stmt.close();
-    hs2Conn .close();
+    conn .close();
 
-    hs2Conn  = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
-    stmt = hs2Conn .createStatement();
+    conn  = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
+    stmt = conn .createStatement();
     ResultSet res = stmt.executeQuery("show tables");
     boolean testTableExists = false;
     while (res.next()) {
@@ -294,10 +352,10 @@ public void testURIDatabaseName() throws Exception{
     assertTrue("table name  "+tableInNonDefaultSchema
         + "   found in SHOW TABLES result set", testTableExists);
     stmt.close();
-    hs2Conn .close();
+    conn .close();
 
-    hs2Conn  = getConnection(jdbcUri+"default",System.getProperty("user.name"),"bar");
-    stmt = hs2Conn .createStatement();
+    conn  = getConnection(jdbcUri+"default",System.getProperty("user.name"),"bar");
+    stmt = conn .createStatement();
     res = stmt.executeQuery("show tables");
     testTableExists = false;
     while (res.next()) {
@@ -310,20 +368,20 @@ public void testURIDatabaseName() throws Exception{
     assertFalse("table name "+tableInNonDefaultSchema
         + "  NOT  found in SHOW TABLES result set", testTableExists);
     stmt.close();
-    hs2Conn .close();
+    conn .close();
 
-    hs2Conn  = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
-    stmt = hs2Conn .createStatement();
+    conn  = getConnection(jdbcUri+dbName,System.getProperty("user.name"),"bar");
+    stmt = conn .createStatement();
     stmt.execute("set hive.support.concurrency = false");
     res = stmt.executeQuery("show tables");
 
     stmt.execute(" drop table if exists table_in_non_default_schema");
     expected = stmt.execute("DROP DATABASE "+ dbName);
     stmt.close();
-    hs2Conn.close();
+    conn.close();
 
-    hs2Conn  = getConnection(jdbcUri+"default",System.getProperty("user.name"),"bar");
-    stmt = hs2Conn .createStatement();
+    conn  = getConnection(jdbcUri+"default",System.getProperty("user.name"),"bar");
+    stmt = conn .createStatement();
     res = stmt.executeQuery("show tables");
     testTableExists = false;
     while (res.next()) {
@@ -334,49 +392,17 @@ public void testURIDatabaseName() throws Exception{
     }
 
     // test URI with no dbName
-    hs2Conn  = getConnection(jdbcUri, System.getProperty("user.name"),"bar");
-    verifyCurrentDB("default", hs2Conn);
-    hs2Conn.close();
-
-    hs2Conn  = getConnection(jdbcUri + ";", System.getProperty("user.name"),"bar");
-    verifyCurrentDB("default", hs2Conn);
-    hs2Conn.close();
-
-    hs2Conn  = getConnection(jdbcUri + ";/foo=bar;foo1=bar1", System.getProperty("user.name"),"bar");
-    verifyCurrentDB("default", hs2Conn);
-    hs2Conn.close();
-  }
-
-  @Test
-  public void testConnectionSchemaAPIs() throws Exception {
-    String db1 = "DB1";
-    /**
-     * get/set Schema are new in JDK7 and not available in java.sql.Connection in JDK6.
-     * Hence the test uses HiveConnection object to call these methods so that test will run with older JDKs
-     */
-    hs2Conn = getConnection();
-    HiveConnection hiveConn = (HiveConnection)hs2Conn;
-
-    assertEquals("default", hiveConn.getSchema());
-    Statement stmt = hs2Conn.createStatement();
-    stmt.execute("DROP DATABASE IF EXISTS " + db1 + " CASCADE");
-    stmt.execute("CREATE DATABASE " + db1);
-    assertEquals("default", hiveConn.getSchema());
-
-    stmt.execute("USE " + db1);
-    assertEquals(db1, hiveConn.getSchema());
-
-    stmt.execute("USE default");
-    assertEquals("default", hiveConn.getSchema());
+    conn  = getConnection(jdbcUri, System.getProperty("user.name"),"bar");
+    verifyCurrentDB("default", conn);
+    conn.close();
 
-    hiveConn.setSchema(db1);
-    assertEquals(db1, hiveConn.getSchema());
-    hiveConn.setSchema("default");
-    assertEquals("default", hiveConn.getSchema());
+    conn  = getConnection(jdbcUri + ";", System.getProperty("user.name"),"bar");
+    verifyCurrentDB("default", conn);
+    conn.close();
 
-    assertTrue(hiveConn.getCatalog().isEmpty());
-    hiveConn.setCatalog("foo");
-    assertTrue(hiveConn.getCatalog().isEmpty());
+    conn  = getConnection(jdbcUri + ";/foo=bar;foo1=bar1", System.getProperty("user.name"),"bar");
+    verifyCurrentDB("default", conn);
+    conn.close();
   }
 
   /**
@@ -388,7 +414,6 @@ public void testConnectionSchemaAPIs() throws Exception {
    */
   private void verifyCurrentDB(String expectedDbName, Connection hs2Conn) throws Exception {
     String verifyTab = "miniHS2DbVerificationTable";
-    hs2Conn = getConnection();
     Statement stmt = hs2Conn.createStatement();
     stmt.execute("DROP TABLE IF EXISTS " + expectedDbName + "." + verifyTab);
     stmt.execute("CREATE TABLE " + expectedDbName + "." + verifyTab + "(id INT)");
@@ -397,6 +422,32 @@ private void verifyCurrentDB(String expectedDbName, Connection hs2Conn) throws E
     stmt.close();
   }
 
+  @Test
+  public void testConnectionSchemaAPIs() throws Exception {
+    /**
+     * get/set Schema are new in JDK7 and not available in java.sql.Connection in JDK6. Hence the
+     * test uses HiveConnection object to call these methods so that test will run with older JDKs
+     */
+    HiveConnection hiveConn = (HiveConnection) conDefault;
+    assertEquals(defaultDbName, hiveConn.getSchema());
+    Statement stmt = conDefault.createStatement();
+
+    stmt.execute("USE " + testDbName);
+    assertEquals(testDbName, hiveConn.getSchema());
+
+    stmt.execute("USE " + defaultDbName);
+    assertEquals(defaultDbName, hiveConn.getSchema());
+
+    hiveConn.setSchema(defaultDbName);
+    assertEquals(defaultDbName, hiveConn.getSchema());
+    hiveConn.setSchema(defaultDbName);
+    assertEquals(defaultDbName, hiveConn.getSchema());
+
+    assertTrue(hiveConn.getCatalog().isEmpty());
+    hiveConn.setCatalog("foo");
+    assertTrue(hiveConn.getCatalog().isEmpty());
+  }
+
   /**
    * This method tests whether while creating a new connection, the config
    * variables specified in the JDBC URI are properly set for the connection.
@@ -406,31 +457,27 @@ private void verifyCurrentDB(String expectedDbName, Connection hs2Conn) throws E
    */
   @Test
   public void testNewConnectionConfiguration() throws Exception {
-
     // Set some conf parameters
-    String hiveConf = "hive.cli.print.header=true;hive.server2.async.exec.shutdown.timeout=20;"
-        + "hive.server2.async.exec.threads=30;hive.server2.thrift.http.max.worker.threads=15";
+    String hiveConf =
+        "hive.cli.print.header=true;hive.server2.async.exec.shutdown.timeout=20;"
+            + "hive.server2.async.exec.threads=30;hive.server2.thrift.max.worker.threads=15";
     // Set some conf vars
     String hiveVar = "stab=salesTable;icol=customerID";
     String jdbcUri = miniHS2.getJdbcURL() + "?" + hiveConf + "#" + hiveVar;
-
     // Open a new connection with these conf & vars
     Connection con1 = DriverManager.getConnection(jdbcUri);
-
-    // Execute "set" command and retrieve values for the conf & vars specified
-    // above
+    // Execute "set" command and retrieve values for the conf & vars specified above
     // Assert values retrieved
     Statement stmt = con1.createStatement();
-
     // Verify that the property has been properly set while creating the
     // connection above
     verifyConfProperty(stmt, "hive.cli.print.header", "true");
     verifyConfProperty(stmt, "hive.server2.async.exec.shutdown.timeout", "20");
     verifyConfProperty(stmt, "hive.server2.async.exec.threads", "30");
-    verifyConfProperty(stmt, "hive.server2.thrift.http.max.worker.threads",
-        "15");
+    verifyConfProperty(stmt, "hive.server2.thrift.max.worker.threads", "15");
     verifyConfProperty(stmt, "stab", "salesTable");
     verifyConfProperty(stmt, "icol", "customerID");
+    stmt.close();
     con1.close();
   }
 
@@ -452,25 +499,21 @@ private void verifyConfProperty(Statement stmt, String property,
   @Test
   public void testSessionScratchDirs() throws Exception {
     // Stop HiveServer2
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
+    stopMiniHS2();
     HiveConf conf = new HiveConf();
     String userName;
     Path scratchDirPath;
-    // 1. Test with doAs=false
-    conf.setBoolean("hive.server2.enable.doAs", false);
     // Set a custom prefix for hdfs scratch dir path
     conf.set("hive.exec.scratchdir", tmpDir + "/hs2");
     // Set a scratch dir permission
     String fsPermissionStr = "700";
     conf.set("hive.scratch.dir.permission", fsPermissionStr);
     // Start an instance of HiveServer2 which uses miniMR
-    miniHS2 = new MiniHS2(conf);
-    Map<String, String> confOverlay = new HashMap<String, String>();
-    miniHS2.start(confOverlay);
+    startMiniHS2(conf);
+    // 1. Test with doAs=false
+    String sessionConf="hive.server2.enable.doAs=false";
     userName = System.getProperty("user.name");
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), userName, "password");
+    Connection conn = getConnection(miniHS2.getJdbcURL(testDbName, sessionConf), userName, "password");
     // FS
     FileSystem fs = miniHS2.getLocalFS();
     FsPermission expectedFSPermission = new FsPermission(HiveConf.getVar(conf,
@@ -488,20 +531,13 @@ public void testSessionScratchDirs() throws Exception {
     // Downloaded resources dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.DOWNLOADED_RESOURCES_DIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
-    hs2Conn.close();
+    conn.close();
 
     // 2. Test with doAs=true
-    // Restart HiveServer2 with doAs=true
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
-    conf.setBoolean("hive.server2.enable.doAs", true);
-    // Start HS2
-    miniHS2 = new MiniHS2(conf);
-    miniHS2.start(confOverlay);
+    sessionConf="hive.server2.enable.doAs=true";
     // Test for user "neo"
     userName = "neo";
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), userName, "the-one");
+    conn = getConnection(miniHS2.getJdbcURL(testDbName, sessionConf), userName, "the-one");
 
     // Verify scratch dir paths and permission
     // HDFS scratch dir
@@ -515,45 +551,32 @@ public void testSessionScratchDirs() throws Exception {
     // Downloaded resources dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.DOWNLOADED_RESOURCES_DIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
-    hs2Conn.close();
-
-    // Test for user "trinity"
-    userName = "trinity";
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), userName, "the-one");
-
-    // Verify scratch dir paths and permission
-    // HDFS scratch dir
-    scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR) + "/" + userName);
-    verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, false);
-
-    // Local scratch dir
-    scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.LOCALSCRATCHDIR));
-    verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
+    conn.close();
 
-    // Downloaded resources dir
-    scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.DOWNLOADED_RESOURCES_DIR));
-    verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
+    // Restore original state
+    restoreMiniHS2AndConnections();
   }
 
-  /** Test UDF whitelist
-   *   - verify default value
-   *   - verify udf allowed with default whitelist
-   *   - verify udf allowed with specific whitelist
-   *   - verify udf disallowed when not in whitelist
+
+  /**
+   * Test UDF whitelist
+   * - verify default value
+   * - verify udf allowed with default whitelist
+   * - verify udf allowed with specific whitelist
+   * - verify udf disallowed when not in whitelist
    * @throws Exception
    */
   @Test
-  public void testUdfWhiteList() throws Exception {
+  public void testUdfWhiteBlackList() throws Exception {
     HiveConf testConf = new HiveConf();
     assertTrue(testConf.getVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_WHITELIST).isEmpty());
     // verify that udf in default whitelist can be executed
-    hs2Conn = getConnection();
-    Statement stmt = hs2Conn.createStatement();
+    Statement stmt = conDefault.createStatement();
     stmt.executeQuery("SELECT substr('foobar', 4) ");
-    hs2Conn.close();
-    miniHS2.stop();
+    stmt.close();
 
     // setup whitelist
+    stopMiniHS2();
     Set<String> funcNames = FunctionRegistry.getFunctionNames();
     funcNames.remove("reflect");
     String funcNameStr = "";
@@ -562,14 +585,12 @@ public void testUdfWhiteList() throws Exception {
     }
     funcNameStr = funcNameStr.substring(1); // remove ',' at begining
     testConf.setVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_WHITELIST, funcNameStr);
-    miniHS2 = new MiniHS2(testConf);
-    miniHS2.start(new HashMap<String, String>());
-
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
-    stmt = hs2Conn.createStatement();
+    startMiniHS2(testConf);
+    Connection conn =
+        getConnection(miniHS2.getJdbcURL(testDbName), System.getProperty("user.name"), "bar");
+    stmt = conn.createStatement();
     // verify that udf in whitelist can be executed
     stmt.executeQuery("SELECT substr('foobar', 3) ");
-
     // verify that udf not in whitelist fails
     try {
       stmt.executeQuery("SELECT reflect('java.lang.String', 'valueOf', 1) ");
@@ -577,6 +598,10 @@ public void testUdfWhiteList() throws Exception {
     } catch (SQLException e) {
       // expected
     }
+    conn.close();
+
+    // Restore original state
+    restoreMiniHS2AndConnections();
   }
 
   /** Test UDF blacklist
@@ -589,18 +614,16 @@ public void testUdfWhiteList() throws Exception {
   public void testUdfBlackList() throws Exception {
     HiveConf testConf = new HiveConf();
     assertTrue(testConf.getVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_BLACKLIST).isEmpty());
-    hs2Conn = getConnection();
-    Statement stmt = hs2Conn.createStatement();
+    Statement stmt = conDefault.createStatement();
     // verify that udf in default whitelist can be executed
     stmt.executeQuery("SELECT substr('foobar', 4) ");
-    hs2Conn.close();
 
-    miniHS2.stop();
+    stopMiniHS2();
     testConf.setVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_BLACKLIST, "reflect");
-    miniHS2 = new MiniHS2(testConf);
-    miniHS2.start(new HashMap<String, String>());
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
-    stmt = hs2Conn.createStatement();
+    startMiniHS2(testConf);
+    Connection conn =
+        getConnection(miniHS2.getJdbcURL(testDbName), System.getProperty("user.name"), "bar");
+    stmt = conn.createStatement();
 
     try {
       stmt.executeQuery("SELECT reflect('java.lang.String', 'valueOf', 1) ");
@@ -608,6 +631,9 @@ public void testUdfBlackList() throws Exception {
     } catch (SQLException e) {
       // expected
     }
+    conn.close();
+    // Restore original state
+    restoreMiniHS2AndConnections();
   }
 
   /** Test UDF blacklist overrides whitelist
@@ -615,9 +641,7 @@ public void testUdfBlackList() throws Exception {
    */
   @Test
   public void testUdfBlackListOverride() throws Exception {
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
+    stopMiniHS2();
     // setup whitelist
     HiveConf testConf = new HiveConf();
 
@@ -629,11 +653,10 @@ public void testUdfBlackListOverride() throws Exception {
     funcNameStr = funcNameStr.substring(1); // remove ',' at begining
     testConf.setVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_WHITELIST, funcNameStr);
     testConf.setVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_BLACKLIST, "reflect");
-    miniHS2 = new MiniHS2(testConf);
-    miniHS2.start(new HashMap<String, String>());
-
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
-    Statement stmt = hs2Conn.createStatement();
+    startMiniHS2(testConf);
+    Connection conn =
+        getConnection(miniHS2.getJdbcURL(testDbName), System.getProperty("user.name"), "bar");
+    Statement stmt = conn.createStatement();
 
     // verify that udf in black list fails even though it's included in whitelist
     try {
@@ -642,6 +665,9 @@ public void testUdfBlackListOverride() throws Exception {
     } catch (SQLException e) {
       // expected
     }
+    conn.close();
+    // Restore original state
+    restoreMiniHS2AndConnections();
   }
 
   /**
@@ -652,19 +678,15 @@ public void testUdfBlackListOverride() throws Exception {
   @Test
   public void testRootScratchDir() throws Exception {
     // Stop HiveServer2
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
+    stopMiniHS2();
     HiveConf conf = new HiveConf();
     String userName;
     Path scratchDirPath;
     conf.set("hive.exec.scratchdir", tmpDir + "/hs2");
     // Start an instance of HiveServer2 which uses miniMR
-    miniHS2 = new MiniHS2(conf);
-    Map<String, String> confOverlay = new HashMap<String, String>();
-    miniHS2.start(confOverlay);
+    startMiniHS2(conf);
     userName = System.getProperty("user.name");
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), userName, "password");
+    Connection conn = getConnection(miniHS2.getJdbcURL(testDbName), userName, "password");
     // FS
     FileSystem fs = miniHS2.getLocalFS();
     FsPermission expectedFSPermission = new FsPermission((short)00733);
@@ -672,19 +694,20 @@ public void testRootScratchDir() throws Exception {
     // HDFS scratch dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, false);
-    hs2Conn.close();
+    conn.close();
 
     // Test with multi-level scratch dir path
     // Stop HiveServer2
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
+    stopMiniHS2();
     conf.set("hive.exec.scratchdir", tmpDir + "/level1/level2/level3");
-    miniHS2 = new MiniHS2(conf);
-    miniHS2.start(confOverlay);
-    hs2Conn = getConnection(miniHS2.getJdbcURL(), userName, "password");
+    startMiniHS2(conf);
+    conn = getConnection(miniHS2.getJdbcURL(testDbName), userName, "password");
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, false);
+    conn.close();
+
+    // Restore original state
+    restoreMiniHS2AndConnections();
   }
 
   private void verifyScratchDir(HiveConf conf, FileSystem fs, Path scratchDirPath,
@@ -699,59 +722,259 @@ private void verifyScratchDir(HiveConf conf, FileSystem fs, Path scratchDirPath,
   }
 
   /**
-   * Tests that Hadoop's ReflectionUtils.CONSTRUCTOR_CACHE clears cached class objects (& hence
-   * doesn't leak classloaders) on closing any session
+   * Tests ADD JAR uses Hives ReflectionUtil.CONSTRUCTOR_CACHE
    *
    * @throws Exception
    */
   @Test
   public void testAddJarConstructorUnCaching() throws Exception {
-    Path jarFilePath = new Path(dataFileDir, "identity_udf.jar");
-    Connection conn = getConnection(miniHS2.getJdbcURL(), "foo", "bar");
-    String tableName = "testAddJar";
-    Statement stmt = conn.createStatement();
-    stmt.execute("SET hive.support.concurrency = false");
-    // Create table
-    stmt.execute("DROP TABLE IF EXISTS " + tableName);
-    stmt.execute("CREATE TABLE " + tableName + " (key INT, value STRING)");
-    // Load data
-    stmt.execute("LOAD DATA LOCAL INPATH '" + kvDataFilePath.toString() + "' INTO TABLE "
-        + tableName);
-    ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
-    // Ensure table is populated
-    assertTrue(res.next());
+    // This test assumes the hive-contrib JAR has been built as part of the Hive build.
+    // Also dependent on the UDFExampleAdd class within that JAR.
+    setReflectionUtilCache();
+    Path jarFilePath = getHiveContribJarPath();
+    long cacheBeforeAddJar, cacheAfterClose;
+    // Force the cache clear so we know its empty
+    invalidateReflectionUtlCache();
+    cacheBeforeAddJar = getReflectionUtilCacheSize();
+    System.out.println("CONSTRUCTOR_CACHE size before add jar: " + cacheBeforeAddJar);
+    System.out.println("CONSTRUCTOR_CACHE as map before add jar:" + getReflectionUtilCache().asMap());
+    Assert.assertTrue("FAILED: CONSTRUCTOR_CACHE size before add jar: " + cacheBeforeAddJar,
+            cacheBeforeAddJar == 0);
 
-    int cacheBeforeClose;
-    int cacheAfterClose;
     // Add the jar file
+    Statement stmt = conTestDb.createStatement();
     stmt.execute("ADD JAR " + jarFilePath.toString());
     // Create a temporary function using the jar
-    stmt.execute("CREATE TEMPORARY FUNCTION func AS 'IdentityStringUDF'");
+    stmt.execute("CREATE TEMPORARY FUNCTION add_func AS '" + testUdfClassName + "'");
     // Execute the UDF
-    stmt.execute("SELECT func(value) from " + tableName);
-    cacheBeforeClose = getReflectionUtilsCacheSize();
-    System.out.println("Cache before connection close: " + cacheBeforeClose);
-    // Cache size should be > 0 now
-    Assert.assertTrue(cacheBeforeClose > 0);
-    conn.close();
-    cacheAfterClose = getReflectionUtilsCacheSize();
-    System.out.println("Cache after connection close: " + cacheAfterClose);
-    // Cache size should be 0 now
-    Assert.assertTrue("Failed: " + cacheAfterClose, cacheAfterClose == 0);
+    ResultSet res = stmt.executeQuery("SELECT add_func(int_col, 1) from " + tableName + " limit 1");
+    assertTrue(res.next());
+    TimeUnit.SECONDS.sleep(7);
+    // Have to force a cleanup of all expired entries here because its possible that the
+    // expired entries will still be counted in Cache.size().
+    // Taken from:
+    // http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/CacheBuilder.html
+    cleanUpReflectionUtlCache();
+    cacheAfterClose = getReflectionUtilCacheSize();
+    System.out.println("CONSTRUCTOR_CACHE size after connection close: " + cacheAfterClose);
+    Assert.assertTrue("FAILED: CONSTRUCTOR_CACHE size after connection close: " + cacheAfterClose,
+            cacheAfterClose == 0);
+    stmt.execute("DROP TEMPORARY FUNCTION IF EXISTS add_func");
+    stmt.close();
+  }
+
+  private void setReflectionUtilCache() {
+    Field constructorCacheField;
+    Cache<Class<?>, Constructor<?>> tmp;
+    try {
+      constructorCacheField = ReflectionUtils.class.getDeclaredField("CONSTRUCTOR_CACHE");
+      if (constructorCacheField != null) {
+        constructorCacheField.setAccessible(true);
+        Field modifiersField = Field.class.getDeclaredField("modifiers");
+        modifiersField.setAccessible(true);
+        modifiersField.setInt(constructorCacheField, constructorCacheField.getModifiers()
+            & ~Modifier.FINAL);
+        tmp =
+            CacheBuilder.newBuilder().expireAfterAccess(5, TimeUnit.SECONDS).concurrencyLevel(64)
+                .weakKeys().weakValues().build();
+        constructorCacheField.set(tmp.getClass(), tmp);
+      }
+    } catch (Exception e) {
+      System.out.println("Error when setting the CONSTRUCTOR_CACHE to expire: " + e);
+    }
+  }
+
+  private Cache getReflectionUtilCache() {
+    Field constructorCacheField;
+    try {
+      constructorCacheField = ReflectionUtils.class.getDeclaredField("CONSTRUCTOR_CACHE");
+      if (constructorCacheField != null) {
+        constructorCacheField.setAccessible(true);
+        return (Cache) constructorCacheField.get(null);
+      }
+    } catch (Exception e) {
+      System.out.println("Error when getting the CONSTRUCTOR_CACHE var: " + e);
+    }
+    return null;
   }
 
-  // Call ReflectionUtils#getCacheSize (which is private)
-  private int getReflectionUtilsCacheSize() {
-    Method getCacheSizeMethod;
+  private void invalidateReflectionUtlCache() {
     try {
-      getCacheSizeMethod = ReflectionUtils.class.getDeclaredMethod("getCacheSize");
-      if (getCacheSizeMethod != null) {
-        getCacheSizeMethod.setAccessible(true);
-        return (Integer) getCacheSizeMethod.invoke(null);
+      Cache constructorCache = getReflectionUtilCache();
+      if (constructorCache != null) {
+        constructorCache.invalidateAll();
+      }
+    } catch (Exception e) {
+      System.out.println("Error when trying to invalidate the cache: " + e);
+    }
+  }
+
+  private void cleanUpReflectionUtlCache() {
+    try {
+      Cache constructorCache = getReflectionUtilCache();
+      if (constructorCache != null) {
+        constructorCache.cleanUp();
+      }
+    } catch (Exception e) {
+      System.out.println("Error when trying to cleanUp the cache: " + e);
+    }
+  }
+
+  private long getReflectionUtilCacheSize() {
+    try {
+      Cache constructorCache = getReflectionUtilCache();
+      if (constructorCache != null) {
+        return constructorCache.size();
       }
     } catch (Exception e) {
       System.out.println(e);
     }
     return -1;
   }
+
+  @Test
+  public void testPermFunc() throws Exception {
+    // This test assumes the hive-contrib JAR has been built as part of the Hive build.
+    // Also dependent on the UDFExampleAdd class within that JAR.
+    Path jarFilePath = getHiveContribJarPath();
+    Statement stmt = conTestDb.createStatement();
+    ResultSet res;
+    // Add the jar file
+    stmt.execute("ADD JAR " + jarFilePath.toString());
+
+    // Register function
+    String queryStr =
+        "CREATE FUNCTION example_add AS '" + testUdfClassName + "' USING JAR '" + jarFilePath + "'";
+    stmt.execute(queryStr);
+
+    // Call describe
+    res = stmt.executeQuery("DESCRIBE FUNCTION " + testDbName + ".example_add");
+    checkForNotExist(res);
+
+    // Use UDF in query
+    res = stmt.executeQuery("SELECT example_add(1, 2) FROM " + tableName + " LIMIT 1");
+    assertTrue("query has results", res.next());
+    assertEquals(3, res.getInt(1));
+    assertFalse("no more results", res.next());
+
+    // A new connection should be able to call describe/use function without issue
+    Connection conn2 = getConnection(testDbName);
+    Statement stmt2 = conn2.createStatement();
+    stmt2.execute("USE " + testDbName);
+    res = stmt2.executeQuery("DESCRIBE FUNCTION " + testDbName + ".example_add");
+    checkForNotExist(res);
+
+    res =
+        stmt2.executeQuery("SELECT " + testDbName + ".example_add(1, 1) FROM " + tableName
+            + " LIMIT 1");
+    assertTrue("query has results", res.next());
+    assertEquals(2, res.getInt(1));
+    assertFalse("no more results", res.next());
+    conn2.close();
+    stmt.execute("DROP FUNCTION IF EXISTS " + testDbName + ".example_add");
+    stmt.close();
+  }
+
+  private Path getHiveContribJarPath() {
+    String mvnRepo = System.getProperty("maven.local.repository");
+    String hiveVersion = System.getProperty("hive.version");
+    String jarFileName = "hive-contrib-" + hiveVersion + ".jar";
+    String[] pathParts = {
+        "org", "apache", "hive",
+        "hive-contrib", hiveVersion, jarFileName
+    };
+
+    // Create path to hive-contrib JAR on local filesystem
+    Path jarFilePath = new Path(mvnRepo);
+    for (String pathPart : pathParts) {
+      jarFilePath = new Path(jarFilePath, pathPart);
+    }
+    return jarFilePath;
+  }
+
+  @Test
+  public void testTempTable() throws Exception {
+    // Create temp table with current connection
+    String tempTableName = "tmp1";
+    Statement stmt = conTestDb.createStatement();
+    stmt.execute("CREATE TEMPORARY TABLE " + tempTableName + " (key string, value string)");
+    stmt.execute("load data local inpath '" + kvDataFilePath.toString() + "' into table "
+        + tempTableName);
+
+    String resultVal = "val_238";
+    String queryStr = "SELECT * FROM " + tempTableName + " where value = '" + resultVal + "'";
+
+    ResultSet res = stmt.executeQuery(queryStr);
+    assertTrue(res.next());
+    assertEquals(resultVal, res.getString(2));
+    res.close();
+    stmt.close();
+
+    // Test getTables()
+    DatabaseMetaData md = conTestDb.getMetaData();
+    assertTrue(md.getConnection() == conTestDb);
+
+    ResultSet rs = md.getTables(null, null, tempTableName, null);
+    boolean foundTable = false;
+    while (rs.next()) {
+      String tableName = rs.getString(3);
+      if (tableName.equalsIgnoreCase(tempTableName)) {
+        assertFalse("Table not found yet", foundTable);
+        foundTable = true;
+      }
+    }
+    assertTrue("Found temp table", foundTable);
+
+    // Test getTables() with no table name pattern
+    rs = md.getTables(null, null, null, null);
+    foundTable = false;
+    while (rs.next()) {
+      String tableName = rs.getString(3);
+      if (tableName.equalsIgnoreCase(tempTableName)) {
+        assertFalse("Table not found yet", foundTable);
+        foundTable = true;
+      }
+    }
+    assertTrue("Found temp table", foundTable);
+
+    // Test getColumns()
+    rs = md.getColumns(null, null, tempTableName, null);
+    assertTrue("First row", rs.next());
+    assertTrue(rs.getString(3).equalsIgnoreCase(tempTableName));
+    assertTrue(rs.getString(4).equalsIgnoreCase("key"));
+    assertEquals(Types.VARCHAR, rs.getInt(5));
+
+    assertTrue("Second row", rs.next());
+    assertTrue(rs.getString(3).equalsIgnoreCase(tempTableName));
+    assertTrue(rs.getString(4).equalsIgnoreCase("value"));
+    assertEquals(Types.VARCHAR, rs.getInt(5));
+
+    // A second connection should not be able to see the table
+    Connection conn2 =
+        DriverManager.getConnection(miniHS2.getJdbcURL(testDbName),
+            System.getProperty("user.name"), "bar");
+    Statement stmt2 = conn2.createStatement();
+    stmt2.execute("USE " + testDbName);
+    boolean gotException = false;
+    try {
+      res = stmt2.executeQuery(queryStr);
+    } catch (SQLException err) {
+      // This is expected to fail.
+      assertTrue("Expecting table not found error, instead got: " + err,
+          err.getMessage().contains("Table not found"));
+      gotException = true;
+    }
+    assertTrue("Exception while querying non-existing temp table", gotException);
+    conn2.close();
+  }
+
+  private void checkForNotExist(ResultSet res) throws Exception {
+    int numRows = 0;
+    while (res.next()) {
+      numRows++;
+      String strVal = res.getString(1);
+      assertEquals("Should not find 'not exist'", -1, strVal.toLowerCase().indexOf("not exist"));
+    }
+    assertTrue("Rows returned from describe function", numRows > 0);
+  }
 }
-- 
1.7.9.5

