From dfdb2569a903ebfc05cd0953589a799b860bb798 Mon Sep 17 00:00:00 2001
From: Szehon Ho <szehon@apache.org>
Date: Fri, 10 Apr 2015 19:34:19 +0000
Subject: [PATCH 0113/1164] HIVE-10291 : Hive on Spark job configuration needs
 to be logged [Spark Branch] (Szehon, reviewed by
 Chengxiang and Xuefu)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1672733 13f79535-47bb-0310-9956-ffa450edef68
---
 .../hive/ql/exec/spark/RemoteHiveSparkClient.java  |   17 ++++++++++++++++-
 1 file changed, 16 insertions(+), 1 deletion(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/RemoteHiveSparkClient.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/RemoteHiveSparkClient.java
index 6701a29..059016d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/RemoteHiveSparkClient.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/RemoteHiveSparkClient.java
@@ -22,6 +22,7 @@
 
 import java.io.IOException;
 import java.io.Serializable;
+import java.io.StringWriter;
 import java.net.URI;
 import java.net.URISyntaxException;
 import java.util.ArrayList;
@@ -33,6 +34,7 @@
 import org.apache.commons.lang.StringUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -231,6 +233,7 @@ public Serializable call(JobContext jc) throws Exception {
 
       Path localScratchDir = KryoSerializer.deserialize(scratchDirBytes, Path.class);
       SparkWork localSparkWork = KryoSerializer.deserialize(sparkWorkBytes, SparkWork.class);
+      logConfigurations(localJobConf);
 
       SparkCounters sparkCounters = new SparkCounters(jc.sc());
       Map<String, List<String>> prefixes = localSparkWork.getRequiredCounterPrefix();
@@ -255,6 +258,18 @@ public Serializable call(JobContext jc) throws Exception {
       jc.monitor(future, sparkCounters, plan.getCachedRDDIds());
       return null;
     }
-  }
 
+    private void logConfigurations(JobConf localJobConf) {
+      if (LOG.isInfoEnabled()) {
+        LOG.info("Logging job configuration: ");
+        StringWriter outWriter = new StringWriter();
+        try {
+          Configuration.dumpConfiguration(localJobConf, outWriter);
+        } catch (IOException e) {
+          LOG.warn("Error logging job configuration", e);
+        }
+        LOG.info(outWriter.toString());
+      }
+    }
+  }
 }
-- 
1.7.9.5

