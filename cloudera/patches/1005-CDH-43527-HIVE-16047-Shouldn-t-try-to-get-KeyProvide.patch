From 7f8e9e83794424e70483ef741503ec4b16feef71 Mon Sep 17 00:00:00 2001
From: Rui Li <lirui@apache.org>
Date: Wed, 1 Mar 2017 11:16:27 +0800
Subject: [PATCH 1005/1164] CDH-43527: HIVE-16047: Shouldn't try to get
 KeyProvider unless encryption is enabled (Rui
 reviewed by Xuefu and Ferdinand)

(cherry picked from commit a9de1cdbb9ffeef43dbee3db1712845f015ac108)

Change-Id: Id7be26ad7b508d75c4af9fac55b69d759646f7e8
---
 .../apache/hadoop/hive/shims/Hadoop23Shims.java    |   16 +++++++++++++++-
 1 file changed, 15 insertions(+), 1 deletion(-)

diff --git a/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java b/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
index 360304b..9d1fd32 100644
--- a/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
+++ b/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
@@ -61,6 +61,8 @@
 import org.apache.hadoop.fs.permission.AclStatus;
 import org.apache.hadoop.fs.permission.FsAction;
 import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.hdfs.DFSClient;
+import org.apache.hadoop.hdfs.DFSConfigKeys;
 import org.apache.hadoop.hdfs.DistributedFileSystem;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
 import org.apache.hadoop.hdfs.protocol.HdfsConstants;
@@ -1259,10 +1261,22 @@ public HdfsEncryptionShim(URI uri, Configuration conf) throws IOException {
       DistributedFileSystem dfs = (DistributedFileSystem)FileSystem.get(uri, conf);
 
       this.conf = conf;
-      this.keyProvider = dfs.getClient().getKeyProvider();
+      this.keyProvider = isEncryptionEnabled(dfs.getClient(), dfs.getConf()) ?
+          dfs.getClient().getKeyProvider() : null;
       this.hdfsAdmin = new HdfsAdmin(uri, conf);
     }
 
+    private boolean isEncryptionEnabled(DFSClient client, Configuration conf) {
+      try {
+        DFSClient.class.getMethod("isHDFSEncryptionEnabled");
+      } catch (NoSuchMethodException e) {
+        // the method is available since Hadoop-2.7.1
+        // if we run with an older Hadoop, check this ourselves
+        return !conf.getTrimmed(DFSConfigKeys.DFS_ENCRYPTION_KEY_PROVIDER_URI, "").isEmpty();
+      }
+      return client.isHDFSEncryptionEnabled();
+    }
+
     @Override
     public boolean isPathEncrypted(Path path) throws IOException {
       Path fullPath;
-- 
1.7.9.5

