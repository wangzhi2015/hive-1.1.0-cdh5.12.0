From 0c34415085b38fc656aaea4aa56706cc217eeb7b Mon Sep 17 00:00:00 2001
From: Zsombor Klara <zsombor.klara@cloudera.com>
Date: Fri, 20 Jan 2017 16:43:53 +0100
Subject: [PATCH 0944/1164] CDH-48506: HIVE-9869: Trunk doesn't build with
 hadoop-1 (Rui via Xuefu, reviewed by Ashutosh)

Change-Id: I150ac52e180e6ab7e9a1672599c5879ee5c6f2ae
---
 .../hadoop/hive/ql/plan/ptf/PTFInputDef.java       |    4 ++--
 .../apache/hadoop/hive/ql/exec/TestExecDriver.java |    6 ++++--
 2 files changed, 6 insertions(+), 4 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
index 95296c0..20535bc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
@@ -19,9 +19,9 @@
 package org.apache.hadoop.hive.ql.plan.ptf;
 
 
+import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.hive.ql.exec.RowSchema;
 import org.apache.hadoop.hive.ql.plan.Explain;
-import org.apache.hadoop.util.StringUtils;
 
 public abstract class PTFInputDef {
   private String expressionTreeString;
@@ -43,7 +43,7 @@ public ShapeDetails getOutputShape() {
   @Explain(displayName = "output shape")
   public String getOutputShapeExplain() {
     RowSchema schema = outputShape.getRr().getRowSchema();
-    return StringUtils.join(", ", schema.getSignature());
+    return StringUtils.join(schema.getSignature(), ", ");
   }
 
   public void setOutputShape(ShapeDetails outputShape) {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
index 41862e6..0592234 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
@@ -60,6 +60,7 @@
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.shims.ShimLoader;
 import org.apache.hadoop.mapred.TextInputFormat;
 import org.apache.hadoop.util.Shell;
 
@@ -94,7 +95,8 @@
       tmppath = new Path(tmpdir);
 
       fs = FileSystem.get(conf);
-      if (fs.exists(tmppath) && !fs.getFileStatus(tmppath).isDir()) {
+      if (fs.exists(tmppath) &&
+          !ShimLoader.getHadoopShims().isDirectory(fs.getFileStatus(tmppath))) {
         throw new RuntimeException(tmpdir + " exists but is not a directory");
       }
 
@@ -169,7 +171,7 @@ private static void fileDiff(String datafile, String testdir) throws Exception {
     if (!fs.exists(di_test)) {
       throw new RuntimeException(tmpdir + File.separator + testdir + " does not exist");
     }
-    if (!fs.getFileStatus(di_test).isDir()) {
+    if (!ShimLoader.getHadoopShims().isDirectory(fs.getFileStatus(di_test))) {
       throw new RuntimeException(tmpdir + File.separator + testdir + " is not a directory");
     }
     FSDataInputStream fi_test = fs.open((fs.listStatus(di_test))[0].getPath());
-- 
1.7.9.5

