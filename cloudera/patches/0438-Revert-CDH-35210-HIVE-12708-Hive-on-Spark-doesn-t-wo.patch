From a76b1607c49eea64280220deca65fa1d9b33e73e Mon Sep 17 00:00:00 2001
From: Xuefu Zhang <xzhang@Cloudera.com>
Date: Tue, 22 Dec 2015 10:36:29 -0800
Subject: [PATCH 0438/1164] Revert CDH-35210: HIVE-12708: Hive on Spark
 doesn't work with Kerboresed HBase [Spark Branch]
 (reviewed by Szehon)

Change-Id: Ic637a62a67df229a1d72e6cf9a5cd459b857d676
---
 ql/pom.xml                                         |   10 ----------
 .../hive/ql/exec/spark/HiveSparkClientFactory.java |   11 -----------
 2 files changed, 21 deletions(-)

diff --git a/ql/pom.xml b/ql/pom.xml
index 40fe777..08917d3 100644
--- a/ql/pom.xml
+++ b/ql/pom.xml
@@ -514,11 +514,6 @@
           <version>${hadoop-20S.version}</version>
           <optional>true</optional>
         </dependency>
-        <dependency>
-          <groupId>org.apache.hbase</groupId>
-          <artifactId>hbase-common</artifactId>
-          <version>${hbase.hadoop1.version}</version>
-        </dependency>
       </dependencies>
     </profile>
     <profile>
@@ -567,11 +562,6 @@
          <version>${hadoop-23.version}</version>
          <optional>true</optional>
        </dependency>
-        <dependency>
-          <groupId>org.apache.hbase</groupId>
-          <artifactId>hbase-common</artifactId>
-          <version>${hbase.hadoop2.version}</version>
-        </dependency>
       </dependencies>
     </profile>
     <profile>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
index 4e8226b..efd9f39 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
@@ -29,7 +29,6 @@
 import org.apache.commons.compress.utils.CharsetNames;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;
 import org.apache.hadoop.hive.ql.io.HiveKey;
@@ -66,7 +65,6 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
 
   public static Map<String, String> initiateSparkConf(HiveConf hiveConf) {
     Map<String, String> sparkConf = new HashMap<String, String>();
-    HBaseConfiguration.addHbaseResources(hiveConf);
 
     // set default spark configurations.
     sparkConf.put("spark.master", SPARK_DEFAULT_MASTER);
@@ -134,16 +132,7 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
         LOG.info(String.format(
           "load yarn property from hive configuration in %s mode (%s -> %s).",
           sparkMaster, propertyName, value));
-      } else if (propertyName.startsWith("hbase")) {
-        // Add HBase related configuration to Spark because in security mode, Spark needs it
-        // to generate hbase delegation token for Spark. This is a temp solution to deal with
-        // Spark problem.
-        String value = hiveConf.get(propertyName);
-        sparkConf.put("spark.hadoop." + propertyName, value);
-        LOG.info(String.format(
-          "load HBase configuration (%s -> %s).", propertyName, value));
       }
-
       if (RpcConfiguration.HIVE_SPARK_RSC_CONFIGS.contains(propertyName)) {
         String value = RpcConfiguration.getValue(hiveConf, propertyName);
         sparkConf.put(propertyName, value);
-- 
1.7.9.5

