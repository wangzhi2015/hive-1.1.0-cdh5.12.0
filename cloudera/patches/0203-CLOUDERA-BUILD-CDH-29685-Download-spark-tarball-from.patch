From c11a0b4f7b169e4638b4a75cb14848ab70856976 Mon Sep 17 00:00:00 2001
From: xzhang <xzhang@xzdt>
Date: Wed, 22 Jul 2015 21:19:09 -0700
Subject: [PATCH 0203/1164] CLOUDERA-BUILD: CDH-29685: Download spark tarball
 from nightly repo

---
 itests/pom.xml                                     |    4 +--
 itests/qtest-spark/pom.xml                         |   31 ++++++++++++++++++++
 .../exec/spark/status/impl/JobMetricsListener.java |    4 +--
 .../org/apache/hive/spark/client/RemoteDriver.java |    4 +--
 4 files changed, 37 insertions(+), 6 deletions(-)

diff --git a/itests/pom.xml b/itests/pom.xml
index 3a61fd1..ccccd50 100644
--- a/itests/pom.xml
+++ b/itests/pom.xml
@@ -88,10 +88,10 @@
                      curl -Sso $DOWNLOAD_DIR/$tarName $url
                     fi
                     tar -zxf $DOWNLOAD_DIR/$tarName -C $BASE_DIR
-                    mv $BASE_DIR/spark-${spark.version}-bin-hadoop2-without-hive $BASE_DIR/$finalName
+                    mv $BASE_DIR/spark-${spark.version} $BASE_DIR/$finalName
                   }
                   mkdir -p $DOWNLOAD_DIR
-                  download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-${spark.version}-bin-hadoop2-without-hive.tgz" "spark"
+                  download "http://repos.jenkins.cloudera.com/cdh5.5.0-static/cdh/5/spark-latest.tar.gz" "spark"
                   cp -f $HIVE_ROOT/data/conf/spark/log4j.properties $BASE_DIR/spark/conf/
                 </echo>
               </target>
diff --git a/itests/qtest-spark/pom.xml b/itests/qtest-spark/pom.xml
index c55a816..0dd5d18 100644
--- a/itests/qtest-spark/pom.xml
+++ b/itests/qtest-spark/pom.xml
@@ -285,6 +285,37 @@
   <build>
     <plugins>
       <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-dependency-plugin</artifactId>
+        <version>2.10</version>
+        <executions>
+          <execution>
+            <phase>test-compile</phase>
+            <goals>
+              <goal>build-classpath</goal>
+            </goals>
+            <configuration>
+              <includeScope>test</includeScope>
+              <outputProperty>test_classpath</outputProperty>
+            </configuration>
+          </execution>
+        </executions>
+      </plugin>
+      <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-surefire-plugin</artifactId>
+        <version>2.18</version>
+        <configuration>
+          <environmentVariables>
+            <!--
+              Setting SPARK_DIST_CLASSPATH is a simple way to make sure any child processes
+              launched by the tests have access to the correct test-time classpath.
+            -->
+            <SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>
+          </environmentVariables>
+        </configuration>
+      </plugin>
+      <plugin>
         <groupId>org.codehaus.mojo</groupId>
         <artifactId>properties-maven-plugin</artifactId>
         <version>1.0-alpha-2</version>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/status/impl/JobMetricsListener.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/status/impl/JobMetricsListener.java
index 51772cd..8d57916 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/status/impl/JobMetricsListener.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/status/impl/JobMetricsListener.java
@@ -23,8 +23,8 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.spark.JavaSparkListener;
 import org.apache.spark.executor.TaskMetrics;
-import org.apache.spark.scheduler.SparkListener;
 import org.apache.spark.scheduler.SparkListenerApplicationEnd;
 import org.apache.spark.scheduler.SparkListenerApplicationStart;
 import org.apache.spark.scheduler.SparkListenerBlockManagerAdded;
@@ -45,7 +45,7 @@
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
-public class JobMetricsListener implements SparkListener {
+public class JobMetricsListener extends JavaSparkListener {
 
   private static final Log LOG = LogFactory.getLog(JobMetricsListener.class);
 
diff --git a/spark-client/src/main/java/org/apache/hive/spark/client/RemoteDriver.java b/spark-client/src/main/java/org/apache/hive/spark/client/RemoteDriver.java
index b77c9e8..fb0554c 100644
--- a/spark-client/src/main/java/org/apache/hive/spark/client/RemoteDriver.java
+++ b/spark-client/src/main/java/org/apache/hive/spark/client/RemoteDriver.java
@@ -43,10 +43,10 @@
 import org.apache.hive.spark.client.rpc.Rpc;
 import org.apache.hive.spark.client.rpc.RpcConfiguration;
 import org.apache.hive.spark.counter.SparkCounters;
+import org.apache.spark.JavaSparkListener;
 import org.apache.spark.SparkConf;
 import org.apache.spark.api.java.JavaFutureAction;
 import org.apache.spark.api.java.JavaSparkContext;
-import org.apache.spark.scheduler.SparkListener;
 import org.apache.spark.scheduler.SparkListenerApplicationEnd;
 import org.apache.spark.scheduler.SparkListenerApplicationStart;
 import org.apache.spark.scheduler.SparkListenerBlockManagerAdded;
@@ -438,7 +438,7 @@ private void monitorJob(JavaFutureAction<?> job,
 
   }
 
-  private class ClientListener implements SparkListener {
+  private class ClientListener extends JavaSparkListener {
 
     private final Map<Integer, Integer> stageToJobId = Maps.newHashMap();
 
-- 
1.7.9.5

