From d583b3ad5f732d55910e9a3577cf6562545bf694 Mon Sep 17 00:00:00 2001
From: chengxiang <chengxiang@unknown>
Date: Fri, 27 Mar 2015 06:36:41 +0000
Subject: [PATCH 0102/1164] HIVE-10073:Runtime exception when querying HBase
 with Spark [Spark Branch](Jimmy Xiang via
 chengxiang)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1669518 13f79535-47bb-0310-9956-ffa450edef68
---
 .../hive/ql/exec/spark/SparkPlanGenerator.java     |   13 +++++++++++++
 1 file changed, 13 insertions(+)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java
index 3518edc..abe5a60 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java
@@ -21,6 +21,7 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
 
 import com.google.common.base.Preconditions;
 
@@ -36,6 +37,8 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.Context;
 import org.apache.hadoop.hive.ql.ErrorMsg;
+import org.apache.hadoop.hive.ql.exec.FileSinkOperator;
+import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.exec.mr.ExecMapper;
 import org.apache.hadoop.hive.ql.exec.mr.ExecReducer;
@@ -199,6 +202,7 @@ private ShuffleTran generate(SparkPlan sparkPlan, SparkEdgeProperty edge, boolea
   private SparkTran generate(BaseWork work) throws Exception {
     initStatsPublisher(work);
     JobConf newJobConf = cloneJobConf(work);
+    checkSpecs(work, newJobConf);
     byte[] confBytes = KryoSerializer.serializeJobConf(newJobConf);
     if (work instanceof MapWork) {
       MapTran mapTran = new MapTran();
@@ -216,6 +220,15 @@ private SparkTran generate(BaseWork work) throws Exception {
     }
   }
 
+  private void checkSpecs(BaseWork work, JobConf jc) throws Exception {
+    Set<Operator<?>> opList = work.getAllOperators();
+    for (Operator<?> op : opList) {
+      if (op instanceof FileSinkOperator) {
+        ((FileSinkOperator) op).checkOutputSpecs(null, jc);
+      }
+    }
+  }
+
   @SuppressWarnings({ "unchecked" })
   private JobConf cloneJobConf(BaseWork work) throws Exception {
     if (workToJobConf.containsKey(work)) {
-- 
1.7.9.5

