From 364816b206924cfb37d6460e359fd0cb573cc4f0 Mon Sep 17 00:00:00 2001
From: xzhang <xzhang@xzdt>
Date: Tue, 5 Jan 2016 15:06:44 -0800
Subject: [PATCH 0447/1164] CDH-35210: HIVE-12708: Hive on Spark doesn't work
 with Kerboresed HBase [Spark Branch] (reviewed by
 Szehon)

Change-Id: Icbe7d328aa6eec770ecb873e09f93495f920e695
---
 ql/pom.xml                                         |   10 ++++++++++
 .../hive/ql/exec/spark/HiveSparkClientFactory.java |   11 +++++++++++
 2 files changed, 21 insertions(+)

diff --git a/ql/pom.xml b/ql/pom.xml
index 640bcb2..6622a88 100644
--- a/ql/pom.xml
+++ b/ql/pom.xml
@@ -520,6 +520,11 @@
           <version>${hadoop-20S.version}</version>
           <optional>true</optional>
         </dependency>
+        <dependency>
+          <groupId>org.apache.hbase</groupId>
+          <artifactId>hbase-common</artifactId>
+          <version>${hbase.hadoop1.version}</version>
+        </dependency>
       </dependencies>
     </profile>
     <profile>
@@ -568,6 +573,11 @@
          <version>${hadoop-23.version}</version>
          <optional>true</optional>
        </dependency>
+        <dependency>
+          <groupId>org.apache.hbase</groupId>
+          <artifactId>hbase-common</artifactId>
+          <version>${hbase.hadoop2.version}</version>
+        </dependency>
       </dependencies>
     </profile>
     <profile>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
index efd9f39..4e8226b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
@@ -29,6 +29,7 @@
 import org.apache.commons.compress.utils.CharsetNames;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;
 import org.apache.hadoop.hive.ql.io.HiveKey;
@@ -65,6 +66,7 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
 
   public static Map<String, String> initiateSparkConf(HiveConf hiveConf) {
     Map<String, String> sparkConf = new HashMap<String, String>();
+    HBaseConfiguration.addHbaseResources(hiveConf);
 
     // set default spark configurations.
     sparkConf.put("spark.master", SPARK_DEFAULT_MASTER);
@@ -132,7 +134,16 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
         LOG.info(String.format(
           "load yarn property from hive configuration in %s mode (%s -> %s).",
           sparkMaster, propertyName, value));
+      } else if (propertyName.startsWith("hbase")) {
+        // Add HBase related configuration to Spark because in security mode, Spark needs it
+        // to generate hbase delegation token for Spark. This is a temp solution to deal with
+        // Spark problem.
+        String value = hiveConf.get(propertyName);
+        sparkConf.put("spark.hadoop." + propertyName, value);
+        LOG.info(String.format(
+          "load HBase configuration (%s -> %s).", propertyName, value));
       }
+
       if (RpcConfiguration.HIVE_SPARK_RSC_CONFIGS.contains(propertyName)) {
         String value = RpcConfiguration.getValue(hiveConf, propertyName);
         sparkConf.put(propertyName, value);
-- 
1.7.9.5

