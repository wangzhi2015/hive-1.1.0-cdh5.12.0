From ff34f64e3a92d4cf91cdab6e1628031d084fe3b3 Mon Sep 17 00:00:00 2001
From: Yongzhi Chen <ychena@apache.org>
Date: Thu, 2 Jun 2016 18:47:13 -0400
Subject: [PATCH 0619/1164] HIVE-13932:Hive SMB Map Join with small set of
 LIMIT failed with NPE (Yongzhi Chen, reviewed by
 Chaoyu Tang)

Conflicts:
	ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java

Change-Id: I90c42c3ad1a3fee2621ece484cd73cb30a948bdb
---
 data/files/smbdata.txt                             |   99 ++++++++++++++++++++
 .../hadoop/hive/ql/exec/SMBMapJoinOperator.java    |    2 +-
 ql/src/test/queries/clientpositive/smblimit.q      |   15 +++
 ql/src/test/results/clientpositive/smblimit.q.out  |   50 ++++++++++
 4 files changed, 165 insertions(+), 1 deletion(-)
 create mode 100644 data/files/smbdata.txt
 create mode 100644 ql/src/test/queries/clientpositive/smblimit.q
 create mode 100644 ql/src/test/results/clientpositive/smblimit.q.out

diff --git a/data/files/smbdata.txt b/data/files/smbdata.txt
new file mode 100644
index 0000000..4422a54
--- /dev/null
+++ b/data/files/smbdata.txt
@@ -0,0 +1,99 @@
+1
+2
+3
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+29
+30
+31
+32
+33
+34
+35
+36
+37
+38
+39
+40
+41
+42
+43
+44
+45
+46
+47
+48
+49
+50
+51
+52
+53
+54
+55
+56
+57
+58
+59
+60
+61
+62
+63
+64
+65
+66
+67
+68
+69
+70
+71
+72
+73
+74
+75
+76
+77
+78
+79
+80
+81
+82
+83
+84
+85
+86
+87
+88
+89
+90
+91
+92
+93
+94
+95
+96
+97
+98
+99
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
index 2c9e81f..8073cb4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
@@ -341,7 +341,7 @@ private void joinFinalLeftData() throws HiveException {
       joinOneGroup();
       dataInCache = false;
       for (byte pos = 0; pos < order.length; pos++) {
-        if (this.candidateStorage[pos].rowCount() > 0) {
+        if (this.candidateStorage[pos] != null && this.candidateStorage[pos].rowCount() > 0) {
           dataInCache = true;
           break;
         }
diff --git a/ql/src/test/queries/clientpositive/smblimit.q b/ql/src/test/queries/clientpositive/smblimit.q
new file mode 100644
index 0000000..2ff467d
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/smblimit.q
@@ -0,0 +1,15 @@
+drop table if exists hlp1;
+drop table if exists btl;
+create table hlp1(c string);
+load data local inpath '../../data/files/smbdata.txt' into table hlp1;
+SET hive.enforce.bucketing=true;
+SET hive.enforce.sorting=true;
+create table btl(c string) clustered by (c) sorted by (c) into 5 buckets;
+insert overwrite table btl select * from hlp1;
+SET hive.auto.convert.sortmerge.join = true;
+SET hive.auto.convert.sortmerge.join.bigtable.selection.policy = org.apache.hadoop.hive.ql.optimizer.LeftmostBigTableSelectorForAutoSMJ;
+SET hive.auto.convert.sortmerge.join.noconditionaltask = true;
+SET hive.optimize.bucketmapjoin = true;
+SET hive.optimize.bucketmapjoin.sortedmerge = true;
+select 1 from btl join btl t1 on btl.c=t1.c limit 1;
+
diff --git a/ql/src/test/results/clientpositive/smblimit.q.out b/ql/src/test/results/clientpositive/smblimit.q.out
new file mode 100644
index 0000000..64ca604
--- /dev/null
+++ b/ql/src/test/results/clientpositive/smblimit.q.out
@@ -0,0 +1,50 @@
+PREHOOK: query: drop table if exists hlp1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table if exists hlp1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table if exists btl
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table if exists btl
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table hlp1(c string)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@hlp1
+POSTHOOK: query: create table hlp1(c string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@hlp1
+PREHOOK: query: load data local inpath '../../data/files/smbdata.txt' into table hlp1
+PREHOOK: type: LOAD
+#### A masked pattern was here ####
+PREHOOK: Output: default@hlp1
+POSTHOOK: query: load data local inpath '../../data/files/smbdata.txt' into table hlp1
+POSTHOOK: type: LOAD
+#### A masked pattern was here ####
+POSTHOOK: Output: default@hlp1
+PREHOOK: query: create table btl(c string) clustered by (c) sorted by (c) into 5 buckets
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@btl
+POSTHOOK: query: create table btl(c string) clustered by (c) sorted by (c) into 5 buckets
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@btl
+PREHOOK: query: insert overwrite table btl select * from hlp1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hlp1
+PREHOOK: Output: default@btl
+POSTHOOK: query: insert overwrite table btl select * from hlp1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hlp1
+POSTHOOK: Output: default@btl
+POSTHOOK: Lineage: btl.c SIMPLE [(hlp1)hlp1.FieldSchema(name:c, type:string, comment:null), ]
+PREHOOK: query: select 1 from btl join btl t1 on btl.c=t1.c limit 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@btl
+#### A masked pattern was here ####
+POSTHOOK: query: select 1 from btl join btl t1 on btl.c=t1.c limit 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@btl
+#### A masked pattern was here ####
+1
-- 
1.7.9.5

