From 0a7b5b3dd2404b48bdbb696a9f74a31ff75c776a Mon Sep 17 00:00:00 2001
From: Szehon Ho <szehon@cloudera.com>
Date: Wed, 9 Dec 2015 11:32:21 -0800
Subject: [PATCH 0432/1164] HIVE-12499 : Add HMS metrics for number of tables
 and partitions (Szehon, reviewed by Jimmy Xiang)

Conflicts:
	metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
	metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java
	metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java
	metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseStore.java
	metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
	metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java

Change-Id: Id547e391ffd76bd454f2d1c9f9b675b247804b64
---
 .../common/metrics/common/MetricsConstant.java     |    8 ++
 .../hive/common/metrics/MetricsTestUtils.java      |    4 +-
 .../hive/metastore/TestMetaStoreMetrics.java       |   83 ++++++++++++--
 .../hadoop/hive/metastore/HMSMetricsListener.java  |  113 ++++++++++++++++++++
 .../hadoop/hive/metastore/HiveMetaStore.java       |   53 +++++++++
 .../apache/hadoop/hive/metastore/ObjectStore.java  |   38 ++++++-
 .../org/apache/hadoop/hive/metastore/RawStore.java |   20 +++-
 .../metastore/DummyRawStoreControlledCommit.java   |   13 +++
 .../metastore/DummyRawStoreForJdoConnection.java   |   14 +++
 9 files changed, 333 insertions(+), 13 deletions(-)
 create mode 100644 metastore/src/java/org/apache/hadoop/hive/metastore/HMSMetricsListener.java

diff --git a/common/src/java/org/apache/hadoop/hive/common/metrics/common/MetricsConstant.java b/common/src/java/org/apache/hadoop/hive/common/metrics/common/MetricsConstant.java
index 9c9247d..3d685b3 100644
--- a/common/src/java/org/apache/hadoop/hive/common/metrics/common/MetricsConstant.java
+++ b/common/src/java/org/apache/hadoop/hive/common/metrics/common/MetricsConstant.java
@@ -44,4 +44,12 @@
 
   public static final String OPERATION_PREFIX = "hs2_operation_";
   public static final String COMPLETED_OPERATION_PREFIX = "hs2_completed_operation_";
+
+  public static final String INIT_TOTAL_DATABASES = "init_total_count_dbs";
+  public static final String INIT_TOTAL_TABLES = "init_total_count_tables";
+  public static final String INIT_TOTAL_PARTITIONS = "init_total_count_partitions";
+
+  public static final String DELTA_TOTAL_DATABASES = "delta_total_count_dbs";
+  public static final String DELTA_TOTAL_TABLES = "delta_total_count_tables";
+  public static final String DELTA_TOTAL_PARTITIONS = "delta_total_count_partitions";
 }
diff --git a/common/src/test/org/apache/hadoop/hive/common/metrics/MetricsTestUtils.java b/common/src/test/org/apache/hadoop/hive/common/metrics/MetricsTestUtils.java
index fd420f7..f21b431 100644
--- a/common/src/test/org/apache/hadoop/hive/common/metrics/MetricsTestUtils.java
+++ b/common/src/test/org/apache/hadoop/hive/common/metrics/MetricsTestUtils.java
@@ -45,9 +45,9 @@
   }
 
   public static void verifyMetricFile(File jsonReportFile, MetricsCategory category, String metricsName,
-    Object value) throws Exception {
+    Object expectedValue) throws Exception {
     JsonNode jsonNode = getJsonNode(jsonReportFile, category, metricsName);
-    Assert.assertEquals(jsonNode.asText(), value.toString());
+    Assert.assertEquals(expectedValue.toString(), jsonNode.asText());
   }
 
   private static JsonNode getJsonNode(File jsonReportFile, MetricsCategory category, String metricsName) throws Exception {
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
index c9da95a..8b33abe 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
@@ -19,26 +19,32 @@
 
 import com.fasterxml.jackson.databind.JsonNode;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import junit.framework.TestCase;
 import org.apache.hadoop.hive.cli.CliSessionState;
+import org.apache.hadoop.hive.common.metrics.MetricsTestUtils;
+import org.apache.hadoop.hive.common.metrics.common.MetricsConstant;
 import org.apache.hadoop.hive.common.metrics.metrics2.MetricsReporting;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
+import org.apache.hadoop.hive.metastore.api.Partition;
+import org.apache.hadoop.hive.metastore.api.SerDeInfo;
+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
+import org.apache.hadoop.hive.metastore.api.Table;
 import org.apache.hadoop.hive.ql.Driver;
 import org.apache.hadoop.hive.ql.metadata.Hive;
+import org.apache.hadoop.hive.ql.processors.CommandProcessorResponse;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.shims.ShimLoader;
-import org.apache.hive.service.server.HiveServer2;
-import org.junit.After;
-import org.junit.AfterClass;
 import org.junit.Assert;
-import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import java.io.File;
-import java.io.IOException;
 import java.nio.file.Files;
 import java.nio.file.Paths;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
 
 /**
@@ -71,19 +77,18 @@ public static void before() throws Exception {
     hiveConf.setVar(HiveConf.ConfVars.HIVE_METRICS_JSON_FILE_INTERVAL, "100ms");
 
     MetaStoreUtils.startMetaStore(port, ShimLoader.getHadoopThriftAuthBridge(), hiveConf);
-
     SessionState.start(new CliSessionState(hiveConf));
     driver = new Driver(hiveConf);
   }
 
+
   @Test
-  public void testMetricsFile() throws Exception {
+  public void testMethodCounts() throws Exception {
     driver.run("show databases");
 
     //give timer thread a chance to print the metrics
     Thread.sleep(2000);
 
-    //As the file is being written, try a few times.
     //This can be replaced by CodahaleMetrics's JsonServlet reporter once it is exposed.
     byte[] jsonData = Files.readAllBytes(Paths.get(jsonReportFile.getAbsolutePath()));
     ObjectMapper objectMapper = new ObjectMapper();
@@ -100,6 +105,66 @@ public void testMetricsFile() throws Exception {
     Assert.assertTrue(committedCountNode.asInt() > 0);
   }
 
+  @Test
+  public void testMetaDataCounts() throws Exception {
+    //1 databases created
+    driver.run("create database testdb1");
+
+    //4 tables
+    driver.run("create table testtbl1 (key string)");
+    driver.run("create table testtblpart (key string) partitioned by (partkey string)");
+    driver.run("use testdb1");
+    driver.run("create table testtbl2 (key string)");
+    driver.run("create table testtblpart2 (key string) partitioned by (partkey string)");
+
+    //6 partitions
+    driver.run("alter table default.testtblpart add partition (partkey='a')");
+    driver.run("alter table default.testtblpart add partition (partkey='b')");
+    driver.run("alter table default.testtblpart add partition (partkey='c')");
+    driver.run("alter table testdb1.testtblpart2 add partition (partkey='a')");
+    driver.run("alter table testdb1.testtblpart2 add partition (partkey='b')");
+    driver.run("alter table testdb1.testtblpart2 add partition (partkey='c')");
+
+
+    //create and drop some additional metadata, to test drop counts.
+    driver.run("create database tempdb");
+    driver.run("use tempdb");
+
+    driver.run("create table delete_by_table (key string) partitioned by (partkey string)");
+    driver.run("alter table delete_by_table add partition (partkey='temp')");
+    driver.run("drop table delete_by_table");
+
+    driver.run("create table delete_by_part (key string) partitioned by (partkey string)");
+    driver.run("alter table delete_by_part add partition (partkey='temp')");
+    driver.run("alter table delete_by_part drop partition (partkey='temp')");
+
+    driver.run("create table delete_by_db (key string) partitioned by (partkey string)");
+    driver.run("alter table delete_by_db add partition (partkey='temp')");
+    driver.run("use default");
+    driver.run("drop database tempdb cascade");
+
+    //give timer thread a chance to print the metrics
+    Thread.sleep(2000);
+
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.COUNTER, MetricsConstant.DELTA_TOTAL_DATABASES, 1);
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.COUNTER, MetricsConstant.DELTA_TOTAL_TABLES, 4);
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.COUNTER, MetricsConstant.DELTA_TOTAL_PARTITIONS, 6);
+
+
+    //to test initial metadata count metrics.
+    hiveConf.setVar(HiveConf.ConfVars.METASTORE_RAW_STORE_IMPL, ObjectStore.class.getName());
+    HiveMetaStore.HMSHandler baseHandler = new HiveMetaStore.HMSHandler("test", hiveConf, false);
+    baseHandler.init();
+    baseHandler.updateMetrics();
+
+    Thread.sleep(2000);
+
+    //1 new db + default
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.GAUGE, MetricsConstant.INIT_TOTAL_DATABASES, 2);
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.GAUGE, MetricsConstant.INIT_TOTAL_TABLES, 4);
+    MetricsTestUtils.verifyMetricFile(jsonReportFile, MetricsTestUtils.GAUGE, MetricsConstant.INIT_TOTAL_PARTITIONS, 6);
+  }
+
 
   @Test
   public void testConnections() throws Exception {
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HMSMetricsListener.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HMSMetricsListener.java
new file mode 100644
index 0000000..fa5922f
--- /dev/null
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HMSMetricsListener.java
@@ -0,0 +1,113 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.metastore;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.common.metrics.common.Metrics;
+import org.apache.hadoop.hive.common.metrics.common.MetricsConstant;
+import org.apache.hadoop.hive.metastore.api.MetaException;
+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;
+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;
+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;
+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;
+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;
+import org.apache.hadoop.hive.metastore.events.DropTableEvent;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+
+/**
+ * Report metrics of metadata added, deleted by this Hive Metastore.
+ */
+public class HMSMetricsListener extends MetaStoreEventListener {
+
+  public static final Logger LOGGER = LoggerFactory.getLogger(HMSMetricsListener.class);
+  private Metrics metrics;
+
+  public HMSMetricsListener(Configuration config, Metrics metrics) {
+    super(config);
+    this.metrics = metrics;
+  }
+
+  @Override
+  public void onCreateDatabase(CreateDatabaseEvent dbEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.incrementCounter(MetricsConstant.DELTA_TOTAL_DATABASES);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+
+  @Override
+  public void onDropDatabase(DropDatabaseEvent dbEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.decrementCounter(MetricsConstant.DELTA_TOTAL_DATABASES);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+
+  @Override
+  public void onCreateTable(CreateTableEvent tableEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.incrementCounter(MetricsConstant.DELTA_TOTAL_TABLES);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+
+  @Override
+  public void onDropTable(DropTableEvent tableEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.decrementCounter(MetricsConstant.DELTA_TOTAL_TABLES);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+
+  @Override
+  public void onDropPartition(DropPartitionEvent partitionEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.decrementCounter(MetricsConstant.DELTA_TOTAL_PARTITIONS);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+
+  @Override
+  public void onAddPartition(AddPartitionEvent partitionEvent) throws MetaException {
+    if (metrics != null) {
+      try {
+        metrics.incrementCounter(MetricsConstant.DELTA_TOTAL_PARTITIONS);
+      } catch (IOException e) {
+        LOGGER.warn("Error updating metadata metrics", e);
+      }
+    }
+  }
+}
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 0317b8d..e7baa9f 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -30,6 +30,9 @@
 import org.apache.commons.cli.OptionBuilder;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.common.metrics.common.MetricsVariable;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
@@ -305,6 +308,9 @@ public TTransport getTransport(TTransport trans) {
 
     private static String currentUrl;
 
+    //For Metrics
+    private int initDatabaseCount, initTableCount, initPartCount;
+
     private Warehouse wh; // hdfs warehouse
     private static final ThreadLocal<RawStore> threadLocalMS =
         new ThreadLocal<RawStore>() {
@@ -487,12 +493,43 @@ public void init() throws MetaException {
         }
       }
 
+      Metrics metrics = MetricsFactory.getInstance();
+      if (metrics != null) {
+        LOG.info("Begin calculating metadata count metrics.");
+        updateMetrics();
+        LOG.info("Finished metadata count metrics: " + initDatabaseCount + " databases, " + initTableCount +
+          " tables, " + initPartCount + " partitions.");
+        metrics.addGauge(MetricsConstant.INIT_TOTAL_DATABASES, new MetricsVariable() {
+          @Override
+          public Object getValue() {
+            return initDatabaseCount;
+          }
+        });
+        metrics.addGauge(MetricsConstant.INIT_TOTAL_TABLES, new MetricsVariable() {
+          @Override
+          public Object getValue() {
+            return initTableCount;
+          }
+        });
+        metrics.addGauge(MetricsConstant.INIT_TOTAL_PARTITIONS, new MetricsVariable() {
+          @Override
+          public Object getValue() {
+            return initPartCount;
+          }
+        });
+      }
+
       preListeners = MetaStoreUtils.getMetaStoreListeners(MetaStorePreEventListener.class,
           hiveConf,
           hiveConf.getVar(HiveConf.ConfVars.METASTORE_PRE_EVENT_LISTENERS));
       listeners = MetaStoreUtils.getMetaStoreListeners(MetaStoreEventListener.class, hiveConf,
           hiveConf.getVar(HiveConf.ConfVars.METASTORE_EVENT_LISTENERS));
       listeners.add(new SessionPropertiesListener(hiveConf));
+
+      if (metrics != null) {
+        listeners.add(new HMSMetricsListener(hiveConf, metrics));
+      }
+
       endFunctionListeners = MetaStoreUtils.getMetaStoreListeners(
           MetaStoreEndFunctionListener.class, hiveConf,
           hiveConf.getVar(HiveConf.ConfVars.METASTORE_END_FUNCTION_LISTENERS));
@@ -1726,6 +1763,15 @@ private void deletePartitionData(List<Path> partPaths, boolean ifPurge) {
           }
           partNames.add(Warehouse.makePartName(tbl.getPartitionKeys(), part.getValues()));
         }
+        for (MetaStoreEventListener listener : listeners) {
+          //No drop part listener events fired for public listeners historically, for drop table case.
+          //Limiting to internal listeners for now, to avoid unexpected calls for public listeners.
+          if (listener instanceof HMSMetricsListener) {
+            for (Partition part : partsToDelete) {
+              listener.onDropPartition(null);
+            }
+          }
+        }
         ms.dropPartitions(dbName, tableName, partNames);
       }
 
@@ -5800,6 +5846,13 @@ public CurrentNotificationEventId get_current_notificationEventId() throws TExce
       RawStore ms = getMS();
       return ms.getCurrentNotificationEventId();
     }
+
+    @VisibleForTesting
+    public void updateMetrics() throws MetaException {
+      initTableCount = getMS().getTableCount();
+      initPartCount = getMS().getPartitionCount();
+      initDatabaseCount = getMS().getDatabaseCount();
+    }
   }
 
 
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
index 37625d6..71a2519 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
@@ -36,8 +36,11 @@
 import java.util.Map.Entry;
 import java.util.Properties;
 import java.util.Set;
+import java.util.Timer;
+import java.util.TimerTask;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 import java.util.regex.Pattern;
@@ -217,7 +220,6 @@
   private volatile int openTrasactionCalls = 0;
   private Transaction currentTransaction = null;
   private TXN_STATUS transactionStatus = TXN_STATUS.NO_STATE;
-
   private Pattern partitionValidationPattern;
 
   /**
@@ -1066,6 +1068,40 @@ public Table getTable(String dbName, String tableName) throws MetaException {
     return tbls;
   }
 
+  public int getDatabaseCount() throws MetaException {
+    return getObjectCount("name", MDatabase.class.getName());
+  }
+
+  public int getPartitionCount() throws MetaException {
+    return getObjectCount("partitionName", MPartition.class.getName());
+  }
+
+  public int getTableCount() throws MetaException {
+    return getObjectCount("tableName", MTable.class.getName());
+  }
+
+  private int getObjectCount(String fieldName, String objName) {
+    Long result = 0L;
+    boolean commited = false;
+    Query query = null;
+    try {
+      openTransaction();
+      String queryStr =
+        "select count(" + fieldName + ") from " + objName;
+      query = pm.newQuery(queryStr);
+      result = (Long) query.execute();
+      commited = commitTransaction();
+    } finally {
+      if (!commited) {
+        rollbackTransaction();
+      }
+      if (query != null) {
+        query.closeAll();
+      }
+    }
+    return result.intValue();
+  }
+
   @Override
   public List<TableMeta> getTableMeta(String dbNames, String tableNames, List<String> tableTypes)
       throws MetaException {
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java
index 7ec89f7..cbe8fa4 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java
@@ -27,6 +27,7 @@
 import java.util.SortedSet;
 
 import org.apache.hadoop.conf.Configurable;
+import org.apache.hadoop.hive.common.classification.InterfaceStability;
 import org.apache.hadoop.hive.metastore.api.AggrStats;
 import org.apache.hadoop.hive.metastore.api.ColumnStatistics;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
@@ -600,5 +601,22 @@ public AggrStats get_aggr_stats_for(String dbName, String tblName,
    * @return
    */
   public CurrentNotificationEventId getCurrentNotificationEventId();
-  
+
+  /**
+   * Gets total number of tables.
+   */
+  @InterfaceStability.Evolving
+  int getTableCount() throws MetaException;
+
+  /**
+   * Gets total number of partitions.
+   */
+  @InterfaceStability.Evolving
+  int getPartitionCount() throws MetaException;
+
+  /**
+   * Gets total number of databases.
+   */
+  @InterfaceStability.Evolving
+  int getDatabaseCount() throws MetaException;
 }
diff --git a/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java b/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
index aeaa021..52707cb 100644
--- a/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
+++ b/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
@@ -765,5 +765,18 @@ public CurrentNotificationEventId getCurrentNotificationEventId() {
     return objectStore.getCurrentNotificationEventId();
   }
 
+  @Override
+  public int getTableCount() throws MetaException {
+    return objectStore.getTableCount();
+  }
 
+  @Override
+  public int getPartitionCount() throws MetaException {
+    return objectStore.getPartitionCount();
+  }
+
+  @Override
+  public int getDatabaseCount() throws MetaException {
+    return objectStore.getDatabaseCount();
+  }
 }
diff --git a/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java b/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
index d6faf36..f6a22af 100644
--- a/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
+++ b/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
@@ -779,6 +779,20 @@ public CurrentNotificationEventId getCurrentNotificationEventId() {
   }
 
 
+  @Override
+  public int getTableCount() throws MetaException {
+    return 0;
+  }
+
+  @Override
+  public int getPartitionCount() throws MetaException {
+    return 0;
+  }
+
+  @Override
+  public int getDatabaseCount() throws MetaException {
+    return 0;
+  }
 }
 
 
-- 
1.7.9.5

