From b575cef822735f573a7e49a89ce7387af36ee650 Mon Sep 17 00:00:00 2001
From: Rajesh Balamohan <rbalamohan at apache dot org>
Date: Fri, 5 Aug 2016 17:58:43 -0700
Subject: [PATCH 0972/1164] CDH-49911 : HIVE-14423 : S3: Fetching partition
 sizes from FS can be expensive when stats are not
 available in metastore (Rajesh Balamohan via
 Chris Nauroth, Ashutosh Chauhan)

Change-Id: Iaf4379ab961c290c14a2ad96ae5003706a89b124
---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    2 +-
 .../apache/hadoop/hive/ql/stats/StatsUtils.java    |   74 ++++++++++++++------
 2 files changed, 55 insertions(+), 21 deletions(-)

diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 1679192..08e61a8 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -383,7 +383,7 @@ public void setSparkConfigUpdated(boolean isSparkConfigUpdated) {
     METASTOREURIS("hive.metastore.uris", "",
         "Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore."),
 
-    METASTORE_FS_HANDLER_THREADS_COUNT("hive.metastore.fshandler.threads", 20,
+    METASTORE_FS_HANDLER_THREADS_COUNT("hive.metastore.fshandler.threads", 15,
         "Number of threads to be allocated for metastore handler for fs operations."),
     METASTORETHRIFTCONNECTIONRETRIES("hive.metastore.connect.retries", 3,
         "Number of retries while opening a connection to metastore"),
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
index b1b5921..ae6b312 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
@@ -24,12 +24,31 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import java.io.IOException;
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.metastore.api.AggrStats;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsData;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
@@ -85,15 +104,6 @@
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.tez.mapreduce.hadoop.MRJobConfig;
 
-import java.math.BigDecimal;
-import java.math.BigInteger;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
 public class StatsUtils {
 
   private static final Log LOG = LogFactory.getLog(StatsUtils.class.getName());
@@ -509,18 +519,42 @@ public static long getFileSizeForTable(HiveConf conf, Table table) {
    *          - partition list
    * @return sizes of patitions
    */
-  public static List<Long> getFileSizeForPartitions(HiveConf conf, List<Partition> parts) {
-    List<Long> sizes = Lists.newArrayList();
-    for (Partition part : parts) {
-      Path path = part.getDataLocation();
-      long size = 0;
-      try {
-        FileSystem fs = path.getFileSystem(conf);
-        size = fs.getContentSummary(path).getLength();
-      } catch (Exception e) {
-        size = 0;
+  public static List<Long> getFileSizeForPartitions(final HiveConf conf, List<Partition> parts) {
+    LOG.info("Number of partitions : " + parts.size());
+    ArrayList<Future<Long>> futures = new ArrayList<>();
+
+    int threads = Math.max(1, conf.getIntVar(ConfVars.METASTORE_FS_HANDLER_THREADS_COUNT));
+    final ExecutorService pool = Executors.newFixedThreadPool(threads,
+                new ThreadFactoryBuilder()
+                    .setDaemon(true)
+                    .setNameFormat("Get-Partitions-Size-%d")
+                    .build());
+
+    final ArrayList<Long> sizes = new ArrayList<>(parts.size());
+    for (final Partition part : parts) {
+      final Path path = part.getDataLocation();
+      futures.add(pool.submit(new Callable<Long>() {
+        @Override
+        public Long call() throws Exception {
+          try {
+            LOG.debug("Partition path : " + path);
+            FileSystem fs = path.getFileSystem(conf);
+            return fs.getContentSummary(path).getLength();
+          } catch (IOException e) {
+            return 0L;
+          }
+        }
+      }));
+    }
+
+    try {
+      for(int i = 0; i < futures.size(); i++) {
+        sizes.add(i, futures.get(i).get());
       }
-      sizes.add(size);
+    } catch (InterruptedException | ExecutionException e) {
+      LOG.warn("Exception in processing files ", e);
+    } finally {
+      pool.shutdownNow();
     }
     return sizes;
   }
-- 
1.7.9.5

