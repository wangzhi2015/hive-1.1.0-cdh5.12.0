From e428c3d67bec91eb4f3f31c949724198aeb1e212 Mon Sep 17 00:00:00 2001
From: Szehon Ho <szehon@cloudera.com>
Date: Wed, 18 Nov 2015 11:02:58 -0800
Subject: [PATCH 0395/1164] CDH-34443: HIVE-12388 : GetTables cannot get
 external tables when TABLE type argument is given
 (Navis and Szehon, via Aihua)

Conflicts:
	itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java

Change-Id: I30e86039849d7cfec5489b720f8c108403e6171d
---
 .../java/org/apache/hive/jdbc/TestJdbcDriver2.java |  145 ++++++++++++++------
 .../cli/operation/ClassicTableTypeMapping.java     |   48 ++++---
 .../service/cli/operation/GetTablesOperation.java  |    3 +-
 .../cli/operation/HiveTableTypeMapping.java        |   19 ++-
 .../service/cli/operation/TableTypeMapping.java    |    6 +-
 5 files changed, 151 insertions(+), 70 deletions(-)

diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
index 9904d71..f556073 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
@@ -18,19 +18,28 @@
 
 package org.apache.hive.jdbc;
 
-import static org.apache.hadoop.hive.conf.SystemVariables.SET_COLUMN_NAME;
-import static org.apache.hadoop.hive.ql.exec.ExplainTask.EXPL_COLUMN_NAME;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import com.google.common.collect.ImmutableSet;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hadoop.hive.metastore.TableType;
+import org.apache.hadoop.hive.ql.exec.UDF;
+import org.apache.hadoop.hive.ql.processors.DfsProcessor;
+import org.apache.hive.common.util.HiveVersionInfo;
+import org.apache.hive.jdbc.Utils.JdbcConnectionParams;
+import org.apache.hive.service.cli.operation.ClassicTableTypeMapping;
+import org.apache.hive.service.cli.operation.ClassicTableTypeMapping.ClassicTableTypes;
+import org.apache.hive.service.cli.operation.HiveTableTypeMapping;
+import org.apache.hive.service.cli.operation.TableTypeMappingFactory.TableTypeMappings;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
 
+import java.io.File;
 import java.io.InputStream;
-import java.lang.Exception;
-import java.lang.Object;
-import java.lang.String;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.DriverManager;
@@ -44,8 +53,8 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Date;
-import java.util.HashSet;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.IdentityHashMap;
 import java.util.List;
 import java.util.Map;
@@ -53,24 +62,9 @@
 import java.util.Set;
 import java.util.regex.Pattern;
 
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hive.conf.HiveConf;
-import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
-import org.apache.hadoop.hive.metastore.TableType;
-import org.apache.hadoop.hive.ql.exec.UDF;
-import org.apache.hadoop.hive.ql.processors.DfsProcessor;
-import org.apache.hive.common.util.HiveVersionInfo;
-import org.apache.hive.jdbc.Utils.JdbcConnectionParams;
-import org.apache.hive.service.cli.operation.ClassicTableTypeMapping;
-import org.apache.hive.service.cli.operation.ClassicTableTypeMapping.ClassicTableTypes;
-import org.apache.hive.service.cli.operation.HiveTableTypeMapping;
-import org.apache.hive.service.cli.operation.TableTypeMappingFactory.TableTypeMappings;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
+import static org.apache.hadoop.hive.conf.SystemVariables.SET_COLUMN_NAME;
+import static org.apache.hadoop.hive.ql.exec.ExplainTask.EXPL_COLUMN_NAME;
+import static org.junit.Assert.*;
 
 
 /**
@@ -90,6 +84,12 @@
   private static final String partitionedTableComment = "Partitioned table";
   private static final String dataTypeTableName = "testdatatypetable";
   private static final String dataTypeTableComment = "Table with many column data types";
+
+  private static File workDir = new File(System.getProperty("test.tmp.dir"));
+  private static final String externalTable = "testHiveJdbcDriver_External";
+  private static final String externalTableComment = "An external table";
+
+
   private final HiveConf conf;
   public static String dataFileDir;
   private final Path dataFilePath;
@@ -147,6 +147,10 @@ public void setUp() throws Exception {
 
     createTestTables(stmt, "", true);
     createTestTables(stmt, "testdb.", false);
+
+    stmt.execute("drop table " + externalTable);
+    stmt.execute("create external table " + externalTable + " (a int) comment '" + externalTableComment +
+      "' location '" + dataFileDir + "'");
   }
 
   private void createTestTables(Statement stmt, String prefix, boolean loadData)
@@ -156,6 +160,7 @@ private void createTestTables(Statement stmt, String prefix, boolean loadData)
     dropTestTables(stmt, prefix);
 
     String tableName = prefix + this.tableName;
+    String externalTable = prefix + this.tableName;
     String partitionedTableName = prefix + this.partitionedTableName;
     String dataTypeTableName = prefix + this.dataTypeTableName;
     String viewName = prefix + this.viewName;
@@ -257,8 +262,9 @@ public void tearDown() throws Exception {
     // drop table
     Statement stmt = con.createStatement();
     assertNotNull("Statement is null", stmt);
-    dropTestTables(stmt, "");
-    dropTestTables(stmt, "testdb.");
+    stmt.execute("drop table " + tableName);
+    stmt.execute("drop table " + partitionedTableName);
+    stmt.execute("drop table " + dataTypeTableName);
 
     con.close();
     assertTrue("Connection should be closed", con.isClosed());
@@ -1070,7 +1076,7 @@ public void testShowTables() throws SQLException {
 
   @Test
   public void testMetaDataGetTables() throws SQLException {
-    getTablesTest(ClassicTableTypes.TABLE.toString(), ClassicTableTypes.VIEW.toString());
+    getTablesTest(ImmutableSet.of(ClassicTableTypes.TABLE.toString()), ClassicTableTypes.VIEW.toString());
   }
 
   @Test
@@ -1078,7 +1084,9 @@ public  void testMetaDataGetTablesHive() throws SQLException {
     Statement stmt = con.createStatement();
     stmt.execute("set " + HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING.varname +
         " = " + TableTypeMappings.HIVE.toString());
-    getTablesTest(TableType.MANAGED_TABLE.toString(), TableType.VIRTUAL_VIEW.toString());
+    getTablesTest(ImmutableSet.of(TableType.MANAGED_TABLE.toString(),
+        TableType.EXTERNAL_TABLE.toString()),
+      TableType.VIRTUAL_VIEW.toString());
   }
 
   @Test
@@ -1087,21 +1095,56 @@ public  void testMetaDataGetTablesClassic() throws SQLException {
     stmt.execute("set " + HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING.varname +
         " = " + TableTypeMappings.CLASSIC.toString());
     stmt.close();
-    getTablesTest(ClassicTableTypes.TABLE.toString(), ClassicTableTypes.VIEW.toString());
+    getTablesTest(ImmutableSet.of(ClassicTableTypes.TABLE.toString()), ClassicTableTypes.VIEW.toString());
+  }
+
+  @Test
+  public void testMetaDataGetExternalTables() throws SQLException {
+    Statement stmt = con.createStatement();
+    stmt.execute("set " + HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING.varname +
+      " = " + TableTypeMappings.HIVE.toString());
+    stmt.close();
+    ResultSet rs = con.getMetaData().getTables(null,
+      null, null, new String[] { TableType.EXTERNAL_TABLE.toString() });
+    ResultSetMetaData resMeta = rs.getMetaData();
+    assertEquals(10, resMeta.getColumnCount());
+    assertEquals("TABLE_CAT", resMeta.getColumnName(1));
+    assertEquals("TABLE_SCHEM", resMeta.getColumnName(2));
+    assertEquals("TABLE_NAME", resMeta.getColumnName(3));
+    assertEquals("TABLE_TYPE", resMeta.getColumnName(4));
+    assertEquals("REMARKS", resMeta.getColumnName(5));
+
+    rs.next();
+
+    String resultDbName = rs.getString("TABLE_SCHEM");
+    assertEquals(resultDbName, "default");
+    String resultTableName = rs.getString("TABLE_NAME");
+    assertEquals(resultTableName, externalTable.toLowerCase());
+
+    String resultTableComment = rs.getString("REMARKS");
+    assertTrue("Missing comment on the table.", resultTableComment.length()>0);
+    String tableType = rs.getString("TABLE_TYPE");
+    assertEquals(TableType.EXTERNAL_TABLE.toString(), tableType);
+
+    assertFalse("Unexpected table", rs.next());
   }
 
   /**
    * Test the type returned for pre-created table type table and view type
    * table
-   * @param tableTypeName expected table type
+   * @param tableTypeNames expected table types
    * @param viewTypeName expected view type
    * @throws SQLException
    */
-  private void getTablesTest(String tableTypeName, String viewTypeName) throws SQLException {
+  private void getTablesTest(Set<String> tableTypeNames, String viewTypeName) throws SQLException {
     String[] ALL = null;
     String[] VIEW_ONLY = {viewTypeName};
-    String[] TABLE_ONLY = {tableTypeName};
-    String[] VIEWORTABLE = {tableTypeName, viewTypeName};
+    String[] TABLE_ONLY = tableTypeNames.toArray(new String[tableTypeNames.size()]);
+
+    Set<String> viewOrTableArray = new HashSet<String>();
+    viewOrTableArray.addAll(tableTypeNames);
+    viewOrTableArray.add(viewTypeName);
+    String[] VIEWORTABLE = viewOrTableArray.toArray(new String[viewOrTableArray.size()]);
 
     Map<Object[], String[]> tests = new IdentityHashMap<Object[], String[]>();
     tests.put(new Object[] { null, "test%jdbc%", ALL}, new String[]{
@@ -1110,7 +1153,8 @@ private void getTablesTest(String tableTypeName, String viewTypeName) throws SQL
         "default.testhivejdbcdriverview",
         "testdb.testhivejdbcdriver_table",
         "testdb.testhivejdbcdriverpartitionedtable",
-        "testdb.testhivejdbcdriverview"});
+        "testdb.testhivejdbcdriverview",
+        "default.testhivejdbcdriver_external"});
     tests.put(new Object[] { "test%", "test%jdbc%", ALL}, new String[]{
         "testdb.testhivejdbcdriver_table",
         "testdb.testhivejdbcdriverpartitionedtable",
@@ -1153,12 +1197,25 @@ private void getTablesTest(String tableTypeName, String viewTypeName) throws SQL
         "default.testhivejdbcdriverview",
         "testdb.testhivejdbcdriver_table",
         "testdb.testhivejdbcdriverpartitionedtable",
+        "testdb.testhivejdbcdriverview",
+        "default.testhivejdbcdriver_external"});
+    tests.put(new Object[] { "%", "%jdbc%", VIEW_ONLY}, new String[]{
+        "default.testhivejdbcdriverview",
         "testdb.testhivejdbcdriverview"});
+
     tests.put(new Object[] { "%", "%jdbc%", VIEW_ONLY}, new String[]{
         "default.testhivejdbcdriverview",
         "testdb.testhivejdbcdriverview"});
     tests.put(new Object[] { null, "", ALL}, new String[]{});
 
+    tests.put(new Object[] { null, "%jdbc%", TABLE_ONLY}, new String[]{
+        "default.testhivejdbcdriver_table",
+        "default.testhivejdbcdriverpartitionedtable",
+        "testdb.testhivejdbcdriver_table",
+        "testdb.testhivejdbcdriverpartitionedtable",
+        "default.testhivejdbcdriver_external"
+    });
+
     for (Map.Entry<Object[], String[]> entry : tests.entrySet()) {
       Object[] checkPattern = entry.getKey();
       String debugString = checkPattern[0] + ", " + checkPattern[1] + ", " +
@@ -1180,7 +1237,7 @@ private void getTablesTest(String tableTypeName, String viewTypeName) throws SQL
         String resultDbName = rs.getString("TABLE_SCHEM");
         String resultTableName = rs.getString("TABLE_NAME");
         assertTrue("Invalid table " + resultDbName + "." + resultTableName + " for test " + debugString,
-            expectedTables.contains(resultDbName + "." + resultTableName));
+          expectedTables.contains(resultDbName + "." + resultTableName));
 
         String resultTableComment = rs.getString("REMARKS");
         assertTrue("Missing comment on the table.", resultTableComment.length()>0);
@@ -1188,7 +1245,7 @@ private void getTablesTest(String tableTypeName, String viewTypeName) throws SQL
         if (resultTableName.endsWith("view")) {
           assertEquals("Expected a tabletype view but got something else.", viewTypeName, tableType);
         } else {
-          assertEquals("Expected a tabletype table but got something else.", tableTypeName, tableType);
+          assertTrue("Expected one of " + tableTypeNames + " table but got something else: " + tableType, tableTypeNames.contains(tableType));
         }
         cnt++;
       }
@@ -1280,8 +1337,8 @@ private void metaDataGetTableTypeTest(Set<String> tabletypes)
   public void testMetaDataGetColumns() throws SQLException {
     Map<String[], Integer> tests = new HashMap<String[], Integer>();
     tests.put(new String[]{"testhivejdbcdriver\\_table", null}, 2);
-    tests.put(new String[]{"testhivejdbc%", null}, 7);
-    tests.put(new String[]{"testhiveJDBC%", null}, 7);
+    tests.put(new String[]{"testhivejdbc%", null}, 8);
+    tests.put(new String[]{"testhiveJDBC%", null}, 8);
     tests.put(new String[]{"%jdbcdriver\\_table", null}, 2);
     tests.put(new String[]{"%jdbcdriver\\_table%", "under\\_col"}, 1);
     //    tests.put(new String[]{"%jdbcdriver\\_table%", "under\\_COL"}, 1);
diff --git a/service/src/java/org/apache/hive/service/cli/operation/ClassicTableTypeMapping.java b/service/src/java/org/apache/hive/service/cli/operation/ClassicTableTypeMapping.java
index 87ac39b..e5a186c 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/ClassicTableTypeMapping.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/ClassicTableTypeMapping.java
@@ -18,6 +18,14 @@
 
 package org.apache.hive.service.cli.operation;
 
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.Iterables;
+import com.google.common.collect.Multimap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.Collection;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
@@ -34,51 +42,51 @@
  */
 public class ClassicTableTypeMapping implements TableTypeMapping {
 
+  private static final Logger LOG = LoggerFactory.getLogger(ClassicTableTypeMapping.class);
+
   public enum ClassicTableTypes {
     TABLE,
     VIEW,
   }
 
   private final Map<String, String> hiveToClientMap = new HashMap<String, String>();
-  private final Map<String, String> clientToHiveMap = new HashMap<String, String>();
+  private final Multimap<String, String> clientToHiveMap = ArrayListMultimap.create();
 
   public ClassicTableTypeMapping () {
-    hiveToClientMap.put(TableType.MANAGED_TABLE.toString(),
-        ClassicTableTypes.TABLE.toString());
-    hiveToClientMap.put(TableType.EXTERNAL_TABLE.toString(),
-        ClassicTableTypes.TABLE.toString());
-    hiveToClientMap.put(TableType.VIRTUAL_VIEW.toString(),
-        ClassicTableTypes.VIEW.toString());
+    hiveToClientMap.put(TableType.MANAGED_TABLE.name(), ClassicTableTypes.TABLE.name());
+    hiveToClientMap.put(TableType.EXTERNAL_TABLE.name(), ClassicTableTypes.TABLE.name());
+    hiveToClientMap.put(TableType.VIRTUAL_VIEW.name(), ClassicTableTypes.VIEW.name());
 
-    clientToHiveMap.put(ClassicTableTypes.TABLE.toString(),
-        TableType.MANAGED_TABLE.toString());
-    clientToHiveMap.put(ClassicTableTypes.VIEW.toString(),
-        TableType.VIRTUAL_VIEW.toString());
+    clientToHiveMap.putAll(ClassicTableTypes.TABLE.name(), Arrays.asList(
+        TableType.MANAGED_TABLE.name(), TableType.EXTERNAL_TABLE.name()));
+    clientToHiveMap.put(ClassicTableTypes.VIEW.name(), TableType.VIRTUAL_VIEW.name());
   }
 
   @Override
-  public String mapToHiveType(String clientTypeName) {
-    if (clientToHiveMap.containsKey(clientTypeName)) {
-      return clientToHiveMap.get(clientTypeName);
-    } else {
-      return clientTypeName;
+  public String[] mapToHiveType(String clientTypeName) {
+    Collection<String> hiveTableType = clientToHiveMap.get(clientTypeName.toUpperCase());
+    if (hiveTableType == null) {
+      LOG.warn("Not supported client table type " + clientTypeName);
+      return new String[] {clientTypeName};
     }
+    return Iterables.toArray(hiveTableType, String.class);
   }
 
   @Override
   public String mapToClientType(String hiveTypeName) {
-    if (hiveToClientMap.containsKey(hiveTypeName)) {
-      return hiveToClientMap.get(hiveTypeName);
-    } else {
+    String clientTypeName = hiveToClientMap.get(hiveTypeName);
+    if (clientTypeName == null) {
+      LOG.warn("Invalid hive table type " + hiveTypeName);
       return hiveTypeName;
     }
+    return clientTypeName;
   }
 
   @Override
   public Set<String> getTableTypeNames() {
     Set<String> typeNameSet = new HashSet<String>();
     for (ClassicTableTypes typeNames : ClassicTableTypes.values()) {
-      typeNameSet.add(typeNames.toString());
+      typeNameSet.add(typeNames.name());
     }
     return typeNameSet;
   }
diff --git a/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java b/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
index 27686d6..999fb9a 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
@@ -19,6 +19,7 @@
 package org.apache.hive.service.cli.operation;
 
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -76,7 +77,7 @@ protected GetTablesOperation(HiveSession parentSession,
     if (tableTypes != null) {
       tableTypeList = new ArrayList<String>();
       for (String tableType : tableTypes) {
-        tableTypeList.add(tableTypeMapping.mapToHiveType(tableType.trim()));
+        tableTypeList.addAll(Arrays.asList(tableTypeMapping.mapToHiveType(tableType.trim())));
       }
     } else {
       tableTypeList = null;
diff --git a/service/src/java/org/apache/hive/service/cli/operation/HiveTableTypeMapping.java b/service/src/java/org/apache/hive/service/cli/operation/HiveTableTypeMapping.java
index b530f21..d45c441 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/HiveTableTypeMapping.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/HiveTableTypeMapping.java
@@ -18,6 +18,9 @@
 
 package org.apache.hive.service.cli.operation;
 
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import java.util.HashSet;
 import java.util.Set;
 
@@ -30,21 +33,29 @@
  */
 public class HiveTableTypeMapping implements TableTypeMapping {
 
+  private static final Logger LOG = LoggerFactory.getLogger(HiveTableTypeMapping.class);
+
   @Override
-  public String mapToHiveType(String clientTypeName) {
-    return clientTypeName;
+  public String[] mapToHiveType(String clientTypeName) {
+    return new String[] {mapToClientType(clientTypeName)};
   }
 
   @Override
   public String mapToClientType(String hiveTypeName) {
-    return hiveTypeName;
+    try {
+      TableType hiveType = TableType.valueOf(hiveTypeName.toUpperCase());
+      return hiveType.name();
+    } catch (IllegalArgumentException e) {
+      LOG.warn("Invalid hive table type " + hiveTypeName);
+      return hiveTypeName;
+    }
   }
 
   @Override
   public Set<String> getTableTypeNames() {
     Set<String> typeNameSet = new HashSet<String>();
     for (TableType typeNames : TableType.values()) {
-      typeNameSet.add(typeNames.toString());
+      typeNameSet.add(typeNames.name());
     }
     return typeNameSet;
   }
diff --git a/service/src/java/org/apache/hive/service/cli/operation/TableTypeMapping.java b/service/src/java/org/apache/hive/service/cli/operation/TableTypeMapping.java
index 3a8a07f..8f531f7 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/TableTypeMapping.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/TableTypeMapping.java
@@ -20,14 +20,18 @@
 
 import java.util.Set;
 
+import org.apache.hadoop.hive.common.classification.InterfaceAudience;
+import org.apache.hadoop.hive.common.classification.InterfaceStability;
 
+@InterfaceAudience.Public
+@InterfaceStability.Evolving
 public interface TableTypeMapping {
   /**
    * Map client's table type name to hive's table type
    * @param clientTypeName
    * @return
    */
-  public String mapToHiveType (String clientTypeName);
+  public String[] mapToHiveType (String clientTypeName);
 
   /**
    * Map hive's table type name to client's table type
-- 
1.7.9.5

