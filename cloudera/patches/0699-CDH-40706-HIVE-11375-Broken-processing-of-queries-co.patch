From baa43fc8239b26d5de547aa6eb0308eba2eaf4bb Mon Sep 17 00:00:00 2001
From: Aihua Xu <aihuaxu@gmail.com>
Date: Fri, 21 Aug 2015 10:39:21 -0700
Subject: [PATCH 0699/1164] CDH-40706: HIVE-11375: Broken processing of
 queries containing NOT (x IS NOT NULL and x <> 0)
 (Aihua Xu, reviewed by Ashutosh Chauhan)

Change-Id: Iaa6e62ec55d42228c562c3339dd6f0e187107939
---
 .../ql/optimizer/ConstantPropagateProcFactory.java |  159 +-
 .../hadoop/hive/ql/udf/generic/GenericUDF.java     |   14 +-
 .../hive/ql/udf/generic/GenericUDFOPAnd.java       |    4 +
 .../hive/ql/udf/generic/GenericUDFOPEqual.java     |    4 +
 .../generic/GenericUDFOPEqualOrGreaterThan.java    |    4 +
 .../udf/generic/GenericUDFOPEqualOrLessThan.java   |    4 +
 .../ql/udf/generic/GenericUDFOPGreaterThan.java    |    4 +
 .../hive/ql/udf/generic/GenericUDFOPLessThan.java  |    4 +
 .../hive/ql/udf/generic/GenericUDFOPNotEqual.java  |    5 +
 .../hive/ql/udf/generic/GenericUDFOPNotNull.java   |    4 +
 .../hive/ql/udf/generic/GenericUDFOPNull.java      |    4 +
 .../hadoop/hive/ql/udf/generic/GenericUDFOPOr.java |    4 +
 .../test/queries/clientpositive/folder_predicate.q |   32 +
 .../clientpositive/annotate_stats_filter.q.out     |   10 +-
 .../clientpositive/constprog_semijoin.q.out        |   12 +-
 .../test/results/clientpositive/decimal_udf.q.out  |   18 +-
 .../results/clientpositive/folder_predicate.q.out  |  368 ++++
 .../results/clientpositive/input_testxpath2.q.out  |    2 +-
 .../list_bucket_query_oneskew_3.q.out              |    6 +-
 .../clientpositive/rand_partitionpruner3.q.out     |   12 +-
 .../clientpositive/select_unquote_not.q.out        |    8 +-
 .../clientpositive/spark/constprog_semijoin.q.out  |   10 +-
 .../clientpositive/spark/vectorization_not.q.out   |    1 +
 .../clientpositive/tez/constprog_semijoin.q.out    |   12 +-
 .../results/clientpositive/tez/decimal_udf.q.out   | 2235 ++++++++++++++++++++
 .../clientpositive/tez/filter_join_breaktask.q.out |   12 +-
 .../clientpositive/tez/vector_decimal_udf.q.out    |   24 +-
 .../clientpositive/udf_isnull_isnotnull.q.out      |    2 +-
 ql/src/test/results/clientpositive/udf_size.q.out  |    2 +-
 .../test/results/clientpositive/union_offcbo.q.out |   12 +-
 .../clientpositive/vector_decimal_udf.q.out        |   24 +-
 31 files changed, 2910 insertions(+), 106 deletions(-)
 create mode 100644 ql/src/test/queries/clientpositive/folder_predicate.q
 create mode 100644 ql/src/test/results/clientpositive/folder_predicate.q.out
 create mode 100644 ql/src/test/results/clientpositive/tez/decimal_udf.q.out

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConstantPropagateProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConstantPropagateProcFactory.java
index 9556f7f..ab71411 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConstantPropagateProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConstantPropagateProcFactory.java
@@ -17,6 +17,8 @@
 
 import java.io.Serializable;
 import java.util.ArrayList;
+import java.util.BitSet;
+import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
@@ -70,6 +72,10 @@
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFNvl;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrGreaterThan;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrLessThan;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPGreaterThan;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPLessThan;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNot;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotEqual;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotNull;
@@ -87,8 +93,10 @@
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 
+import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
 
@@ -216,6 +224,65 @@ private static ExprNodeDesc foldExpr(ExprNodeDesc desc, Map<ColumnInfo, ExprNode
   }
 
   /**
+   * Combines the logical not() operator with the child operator if possible.
+   * @param desc the expression to be evaluated
+   * @return  the new expression to be replaced
+   * @throws UDFArgumentException
+   */
+  private static ExprNodeDesc foldNegative(ExprNodeDesc desc) throws UDFArgumentException {
+    if (desc instanceof ExprNodeGenericFuncDesc) {
+      ExprNodeGenericFuncDesc funcDesc = (ExprNodeGenericFuncDesc) desc;
+
+      GenericUDF udf = funcDesc.getGenericUDF();
+      if (udf instanceof GenericUDFOPNot) {
+        ExprNodeDesc child = funcDesc.getChildren().get(0);
+        if (child instanceof ExprNodeGenericFuncDesc) {
+          ExprNodeGenericFuncDesc childDesc = (ExprNodeGenericFuncDesc)child;
+          GenericUDF childUDF = childDesc.getGenericUDF();
+          List<ExprNodeDesc> grandChildren = child.getChildren();
+
+          if (childUDF instanceof GenericUDFBaseCompare ||
+              childUDF instanceof GenericUDFOPNull ||
+              childUDF instanceof GenericUDFOPNotNull) {
+            List<ExprNodeDesc> newGrandChildren = new ArrayList<ExprNodeDesc>();
+            for(ExprNodeDesc grandChild : grandChildren) {
+              newGrandChildren.add(foldNegative(grandChild));
+            }
+
+            return ExprNodeGenericFuncDesc.newInstance(
+                childUDF.negative(),
+                newGrandChildren);
+          } else if (childUDF instanceof GenericUDFOPAnd ||
+              childUDF instanceof GenericUDFOPOr) {
+            List<ExprNodeDesc> newGrandChildren = new ArrayList<ExprNodeDesc>();
+            for(ExprNodeDesc grandChild : grandChildren) {
+              newGrandChildren.add(foldNegative(
+                  ExprNodeGenericFuncDesc.newInstance(new GenericUDFOPNot(),
+                      Arrays.asList(grandChild))));
+            }
+
+            return ExprNodeGenericFuncDesc.newInstance(
+                childUDF.negative(),
+                newGrandChildren);
+          }else if (childUDF instanceof GenericUDFOPNot) {
+            return foldNegative(child.getChildren().get(0));
+          } else {
+            // For operator like if() that cannot be handled, leave not() as it
+            // is and continue processing the children
+            List<ExprNodeDesc> newGrandChildren = new ArrayList<ExprNodeDesc>();
+            for(ExprNodeDesc grandChild : grandChildren) {
+              newGrandChildren.add(foldNegative(grandChild));
+            }
+            childDesc.setChildren(newGrandChildren);
+            return funcDesc;
+          }
+        }
+      }
+    }
+    return desc;
+  }
+
+  /**
    * Fold input expression desc, only performing short-cutting.
    *
    * Unnecessary AND/OR operations involving a constant true/false value will be eliminated.
@@ -231,6 +298,11 @@ private static ExprNodeDesc foldExpr(ExprNodeDesc desc, Map<ColumnInfo, ExprNode
   private static ExprNodeDesc foldExprShortcut(ExprNodeDesc desc, Map<ColumnInfo, ExprNodeDesc> constants,
       ConstantPropagateProcCtx cppCtx, Operator<? extends Serializable> op, int tag,
       boolean propagate) throws UDFArgumentException {
+    // Combine NOT operator with the child operator. Otherwise, the following optimization
+    // from bottom up could lead to incorrect result, such as not(x > 3 and x is not null),
+    // should not be optimized to not(x > 3), but (x <=3 or x is null).
+    desc = foldNegative(desc);
+
     if (desc instanceof ExprNodeGenericFuncDesc) {
       ExprNodeGenericFuncDesc funcDesc = (ExprNodeGenericFuncDesc) desc;
 
@@ -242,15 +314,17 @@ private static ExprNodeDesc foldExprShortcut(ExprNodeDesc desc, Map<ColumnInfo,
         newExprs.add(foldExpr(childExpr, constants, cppCtx, op, tag, propagateNext));
       }
 
-      // Don't evalulate nondeterministic function since the value can only calculate during runtime.
+      // Don't evaluate nondeterministic function since the value can only calculate during runtime.
       if (!isDeterministicUdf(udf)) {
-        LOG.debug("Function " + udf.getClass() + " is undeterministic. Don't evalulating immediately.");
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Function " + udf.getClass() + " is undeterministic. Don't evalulate immediately.");
+        }
         ((ExprNodeGenericFuncDesc) desc).setChildren(newExprs);
         return desc;
       }
 
       // Check if the function can be short cut.
-      ExprNodeDesc shortcut = shortcutFunction(udf, newExprs);
+      ExprNodeDesc shortcut = shortcutFunction(udf, newExprs, op);
       if (shortcut != null) {
         LOG.debug("Folding expression:" + desc + " -> " + shortcut);
         return shortcut;
@@ -265,11 +339,11 @@ private static ExprNodeDesc foldExprShortcut(ExprNodeDesc desc, Map<ColumnInfo,
    *
    * This function recursively checks if any subexpression of a specified expression
    * can be evaluated to be constant and replaces such subexpression with the constant.
-   * If the expression is a derterministic UDF and all the subexpressions are constants,
+   * If the expression is a deterministic UDF and all the subexpressions are constants,
    * the value will be calculated immediately (during compilation time vs. runtime).
    * e.g.:
    *   concat(year, month) => 200112 for year=2001, month=12 since concat is deterministic UDF
-   *   unix_timestamp(time) => unix_timestamp(123) for time=123 since unix_timestamp is nonderministic UDF
+   *   unix_timestamp(time) => unix_timestamp(123) for time=123 since unix_timestamp is nondeterministic UDF
    * @param desc folding expression
    * @param constants current propagated constant map
    * @param cppCtx
@@ -281,6 +355,11 @@ private static ExprNodeDesc foldExprShortcut(ExprNodeDesc desc, Map<ColumnInfo,
   private static ExprNodeDesc foldExprFull(ExprNodeDesc desc, Map<ColumnInfo, ExprNodeDesc> constants,
       ConstantPropagateProcCtx cppCtx, Operator<? extends Serializable> op, int tag,
       boolean propagate) throws UDFArgumentException {
+    // Combine NOT operator with the child operator. Otherwise, the following optimization
+    // from bottom up could lead to incorrect result, such as not(x > 3 and x is not null),
+    // should not be optimized to not(x > 3), but (x <=3 or x is null).
+    desc = foldNegative(desc);
+
     if (desc instanceof ExprNodeGenericFuncDesc) {
       ExprNodeGenericFuncDesc funcDesc = (ExprNodeGenericFuncDesc) desc;
 
@@ -292,9 +371,11 @@ private static ExprNodeDesc foldExprFull(ExprNodeDesc desc, Map<ColumnInfo, Expr
         newExprs.add(foldExpr(childExpr, constants, cppCtx, op, tag, propagateNext));
       }
 
-      // Don't evalulate nondeterministic function since the value can only calculate during runtime.
+      // Don't evaluate nondeterministic function since the value can only calculate during runtime.
       if (!isDeterministicUdf(udf)) {
-        LOG.debug("Function " + udf.getClass() + " is undeterministic. Don't evalulating immediately.");
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Function " + udf.getClass() + " is undeterministic. Don't evaluate immediately.");
+        }
         ((ExprNodeGenericFuncDesc) desc).setChildren(newExprs);
         return desc;
       } else {
@@ -305,7 +386,7 @@ private static ExprNodeDesc foldExprFull(ExprNodeDesc desc, Map<ColumnInfo, Expr
           return constant;
         } else {
           // Check if the function can be short cut.
-          ExprNodeDesc shortcut = shortcutFunction(udf, newExprs);
+          ExprNodeDesc shortcut = shortcutFunction(udf, newExprs, op);
           if (shortcut != null) {
             LOG.debug("Folding expression:" + desc + " -> " + shortcut);
             return shortcut;
@@ -435,8 +516,8 @@ private static ExprNodeColumnDesc getColumnExpr(ExprNodeDesc expr) {
     return (expr instanceof ExprNodeColumnDesc) ? (ExprNodeColumnDesc)expr : null;
   }
 
-  private static ExprNodeDesc shortcutFunction(GenericUDF udf, List<ExprNodeDesc> newExprs) throws UDFArgumentException {
-
+  private static ExprNodeDesc shortcutFunction(GenericUDF udf, List<ExprNodeDesc> newExprs,
+    Operator<? extends Serializable> op) throws UDFArgumentException {
     if (udf instanceof GenericUDFOPEqual) {
      assert newExprs.size() == 2;
      boolean foundUDFInFirst = false;
@@ -487,36 +568,69 @@ private static ExprNodeDesc shortcutFunction(GenericUDF udf, List<ExprNodeDesc>
        return null;
      }
     }
+
     if (udf instanceof GenericUDFOPAnd) {
+      final BitSet positionsToRemove = new BitSet();
+      final List<ExprNodeDesc> notNullExprs = new ArrayList<ExprNodeDesc>();
+      final List<Integer> notNullExprsPositions = new ArrayList<Integer>();
+      final List<ExprNodeDesc> compareExprs = new ArrayList<ExprNodeDesc>();
       for (int i = 0; i < 2; i++) {
         ExprNodeDesc childExpr = newExprs.get(i);
-        ExprNodeDesc other = newExprs.get(Math.abs(i - 1));
         if (childExpr instanceof ExprNodeConstantDesc) {
           ExprNodeConstantDesc c = (ExprNodeConstantDesc) childExpr;
           if (Boolean.TRUE.equals(c.getValue())) {
 
             // if true, prune it
-            return other;
+            positionsToRemove.set(i);
           } else {
 
             // if false return false
             return childExpr;
           }
-        } else // Try to fold (key = 86) and (key is not null) to (key = 86) 
-        if (childExpr instanceof ExprNodeGenericFuncDesc &&
-            ((ExprNodeGenericFuncDesc)childExpr).getGenericUDF() instanceof GenericUDFOPNotNull &&
-            childExpr.getChildren().get(0) instanceof ExprNodeColumnDesc && other instanceof ExprNodeGenericFuncDesc
-            && ((ExprNodeGenericFuncDesc)other).getGenericUDF() instanceof GenericUDFBaseCompare
-            && other.getChildren().size() == 2) {
-          ExprNodeColumnDesc colDesc = getColumnExpr(other.getChildren().get(0));
+        } else if (childExpr instanceof ExprNodeGenericFuncDesc &&
+                ((ExprNodeGenericFuncDesc) childExpr).getGenericUDF() instanceof GenericUDFOPNotNull &&
+                childExpr.getChildren().get(0) instanceof ExprNodeColumnDesc) {
+          notNullExprs.add(childExpr.getChildren().get(0));
+          notNullExprsPositions.add(i);
+        } else if (childExpr instanceof ExprNodeGenericFuncDesc &&
+                ((ExprNodeGenericFuncDesc) childExpr).getGenericUDF() instanceof GenericUDFBaseCompare &&
+                !(((ExprNodeGenericFuncDesc) childExpr).getGenericUDF() instanceof GenericUDFOPNotEqual) &&
+                childExpr.getChildren().size() == 2) {
+          // Try to fold (key <op> 86) and (key is not null) to (key <op> 86)
+          // where <op> can be "=", ">=", "<=", ">", "<".
+          // Note: (key <> 86) and (key is not null) cannot be folded
+          ExprNodeColumnDesc colDesc = getColumnExpr(childExpr.getChildren().get(0));
           if (null == colDesc) {
-            colDesc = getColumnExpr(other.getChildren().get(1));
+            colDesc = getColumnExpr(childExpr.getChildren().get(1));
           }
-          if (null != colDesc && colDesc.isSame(childExpr.getChildren().get(0))) {
-            return other;
+          if (colDesc != null) {
+            compareExprs.add(colDesc);
           }
         }
       }
+      // Try to fold (key = 86) and (key is not null) to (key = 86)
+      for (int i = 0; i < notNullExprs.size(); i++) {
+        for (ExprNodeDesc other : compareExprs) {
+          if (notNullExprs.get(i).isSame(other)) {
+            positionsToRemove.set(notNullExprsPositions.get(i));
+            break;
+          }
+        }
+      }
+      // Remove unnecessary expressions
+      int pos = 0;
+      int removed = 0;
+      while ((pos = positionsToRemove.nextSetBit(pos)) != -1) {
+        newExprs.remove(pos - removed);
+        pos++;
+        removed++;
+      }
+      if (newExprs.size() == 0) {
+        return new ExprNodeConstantDesc(TypeInfoFactory.booleanTypeInfo, Boolean.TRUE);
+      }
+      if (newExprs.size() == 1) {
+        return newExprs.get(0);
+      }
     }
 
     if (udf instanceof GenericUDFOPOr) {
@@ -580,6 +694,7 @@ private static ExprNodeDesc shortcutFunction(GenericUDF udf, List<ExprNodeDesc>
         }
       }
     }
+
     if (udf instanceof GenericUDFCase) {
       // HIVE-9644 Attempt to fold expression like :
       // where (case ss_sold_date when '1998-01-01' then 1=1 else null=1 end);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDF.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDF.java
index 8e467c4..8df4d5e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDF.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDF.java
@@ -213,12 +213,24 @@ public void close() throws IOException {
   }
 
   /**
-   * Some functions are affected by appearing order of arguments (comparisons, for example)
+   * Some functions like comparisons may be affected by appearing order of arguments.
+   * This is to convert a function, such as 3 > x to x < 3. The flip function of
+   * GenericUDFOPGreaterThan is GenericUDFOPLessThan.
    */
   public GenericUDF flip() {
     return this;
   }
 
+  /**
+   * Gets the negative function of the current one. E.g., GenericUDFOPNotEqual for
+   * GenericUDFOPEqual, or GenericUDFOPNull for GenericUDFOPNotNull.
+   * @return Negative function
+   * @throws UDFArgumentException
+   */
+  public GenericUDF negative() {
+    throw new UnsupportedOperationException("Negative function doesn't exist for " + getFuncName());
+  }
+
   public String getUdfName() {
     return getClass().getName();
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPAnd.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPAnd.java
index 47abb20..459b63b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPAnd.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPAnd.java
@@ -88,4 +88,8 @@ public String getDisplayString(String[] children) {
     return "(" + children[0] + " and " + children[1] + ")";
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPOr();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqual.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqual.java
index 3870b51..feb1bee 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqual.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqual.java
@@ -116,4 +116,8 @@ public Object evaluate(DeferredObject[] arguments) throws HiveException {
     return result;
   }
 
+  @Override
+  public GenericUDF negative() {
+      return new GenericUDFOPNotEqual();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrGreaterThan.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrGreaterThan.java
index 65e1835..156148e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrGreaterThan.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrGreaterThan.java
@@ -128,4 +128,8 @@ public GenericUDF flip() {
     return new GenericUDFOPEqualOrLessThan();
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPLessThan();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrLessThan.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrLessThan.java
index 3e4a1d2..d0f9fff 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrLessThan.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPEqualOrLessThan.java
@@ -128,5 +128,9 @@ public GenericUDF flip() {
     return new GenericUDFOPEqualOrGreaterThan();
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPGreaterThan();
+  }
 }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPGreaterThan.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPGreaterThan.java
index df7a857..9664310 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPGreaterThan.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPGreaterThan.java
@@ -128,5 +128,9 @@ public GenericUDF flip() {
     return new GenericUDFOPLessThan();
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPEqualOrLessThan();
+  }
 }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPLessThan.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPLessThan.java
index fafd99b..d8864ea 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPLessThan.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPLessThan.java
@@ -128,4 +128,8 @@ public GenericUDF flip() {
     return new GenericUDFOPGreaterThan();
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPEqualOrGreaterThan();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotEqual.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotEqual.java
index 0436488..2ae22da 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotEqual.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotEqual.java
@@ -115,4 +115,9 @@ public Object evaluate(DeferredObject[] arguments) throws HiveException {
     }
     return result;
   }
+
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPEqual();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotNull.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotNull.java
index d22b35d..2b67c38 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotNull.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNotNull.java
@@ -60,4 +60,8 @@ public String getDisplayString(String[] children) {
     return children[0] + " is not null";
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPNull();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNull.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNull.java
index fe20e9a..4eb92eb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNull.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPNull.java
@@ -60,4 +60,8 @@ public String getDisplayString(String[] children) {
     return children[0] + " is null";
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPNotNull();
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPOr.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPOr.java
index cd656a0..cbe04eb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPOr.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPOr.java
@@ -89,4 +89,8 @@ public String getDisplayString(String[] children) {
     return "(" + children[0] + " or " + children[1] + ")";
   }
 
+  @Override
+  public GenericUDF negative() {
+    return new GenericUDFOPAnd();
+  }
 }
diff --git a/ql/src/test/queries/clientpositive/folder_predicate.q b/ql/src/test/queries/clientpositive/folder_predicate.q
new file mode 100644
index 0000000..2377dd4
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/folder_predicate.q
@@ -0,0 +1,32 @@
+drop table if exists predicate_fold_tb;
+
+create table predicate_fold_tb(value int);
+insert into predicate_fold_tb values(NULL), (1), (2), (3), (4), (5);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3);
+
+explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3);
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3);
diff --git a/ql/src/test/results/clientpositive/annotate_stats_filter.q.out b/ql/src/test/results/clientpositive/annotate_stats_filter.q.out
index 492e302..054b573 100644
--- a/ql/src/test/results/clientpositive/annotate_stats_filter.q.out
+++ b/ql/src/test/results/clientpositive/annotate_stats_filter.q.out
@@ -297,15 +297,15 @@ STAGE PLANS:
             alias: loc_orc
             Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
-              predicate: (not zip is not null) (type: boolean)
+              predicate: zip is null (type: boolean)
               Statistics: Num rows: 1 Data size: 102 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                expressions: state (type: string), locid (type: int), zip (type: bigint), year (type: int)
+                expressions: state (type: string), locid (type: int), null (type: bigint), year (type: int)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 1 Data size: 102 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 1 Data size: 102 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -375,7 +375,7 @@ STAGE PLANS:
             alias: loc_orc
             Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
-              predicate: (not zip is null) (type: boolean)
+              predicate: zip is not null (type: boolean)
               Statistics: Num rows: 7 Data size: 702 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: state (type: string), locid (type: int), zip (type: bigint), year (type: int)
diff --git a/ql/src/test/results/clientpositive/constprog_semijoin.q.out b/ql/src/test/results/clientpositive/constprog_semijoin.q.out
index 105f4c0..73dc2d5 100644
--- a/ql/src/test/results/clientpositive/constprog_semijoin.q.out
+++ b/ql/src/test/results/clientpositive/constprog_semijoin.q.out
@@ -406,17 +406,17 @@ STAGE PLANS:
             alias: table1
             Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (dimid <> 100) (type: boolean)
-              Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+              predicate: ((dimid <> 100) and dimid is not null) (type: boolean)
+              Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: id (type: int), val (type: string), val1 (type: string), dimid (type: int)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col3 (type: int), 100 (type: int)
                   sort order: ++
                   Map-reduce partition columns: _col3 (type: int), 100 (type: int)
-                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                   value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
           TableScan
             alias: table3
@@ -446,10 +446,10 @@ STAGE PLANS:
             0 _col3 (type: int), 100 (type: int)
             1 _col0 (type: int), _col1 (type: int)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/decimal_udf.q.out b/ql/src/test/results/clientpositive/decimal_udf.q.out
index 2ef9b93..75e6e68 100644
--- a/ql/src/test/results/clientpositive/decimal_udf.q.out
+++ b/ql/src/test/results/clientpositive/decimal_udf.q.out
@@ -973,12 +973,12 @@ STAGE PLANS:
           alias: decimal_udf
           Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
-            predicate: (key <> CAST( 0 AS decimal(20,10))) (type: boolean)
-            Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+            predicate: (key is not null and (key <> CAST( 0 AS decimal(20,10)))) (type: boolean)
+            Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: (key / key) (type: decimal(38,24))
               outputColumnNames: _col0
-              Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: SELECT key / key FROM DECIMAL_UDF WHERE key is not null and key <> 0
@@ -1039,12 +1039,12 @@ STAGE PLANS:
           alias: decimal_udf
           Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
-            predicate: (value <> 0) (type: boolean)
-            Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+            predicate: (value is not null and (value <> 0)) (type: boolean)
+            Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: (key / CAST( value AS decimal(10,0))) (type: decimal(31,21))
               outputColumnNames: _col0
-              Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: SELECT key / value FROM DECIMAL_UDF WHERE value is not null and value <> 0
@@ -1095,12 +1095,12 @@ STAGE PLANS:
           alias: decimal_udf
           Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
-            predicate: (value <> 0) (type: boolean)
-            Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+            predicate: (value is not null and (value <> 0)) (type: boolean)
+            Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: (UDFToDouble(key) / (UDFToDouble(value) / 2.0)) (type: double)
               outputColumnNames: _col0
-              Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 2 Data size: 239 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
diff --git a/ql/src/test/results/clientpositive/folder_predicate.q.out b/ql/src/test/results/clientpositive/folder_predicate.q.out
new file mode 100644
index 0000000..fa27412
--- /dev/null
+++ b/ql/src/test/results/clientpositive/folder_predicate.q.out
@@ -0,0 +1,368 @@
+PREHOOK: query: drop table if exists predicate_fold_tb
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table if exists predicate_fold_tb
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table predicate_fold_tb(value int)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@predicate_fold_tb
+POSTHOOK: query: create table predicate_fold_tb(value int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@predicate_fold_tb
+PREHOOK: query: insert into predicate_fold_tb values(NULL), (1), (2), (3), (4), (5)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@values__tmp__table__1
+PREHOOK: Output: default@predicate_fold_tb
+POSTHOOK: query: insert into predicate_fold_tb values(NULL), (1), (2), (3), (4), (5)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@values__tmp__table__1
+POSTHOOK: Output: default@predicate_fold_tb
+POSTHOOK: Lineage: predicate_fold_tb.value EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value <> 3)) (type: boolean)
+              Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value = 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+1
+2
+4
+5
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value < 3)) (type: boolean)
+              Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value >= 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+1
+2
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value > 3)) (type: boolean)
+              Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <= 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+4
+5
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value <= 3)) (type: boolean)
+              Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+1
+2
+3
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value >= 3)) (type: boolean)
+              Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 5 Data size: 5 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value < 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+3
+4
+5
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or (value = 3)) (type: boolean)
+              Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value <> 3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+3
+PREHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3)
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Map Operator Tree:
+          TableScan
+            alias: predicate_fold_tb
+            Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Filter Operator
+              predicate: (value is null or ((value <= 1) or (value > 3))) (type: boolean)
+              Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 6 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM predicate_fold_tb WHERE not(value IS NOT NULL AND value > 1 AND value <=3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@predicate_fold_tb
+#### A masked pattern was here ####
+NULL
+1
+4
+5
diff --git a/ql/src/test/results/clientpositive/input_testxpath2.q.out b/ql/src/test/results/clientpositive/input_testxpath2.q.out
index d3a6f29..67e270f 100644
--- a/ql/src/test/results/clientpositive/input_testxpath2.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath2.q.out
@@ -32,7 +32,7 @@ STAGE PLANS:
             alias: src_thrift
             Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
+              predicate: (lint is not null and mstringstring is not null) (type: boolean)
               Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: size(lint) (type: int), size(lintstring) (type: int), size(mstringstring) (type: int)
diff --git a/ql/src/test/results/clientpositive/list_bucket_query_oneskew_3.q.out b/ql/src/test/results/clientpositive/list_bucket_query_oneskew_3.q.out
index d0eb853..073f061 100644
--- a/ql/src/test/results/clientpositive/list_bucket_query_oneskew_3.q.out
+++ b/ql/src/test/results/clientpositive/list_bucket_query_oneskew_3.q.out
@@ -295,12 +295,12 @@ STAGE PLANS:
           GatherStats: false
           Filter Operator
             isSamplingPred: false
-            predicate: (not (x = 86)) (type: boolean)
-            Statistics: Num rows: 15 Data size: 60 Basic stats: COMPLETE Column stats: NONE
+            predicate: (x <> 86) (type: boolean)
+            Statistics: Num rows: 29 Data size: 117 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: x (type: int)
               outputColumnNames: _col0
-              Statistics: Num rows: 15 Data size: 60 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 29 Data size: 117 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: -- List Bucketing Query
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
index ef8ee2f..634e171 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
@@ -115,12 +115,12 @@ STAGE PLANS:
           GatherStats: false
           Filter Operator
             isSamplingPred: false
-            predicate: ((rand(1) < 0.1) and (not ((UDFToDouble(key) > 50.0) or (UDFToDouble(key) < 10.0)))) (type: boolean)
-            Statistics: Num rows: 56 Data size: 594 Basic stats: COMPLETE Column stats: NONE
+            predicate: ((rand(1) < 0.1) and ((UDFToDouble(key) <= 50.0) and (UDFToDouble(key) >= 10.0))) (type: boolean)
+            Statistics: Num rows: 18 Data size: 191 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: key (type: string), value (type: string), '2008-04-08' (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 56 Data size: 594 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 18 Data size: 191 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
@@ -247,12 +247,12 @@ STAGE PLANS:
           GatherStats: false
           Filter Operator
             isSamplingPred: false
-            predicate: (not ((UDFToDouble(key) > 50.0) or (UDFToDouble(key) < 10.0))) (type: boolean)
-            Statistics: Num rows: 168 Data size: 1784 Basic stats: COMPLETE Column stats: NONE
+            predicate: ((UDFToDouble(key) <= 50.0) and (UDFToDouble(key) >= 10.0)) (type: boolean)
+            Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: key (type: string), value (type: string), '2008-04-08' (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 168 Data size: 1784 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
               ListSink
 
 PREHOOK: query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
diff --git a/ql/src/test/results/clientpositive/select_unquote_not.q.out b/ql/src/test/results/clientpositive/select_unquote_not.q.out
index 64de433..3b8146b 100644
--- a/ql/src/test/results/clientpositive/select_unquote_not.q.out
+++ b/ql/src/test/results/clientpositive/select_unquote_not.q.out
@@ -59,15 +59,15 @@ STAGE PLANS:
             alias: npe_test
             Statistics: Num rows: 498 Data size: 5290 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (not (UDFToDouble(ds) < 1970.0)) (type: boolean)
-              Statistics: Num rows: 332 Data size: 3526 Basic stats: COMPLETE Column stats: NONE
+              predicate: (UDFToDouble(ds) >= 1970.0) (type: boolean)
+              Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 332 Data size: 3526 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 332 Data size: 3526 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/spark/constprog_semijoin.q.out b/ql/src/test/results/clientpositive/spark/constprog_semijoin.q.out
index 6fec254..60e33ac 100644
--- a/ql/src/test/results/clientpositive/spark/constprog_semijoin.q.out
+++ b/ql/src/test/results/clientpositive/spark/constprog_semijoin.q.out
@@ -415,13 +415,13 @@ STAGE PLANS:
                   alias: table1
                   Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: (dimid <> 100) (type: boolean)
-                    Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                    predicate: (dimid is not null and (dimid <> 100)) (type: boolean)
+                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                     Reduce Output Operator
                       key expressions: dimid (type: int)
                       sort order: +
                       Map-reduce partition columns: dimid (type: int)
-                      Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                       value expressions: id (type: int), val (type: string), val1 (type: string)
         Map 3 
             Map Operator Tree:
@@ -454,10 +454,10 @@ STAGE PLANS:
                   0 dimid (type: int)
                   1 _col1 (type: int)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/spark/vectorization_not.q.out b/ql/src/test/results/clientpositive/spark/vectorization_not.q.out
index b5587ba..32be565 100644
--- a/ql/src/test/results/clientpositive/spark/vectorization_not.q.out
+++ b/ql/src/test/results/clientpositive/spark/vectorization_not.q.out
@@ -1,4 +1,5 @@
 WARNING: Comparing a bigint and a double may result in a loss of precision.
+WARNING: Comparing a bigint and a double may result in a loss of precision.
 PREHOOK: query: SELECT AVG(cbigint),
        (-(AVG(cbigint))),
        (-6432 + AVG(cbigint)),
diff --git a/ql/src/test/results/clientpositive/tez/constprog_semijoin.q.out b/ql/src/test/results/clientpositive/tez/constprog_semijoin.q.out
index b538cf2..a10dee2 100644
--- a/ql/src/test/results/clientpositive/tez/constprog_semijoin.q.out
+++ b/ql/src/test/results/clientpositive/tez/constprog_semijoin.q.out
@@ -419,17 +419,17 @@ STAGE PLANS:
                   alias: table1
                   Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: (dimid <> 100) (type: boolean)
-                    Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                    predicate: ((dimid <> 100) and dimid is not null) (type: boolean)
+                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: id (type: int), val (type: string), val1 (type: string), dimid (type: int)
                       outputColumnNames: _col0, _col1, _col2, _col3
-                      Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                       Reduce Output Operator
                         key expressions: _col3 (type: int), 100 (type: int)
                         sort order: ++
                         Map-reduce partition columns: _col3 (type: int), 100 (type: int)
-                        Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
+                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                         value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
         Map 3 
             Map Operator Tree:
@@ -462,10 +462,10 @@ STAGE PLANS:
                   0 _col3 (type: int), 100 (type: int)
                   1 _col0 (type: int), _col1 (type: int)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 11 Data size: 220 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/tez/decimal_udf.q.out b/ql/src/test/results/clientpositive/tez/decimal_udf.q.out
new file mode 100644
index 0000000..9b7f948
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/decimal_udf.q.out
@@ -0,0 +1,2235 @@
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal(20,10), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@DECIMAL_UDF
+POSTHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal(20,10), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@DECIMAL_UDF
+PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv7.txt' INTO TABLE DECIMAL_UDF
+PREHOOK: type: LOAD
+#### A masked pattern was here ####
+PREHOOK: Output: default@decimal_udf
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv7.txt' INTO TABLE DECIMAL_UDF
+POSTHOOK: type: LOAD
+#### A masked pattern was here ####
+POSTHOOK: Output: default@decimal_udf
+PREHOOK: query: -- addition
+EXPLAIN SELECT key + key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- addition
+EXPLAIN SELECT key + key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key + key) (type: decimal(21,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key + key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key + key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-8800
+NULL
+0
+0
+200
+20
+2
+0.2
+0.02
+400
+40
+4
+0
+0.4
+0.04
+0.6
+0.66
+0.666
+-0.6
+-0.66
+-0.666
+2
+4
+6.28
+-2.24
+-2.24
+-2.244
+2.24
+2.244
+248
+250.4
+-2510.98
+6.28
+6.28
+6.28
+2
+-2469135780.246913578
+2469135780.24691356
+PREHOOK: query: EXPLAIN SELECT key + value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key + value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key + CAST( value AS decimal(10,0))) (type: decimal(21,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key + value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key + value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+0
+NULL
+0
+0
+200
+20
+2
+0.1
+0.01
+400
+40
+4
+0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+2
+4
+6.14
+-2.12
+-2.12
+-12.122
+2.12
+2.122
+248
+250.2
+-2510.49
+6.14
+6.14
+7.14
+2
+-2469135780.123456789
+2469135780.12345678
+PREHOOK: query: EXPLAIN SELECT key + (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key + (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) + (UDFToDouble(value) / 2.0)) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key + (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key + (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-2200.0
+NULL
+0.0
+0.0
+150.0
+15.0
+1.5
+0.1
+0.01
+300.0
+30.0
+3.0
+0.0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+1.5
+3.0
+4.640000000000001
+-1.62
+-1.62
+-6.622
+1.62
+1.622
+186.0
+187.7
+-1882.99
+4.640000000000001
+4.640000000000001
+5.140000000000001
+1.5
+-1.8518518351234567E9
+1.8518518351234567E9
+PREHOOK: query: EXPLAIN SELECT key + '1.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key + '1.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) + 1.0) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key + '1.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key + '1.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4399.0
+NULL
+1.0
+1.0
+101.0
+11.0
+2.0
+1.1
+1.01
+201.0
+21.0
+3.0
+1.0
+1.2
+1.02
+1.3
+1.33
+1.333
+0.7
+0.6699999999999999
+0.667
+2.0
+3.0
+4.140000000000001
+-0.1200000000000001
+-0.1200000000000001
+-0.12200000000000011
+2.12
+2.122
+125.0
+126.2
+-1254.49
+4.140000000000001
+4.140000000000001
+4.140000000000001
+2.0
+-1.2345678891234567E9
+1.2345678911234567E9
+PREHOOK: query: -- substraction
+EXPLAIN SELECT key - key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- substraction
+EXPLAIN SELECT key - key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key - key) (type: decimal(21,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key - key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key - key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+0
+NULL
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+0
+PREHOOK: query: EXPLAIN SELECT key - value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key - value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key - CAST( value AS decimal(10,0))) (type: decimal(21,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key - value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key - value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-8800
+NULL
+0
+0
+0
+0
+0
+0.1
+0.01
+0
+0
+0
+0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+0
+0
+0.14
+-0.12
+-0.12
+9.878
+0.12
+0.122
+0
+0.2
+-0.49
+0.14
+0.14
+-0.86
+0
+-0.123456789
+0.12345678
+PREHOOK: query: EXPLAIN SELECT key - (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key - (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) - (UDFToDouble(value) / 2.0)) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key - (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key - (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-6600.0
+NULL
+0.0
+0.0
+50.0
+5.0
+0.5
+0.1
+0.01
+100.0
+10.0
+1.0
+0.0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+0.5
+1.0
+1.6400000000000001
+-0.6200000000000001
+-0.6200000000000001
+4.378
+0.6200000000000001
+0.6220000000000001
+62.0
+62.7
+-627.99
+1.6400000000000001
+1.6400000000000001
+1.1400000000000001
+0.5
+-6.172839451234567E8
+6.172839451234567E8
+PREHOOK: query: EXPLAIN SELECT key - '1.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key - '1.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) - 1.0) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key - '1.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key - '1.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4401.0
+NULL
+-1.0
+-1.0
+99.0
+9.0
+0.0
+-0.9
+-0.99
+199.0
+19.0
+1.0
+-1.0
+-0.8
+-0.98
+-0.7
+-0.6699999999999999
+-0.667
+-1.3
+-1.33
+-1.333
+0.0
+1.0
+2.14
+-2.12
+-2.12
+-2.122
+0.1200000000000001
+0.12200000000000011
+123.0
+124.2
+-1256.49
+2.14
+2.14
+2.14
+0.0
+-1.2345678911234567E9
+1.2345678891234567E9
+PREHOOK: query: -- multiplication
+EXPLAIN SELECT key * key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- multiplication
+EXPLAIN SELECT key * key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key * key) (type: decimal(38,20))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key * key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key * key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+19360000
+NULL
+0
+0
+10000
+100
+1
+0.01
+0.0001
+40000
+400
+4
+0
+0.04
+0.0004
+0.09
+0.1089
+0.110889
+0.09
+0.1089
+0.110889
+1
+4
+9.8596
+1.2544
+1.2544
+1.258884
+1.2544
+1.258884
+15376
+15675.04
+1576255.1401
+9.8596
+9.8596
+9.8596
+1
+NULL
+NULL
+PREHOOK: query: EXPLAIN SELECT key, value FROM DECIMAL_UDF where key * value > 0
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key, value FROM DECIMAL_UDF where key * value > 0
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Filter Operator
+            predicate: ((key * CAST( value AS decimal(10,0))) > CAST( 0 AS decimal(31,10))) (type: boolean)
+            Select Operator
+              expressions: key (type: decimal(20,10)), value (type: int)
+              outputColumnNames: _col0, _col1
+              ListSink
+
+PREHOOK: query: SELECT key, value FROM DECIMAL_UDF where key * value > 0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key, value FROM DECIMAL_UDF where key * value > 0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+100	100
+10	10
+1	1
+200	200
+20	20
+2	2
+1	1
+2	2
+3.14	3
+-1.12	-1
+-1.12	-1
+-1.122	-11
+1.12	1
+1.122	1
+124	124
+125.2	125
+-1255.49	-1255
+3.14	3
+3.14	3
+3.14	4
+1	1
+-1234567890.123456789	-1234567890
+1234567890.12345678	1234567890
+PREHOOK: query: EXPLAIN SELECT key * value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key * value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key * CAST( value AS decimal(10,0))) (type: decimal(31,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key * value FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key * value FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-19360000
+NULL
+0
+0
+10000
+100
+1
+0
+0
+40000
+400
+4
+0
+0
+0
+0
+0
+0
+0
+0
+0
+1
+4
+9.42
+1.12
+1.12
+12.342
+1.12
+1.122
+15376
+15650
+1575639.95
+9.42
+9.42
+12.56
+1
+1524157875171467887.50190521
+1524157875171467876.3907942
+PREHOOK: query: EXPLAIN SELECT key * (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key * (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) * (UDFToDouble(value) / 2.0)) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key * (value/2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key * (value/2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-9680000.0
+NULL
+0.0
+0.0
+5000.0
+50.0
+0.5
+0.0
+0.0
+20000.0
+200.0
+2.0
+0.0
+0.0
+0.0
+0.0
+0.0
+0.0
+-0.0
+-0.0
+-0.0
+0.5
+2.0
+4.71
+0.56
+0.56
+6.171
+0.56
+0.561
+7688.0
+7825.0
+787819.975
+4.71
+4.71
+6.28
+0.5
+7.6207893758573389E17
+7.6207893758573389E17
+PREHOOK: query: EXPLAIN SELECT key * '2.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key * '2.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) * 2.0) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT key * '2.0' FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key * '2.0' FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-8800.0
+NULL
+0.0
+0.0
+200.0
+20.0
+2.0
+0.2
+0.02
+400.0
+40.0
+4.0
+0.0
+0.4
+0.04
+0.6
+0.66
+0.666
+-0.6
+-0.66
+-0.666
+2.0
+4.0
+6.28
+-2.24
+-2.24
+-2.244
+2.24
+2.244
+248.0
+250.4
+-2510.98
+6.28
+6.28
+6.28
+2.0
+-2.4691357802469134E9
+2.4691357802469134E9
+PREHOOK: query: -- division
+EXPLAIN SELECT key / 0 FROM DECIMAL_UDF limit 1
+PREHOOK: type: QUERY
+POSTHOOK: query: -- division
+EXPLAIN SELECT key / 0 FROM DECIMAL_UDF limit 1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (key / CAST( 0 AS decimal(10,0))) (type: decimal(22,12))
+            outputColumnNames: _col0
+            Limit
+              Number of rows: 1
+              ListSink
+
+PREHOOK: query: SELECT key / 0 FROM DECIMAL_UDF limit 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key / 0 FROM DECIMAL_UDF limit 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: EXPLAIN SELECT key / NULL FROM DECIMAL_UDF limit 1
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key / NULL FROM DECIMAL_UDF limit 1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (UDFToDouble(key) / null) (type: double)
+            outputColumnNames: _col0
+            Limit
+              Number of rows: 1
+              ListSink
+
+PREHOOK: query: SELECT key / NULL FROM DECIMAL_UDF limit 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key / NULL FROM DECIMAL_UDF limit 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: EXPLAIN SELECT key / key FROM DECIMAL_UDF WHERE key is not null and key <> 0
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key / key FROM DECIMAL_UDF WHERE key is not null and key <> 0
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Filter Operator
+            predicate: (key is not null and (key <> CAST( 0 AS decimal(20,10)))) (type: boolean)
+            Select Operator
+              expressions: (key / key) (type: decimal(38,24))
+              outputColumnNames: _col0
+              ListSink
+
+PREHOOK: query: SELECT key / key FROM DECIMAL_UDF WHERE key is not null and key <> 0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key / key FROM DECIMAL_UDF WHERE key is not null and key <> 0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+PREHOOK: query: EXPLAIN SELECT key / value FROM DECIMAL_UDF WHERE value is not null and value <> 0
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key / value FROM DECIMAL_UDF WHERE value is not null and value <> 0
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Filter Operator
+            predicate: (value is not null and (value <> 0)) (type: boolean)
+            Select Operator
+              expressions: (key / CAST( value AS decimal(10,0))) (type: decimal(31,21))
+              outputColumnNames: _col0
+              ListSink
+
+PREHOOK: query: SELECT key / value FROM DECIMAL_UDF WHERE value is not null and value <> 0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key / value FROM DECIMAL_UDF WHERE value is not null and value <> 0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-1
+1
+1
+1
+1
+1
+1
+1
+1
+1.046666666666666666667
+1.12
+1.12
+0.102
+1.12
+1.122
+1
+1.0016
+1.000390438247011952191
+1.046666666666666666667
+1.046666666666666666667
+0.785
+1
+1.0000000001
+1.00000000009999999271
+PREHOOK: query: EXPLAIN SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Filter Operator
+            predicate: (value is not null and (value <> 0)) (type: boolean)
+            Select Operator
+              expressions: (UDFToDouble(key) / (UDFToDouble(value) / 2.0)) (type: double)
+              outputColumnNames: _col0
+              ListSink
+
+PREHOOK: query: SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-2.0
+2.0
+2.0
+2.0
+2.0
+2.0
+2.0
+2.0
+2.0
+2.0933333333333333
+2.24
+2.24
+0.20400000000000001
+2.24
+2.244
+2.0
+2.0032
+2.000780876494024
+2.0933333333333333
+2.0933333333333333
+1.57
+2.0
+2.0000000002
+2.0000000002
+PREHOOK: query: EXPLAIN SELECT 1 + (key / '2.0') FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT 1 + (key / '2.0') FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (1.0 + (UDFToDouble(key) / 2.0)) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT 1 + (key / '2.0') FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT 1 + (key / '2.0') FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-2199.0
+NULL
+1.0
+1.0
+51.0
+6.0
+1.5
+1.05
+1.005
+101.0
+11.0
+2.0
+1.0
+1.1
+1.01
+1.15
+1.165
+1.1665
+0.85
+0.835
+0.8335
+1.5
+2.0
+2.5700000000000003
+0.43999999999999995
+0.43999999999999995
+0.43899999999999995
+1.56
+1.561
+63.0
+63.6
+-626.745
+2.5700000000000003
+2.5700000000000003
+2.5700000000000003
+1.5
+-6.172839440617284E8
+6.172839460617284E8
+PREHOOK: query: -- abs
+EXPLAIN SELECT abs(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- abs
+EXPLAIN SELECT abs(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: abs(key) (type: decimal(20,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT abs(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT abs(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+4400
+NULL
+0
+0
+100
+10
+1
+0.1
+0.01
+200
+20
+2
+0
+0.2
+0.02
+0.3
+0.33
+0.333
+0.3
+0.33
+0.333
+1
+2
+3.14
+1.12
+1.12
+1.122
+1.12
+1.122
+124
+125.2
+1255.49
+3.14
+3.14
+3.14
+1
+1234567890.123456789
+1234567890.12345678
+PREHOOK: query: -- avg
+EXPLAIN SELECT value, sum(key) / count(key), avg(key), sum(key) FROM DECIMAL_UDF GROUP BY value ORDER BY value
+PREHOOK: type: QUERY
+POSTHOOK: query: -- avg
+EXPLAIN SELECT value, sum(key) / count(key), avg(key), sum(key) FROM DECIMAL_UDF GROUP BY value ORDER BY value
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: value (type: int), key (type: decimal(20,10))
+                    outputColumnNames: _col0, _col1
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: sum(_col1), count(_col1), avg(_col1)
+                      keys: _col0 (type: int)
+                      mode: hash
+                      outputColumnNames: _col0, _col1, _col2, _col3
+                      Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: decimal(30,10)), _col2 (type: bigint), _col3 (type: struct<count:bigint,sum:decimal(30,10),input:decimal(20,10)>)
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: sum(VALUE._col0), count(VALUE._col1), avg(VALUE._col2)
+                keys: KEY._col0 (type: int)
+                mode: mergepartial
+                outputColumnNames: _col0, _col1, _col2, _col3
+                Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                Select Operator
+                  expressions: _col0 (type: int), (_col1 / CAST( _col2 AS decimal(19,0))) (type: decimal(38,23)), _col3 (type: decimal(24,14)), _col1 (type: decimal(30,10))
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                  Reduce Output Operator
+                    key expressions: _col0 (type: int)
+                    sort order: +
+                    Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                    value expressions: _col1 (type: decimal(38,23)), _col2 (type: decimal(24,14)), _col3 (type: decimal(30,10))
+        Reducer 3 
+            Reduce Operator Tree:
+              Select Operator
+                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(38,23)), VALUE._col1 (type: decimal(24,14)), VALUE._col2 (type: decimal(30,10))
+                outputColumnNames: _col0, _col1, _col2, _col3
+                Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT value, sum(key) / count(key), avg(key), sum(key) FROM DECIMAL_UDF GROUP BY value ORDER BY value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT value, sum(key) / count(key), avg(key), sum(key) FROM DECIMAL_UDF GROUP BY value ORDER BY value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-1234567890	-1234567890.123456789	-1234567890.123456789	-1234567890.123456789
+-1255	-1255.49	-1255.49	-1255.49
+-11	-1.122	-1.122	-1.122
+-1	-1.12	-1.12	-2.24
+0	0.02538461538461538461538	0.02538461538462	0.33
+1	1.0484	1.0484	5.242
+2	2	2	4
+3	3.14	3.14	9.42
+4	3.14	3.14	3.14
+10	10	10	10
+20	20	20	20
+100	100	100	100
+124	124	124	124
+125	125.2	125.2	125.2
+200	200	200	200
+4400	-4400	-4400	-4400
+1234567890	1234567890.12345678	1234567890.12345678	1234567890.12345678
+PREHOOK: query: -- negative
+EXPLAIN SELECT -key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- negative
+EXPLAIN SELECT -key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: (- key) (type: decimal(20,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT -key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT -key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+4400
+NULL
+0
+0
+-100
+-10
+-1
+-0.1
+-0.01
+-200
+-20
+-2
+0
+-0.2
+-0.02
+-0.3
+-0.33
+-0.333
+0.3
+0.33
+0.333
+-1
+-2
+-3.14
+1.12
+1.12
+1.122
+-1.12
+-1.122
+-124
+-125.2
+1255.49
+-3.14
+-3.14
+-3.14
+-1
+1234567890.123456789
+-1234567890.12345678
+PREHOOK: query: -- positive
+EXPLAIN SELECT +key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- positive
+EXPLAIN SELECT +key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: key (type: decimal(20,10))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT +key FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT +key FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4400
+NULL
+0
+0
+100
+10
+1
+0.1
+0.01
+200
+20
+2
+0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+1
+2
+3.14
+-1.12
+-1.12
+-1.122
+1.12
+1.122
+124
+125.2
+-1255.49
+3.14
+3.14
+3.14
+1
+-1234567890.123456789
+1234567890.12345678
+PREHOOK: query: -- ceiling
+EXPlAIN SELECT CEIL(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- ceiling
+EXPlAIN SELECT CEIL(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: ceil(key) (type: decimal(11,0))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT CEIL(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT CEIL(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4400
+NULL
+0
+0
+100
+10
+1
+1
+1
+200
+20
+2
+0
+1
+1
+1
+1
+1
+0
+0
+0
+1
+2
+4
+-1
+-1
+-1
+2
+2
+124
+126
+-1255
+4
+4
+4
+1
+-1234567890
+1234567891
+PREHOOK: query: -- floor
+EXPLAIN SELECT FLOOR(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- floor
+EXPLAIN SELECT FLOOR(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: floor(key) (type: decimal(11,0))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT FLOOR(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT FLOOR(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4400
+NULL
+0
+0
+100
+10
+1
+0
+0
+200
+20
+2
+0
+0
+0
+0
+0
+0
+-1
+-1
+-1
+1
+2
+3
+-2
+-2
+-2
+1
+1
+124
+125
+-1256
+3
+3
+3
+1
+-1234567891
+1234567890
+PREHOOK: query: -- round
+EXPLAIN SELECT ROUND(key, 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- round
+EXPLAIN SELECT ROUND(key, 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: round(key, 2) (type: decimal(13,2))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT ROUND(key, 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT ROUND(key, 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-4400
+NULL
+0
+0
+100
+10
+1
+0.1
+0.01
+200
+20
+2
+0
+0.2
+0.02
+0.3
+0.33
+0.33
+-0.3
+-0.33
+-0.33
+1
+2
+3.14
+-1.12
+-1.12
+-1.12
+1.12
+1.12
+124
+125.2
+-1255.49
+3.14
+3.14
+3.14
+1
+-1234567890.12
+1234567890.12
+PREHOOK: query: -- power
+EXPLAIN SELECT POWER(key, 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- power
+EXPLAIN SELECT POWER(key, 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: power(key, 2) (type: double)
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT POWER(key, 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT POWER(key, 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+1.936E7
+NULL
+0.0
+0.0
+10000.0
+100.0
+1.0
+0.010000000000000002
+1.0E-4
+40000.0
+400.0
+4.0
+0.0
+0.04000000000000001
+4.0E-4
+0.09
+0.10890000000000001
+0.11088900000000002
+0.09
+0.10890000000000001
+0.11088900000000002
+1.0
+4.0
+9.8596
+1.2544000000000002
+1.2544000000000002
+1.2588840000000003
+1.2544000000000002
+1.2588840000000003
+15376.0
+15675.04
+1576255.1401
+9.8596
+9.8596
+9.8596
+1.0
+1.52415787532388352E18
+1.52415787532388352E18
+PREHOOK: query: -- modulo
+EXPLAIN SELECT (key + 1) % (key / 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- modulo
+EXPLAIN SELECT (key + 1) % (key / 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: decimal_udf
+          Select Operator
+            expressions: ((key + CAST( 1 AS decimal(10,0))) % (key / CAST( 2 AS decimal(10,0)))) (type: decimal(22,12))
+            outputColumnNames: _col0
+            ListSink
+
+PREHOOK: query: SELECT (key + 1) % (key / 2) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT (key + 1) % (key / 2) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-2199
+NULL
+NULL
+NULL
+1
+1
+0
+0
+0
+1
+1
+0
+NULL
+0
+0
+0.1
+0.01
+0.001
+0.1
+0.01
+0.001
+0
+0
+1
+-0.12
+-0.12
+-0.122
+0.44
+0.439
+1
+1
+-626.745
+1
+1
+1
+0
+-617283944.0617283945
+1
+PREHOOK: query: -- stddev, var
+EXPLAIN SELECT value, stddev(key), variance(key) FROM DECIMAL_UDF GROUP BY value
+PREHOOK: type: QUERY
+POSTHOOK: query: -- stddev, var
+EXPLAIN SELECT value, stddev(key), variance(key) FROM DECIMAL_UDF GROUP BY value
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: value (type: int), key (type: decimal(20,10))
+                    outputColumnNames: _col0, _col1
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: stddev(_col1), variance(_col1)
+                      keys: _col0 (type: int)
+                      mode: hash
+                      outputColumnNames: _col0, _col1, _col2
+                      Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: struct<count:bigint,sum:double,variance:double>), _col2 (type: struct<count:bigint,sum:double,variance:double>)
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: stddev(VALUE._col0), variance(VALUE._col1)
+                keys: KEY._col0 (type: int)
+                mode: mergepartial
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT value, stddev(key), variance(key) FROM DECIMAL_UDF GROUP BY value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT value, stddev(key), variance(key) FROM DECIMAL_UDF GROUP BY value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-1234567890	0.0	0.0
+-1255	0.0	0.0
+-11	0.0	0.0
+-1	0.0	0.0
+0	0.22561046704494161	0.050900082840236685
+1	0.05928102563215321	0.0035142400000000066
+2	0.0	0.0
+3	0.0	0.0
+4	0.0	0.0
+10	0.0	0.0
+20	0.0	0.0
+100	0.0	0.0
+124	0.0	0.0
+125	0.0	0.0
+200	0.0	0.0
+4400	0.0	0.0
+1234567890	0.0	0.0
+PREHOOK: query: -- stddev_samp, var_samp
+EXPLAIN SELECT value, stddev_samp(key), var_samp(key) FROM DECIMAL_UDF GROUP BY value
+PREHOOK: type: QUERY
+POSTHOOK: query: -- stddev_samp, var_samp
+EXPLAIN SELECT value, stddev_samp(key), var_samp(key) FROM DECIMAL_UDF GROUP BY value
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: value (type: int), key (type: decimal(20,10))
+                    outputColumnNames: _col0, _col1
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: stddev_samp(_col1), var_samp(_col1)
+                      keys: _col0 (type: int)
+                      mode: hash
+                      outputColumnNames: _col0, _col1, _col2
+                      Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: struct<count:bigint,sum:double,variance:double>), _col2 (type: struct<count:bigint,sum:double,variance:double>)
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: stddev_samp(VALUE._col0), var_samp(VALUE._col1)
+                keys: KEY._col0 (type: int)
+                mode: mergepartial
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 119 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT value, stddev_samp(key), var_samp(key) FROM DECIMAL_UDF GROUP BY value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT value, stddev_samp(key), var_samp(key) FROM DECIMAL_UDF GROUP BY value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-1234567890	0.0	0.0
+-1255	0.0	0.0
+-11	0.0	0.0
+-1	0.0	0.0
+0	0.2348228191855647	0.055141756410256405
+1	0.06627820154470102	0.004392800000000008
+2	0.0	0.0
+3	0.0	0.0
+4	0.0	0.0
+10	0.0	0.0
+20	0.0	0.0
+100	0.0	0.0
+124	0.0	0.0
+125	0.0	0.0
+200	0.0	0.0
+4400	0.0	0.0
+1234567890	0.0	0.0
+PREHOOK: query: -- histogram
+EXPLAIN SELECT histogram_numeric(key, 3) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- histogram
+EXPLAIN SELECT histogram_numeric(key, 3) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: key (type: decimal(20,10))
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: histogram_numeric(_col0, 3)
+                      mode: hash
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                      Reduce Output Operator
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                        value expressions: _col0 (type: array<double>)
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: histogram_numeric(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT histogram_numeric(key, 3) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT histogram_numeric(key, 3) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+[{"x":-1.2345678901234567E9,"y":1.0},{"x":-144.50057142857142,"y":35.0},{"x":1.2345678901234567E9,"y":1.0}]
+PREHOOK: query: -- min
+EXPLAIN SELECT MIN(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- min
+EXPLAIN SELECT MIN(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: key (type: decimal(20,10))
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: min(_col0)
+                      mode: hash
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: decimal(20,10))
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: min(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT MIN(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT MIN(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+-1234567890.123456789
+PREHOOK: query: -- max
+EXPLAIN SELECT MAX(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- max
+EXPLAIN SELECT MAX(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: key (type: decimal(20,10))
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: max(_col0)
+                      mode: hash
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: decimal(20,10))
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: max(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT MAX(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT MAX(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+1234567890.12345678
+PREHOOK: query: -- count
+EXPLAIN SELECT COUNT(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+POSTHOOK: query: -- count
+EXPLAIN SELECT COUNT(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: decimal_udf
+                  Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: key (type: decimal(20,10))
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 3 Data size: 359 Basic stats: COMPLETE Column stats: NONE
+                    Group By Operator
+                      aggregations: count(_col0)
+                      mode: hash
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: bigint)
+        Reducer 2 
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: count(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT COUNT(key) FROM DECIMAL_UDF
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(key) FROM DECIMAL_UDF
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_udf
+#### A masked pattern was here ####
+37
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@decimal_udf
+PREHOOK: Output: default@decimal_udf
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@decimal_udf
+POSTHOOK: Output: default@decimal_udf
diff --git a/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out b/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out
index 06f1ca4..99120bb 100644
--- a/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out
+++ b/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out
@@ -289,13 +289,13 @@ STAGE PLANS:
                   GatherStats: false
                   Filter Operator
                     isSamplingPred: false
-                    predicate: (value <> '') (type: boolean)
-                    Statistics: Num rows: 25 Data size: 211 Basic stats: COMPLETE Column stats: NONE
+                    predicate: ((value <> '') and value is not null) (type: boolean)
+                    Statistics: Num rows: 13 Data size: 109 Basic stats: COMPLETE Column stats: NONE
                     Reduce Output Operator
                       key expressions: value (type: string)
                       sort order: +
                       Map-reduce partition columns: value (type: string)
-                      Statistics: Num rows: 25 Data size: 211 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 13 Data size: 109 Basic stats: COMPLETE Column stats: NONE
                       tag: 1
                       auto parallelism: true
             Path -> Alias:
@@ -379,17 +379,17 @@ STAGE PLANS:
                   1 value (type: string)
                 outputColumnNames: _col0, _col13
                 Position of Big Table: 0
-                Statistics: Num rows: 27 Data size: 232 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 15 Data size: 130 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
                   expressions: _col0 (type: int), _col13 (type: string)
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 27 Data size: 232 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 15 Data size: 130 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
 #### A masked pattern was here ####
                     NumFilesPerFileSink: 1
-                    Statistics: Num rows: 27 Data size: 232 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 15 Data size: 130 Basic stats: COMPLETE Column stats: NONE
 #### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
diff --git a/ql/src/test/results/clientpositive/tez/vector_decimal_udf.q.out b/ql/src/test/results/clientpositive/tez/vector_decimal_udf.q.out
index 04e658c..8a78ffb 100644
--- a/ql/src/test/results/clientpositive/tez/vector_decimal_udf.q.out
+++ b/ql/src/test/results/clientpositive/tez/vector_decimal_udf.q.out
@@ -1239,15 +1239,15 @@ STAGE PLANS:
                   alias: decimal_udf
                   Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: (key <> CAST( 0 AS decimal(20,10))) (type: boolean)
-                    Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                    predicate: (key is not null and (key <> CAST( 0 AS decimal(20,10)))) (type: boolean)
+                    Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: (key / key) (type: decimal(38,24))
                       outputColumnNames: _col0
-                      Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                        Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1321,15 +1321,15 @@ STAGE PLANS:
                   alias: decimal_udf
                   Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: (value <> 0) (type: boolean)
-                    Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                    predicate: (value is not null and (value <> 0)) (type: boolean)
+                    Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: (key / CAST( value AS decimal(10,0))) (type: decimal(31,21))
                       outputColumnNames: _col0
-                      Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                        Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1393,15 +1393,15 @@ STAGE PLANS:
                   alias: decimal_udf
                   Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: (value <> 0) (type: boolean)
-                    Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                    predicate: (value is not null and (value <> 0)) (type: boolean)
+                    Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: (UDFToDouble(key) / (UDFToDouble(value) / 2.0)) (type: double)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                        Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out b/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
index d459ce3..b59a5b9 100644
--- a/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
+++ b/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
@@ -97,7 +97,7 @@ STAGE PLANS:
           alias: src_thrift
           Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
-            predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
+            predicate: (lint is not null and mstringstring is not null) (type: boolean)
             Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint is not null (type: boolean), lintstring is not null (type: boolean), mstringstring is not null (type: boolean)
diff --git a/ql/src/test/results/clientpositive/udf_size.q.out b/ql/src/test/results/clientpositive/udf_size.q.out
index efb06a1..13594d2 100644
--- a/ql/src/test/results/clientpositive/udf_size.q.out
+++ b/ql/src/test/results/clientpositive/udf_size.q.out
@@ -38,7 +38,7 @@ STAGE PLANS:
           alias: src_thrift
           Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
-            predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
+            predicate: (lint is not null and mstringstring is not null) (type: boolean)
             Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: size(lint) (type: int), size(lintstring) (type: int), size(mstringstring) (type: int), -1 (type: int)
diff --git a/ql/src/test/results/clientpositive/union_offcbo.q.out b/ql/src/test/results/clientpositive/union_offcbo.q.out
index 5351597..0d0910e 100644
--- a/ql/src/test/results/clientpositive/union_offcbo.q.out
+++ b/ql/src/test/results/clientpositive/union_offcbo.q.out
@@ -286,7 +286,7 @@ STAGE PLANS:
           outputColumnNames: _col8, _col9, _col10, _col12, _col13, _col16, _col17, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col18 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col18 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col10 (type: bigint), _col16 (type: string), _col17 (type: bigint), _col13 (type: string), _col18 (type: string), _col19 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col12 >= '2016-02-05'))) THEN ('DEL') WHEN (((_col18 is not null and _col8 is null) and (_col12 <= '2016-02-05'))) THEN ('RET') WHEN (((_col18 = _col8) and (_col19 <> _col9))) THEN ('A_INS') ELSE ('NA') END (type: string)
@@ -379,7 +379,7 @@ STAGE PLANS:
           outputColumnNames: _col0, _col1, _col6, _col7, _col8, _col9, _col11, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col8 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col8 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col0 (type: bigint), _col6 (type: string), _col7 (type: bigint), '2099-12-31' (type: string), _col8 (type: string), _col9 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col11 <= _col1))) THEN ('DEL') WHEN (((_col18 is null and _col8 is not null) or ((_col18 = _col8) and (_col19 <> _col9)))) THEN ('INS') ELSE ('NA') END (type: string)
@@ -627,7 +627,7 @@ STAGE PLANS:
           outputColumnNames: _col8, _col9, _col10, _col12, _col13, _col16, _col17, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col18 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col18 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col10 (type: bigint), _col16 (type: string), _col17 (type: bigint), _col13 (type: string), _col18 (type: string), _col19 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col12 >= '2016-02-05'))) THEN ('DEL') WHEN (((_col18 is not null and _col8 is null) and (_col12 <= '2016-02-05'))) THEN ('RET') WHEN (((_col18 = _col8) and (_col19 <> _col9))) THEN ('A_INS') ELSE ('NA') END (type: string)
@@ -723,7 +723,7 @@ STAGE PLANS:
           outputColumnNames: _col0, _col1, _col6, _col7, _col8, _col9, _col11, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col8 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col8 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col0 (type: bigint), _col6 (type: string), _col7 (type: bigint), '2099-12-31' (type: string), _col8 (type: string), _col9 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col11 <= _col1))) THEN ('DEL') WHEN (((_col18 is null and _col8 is not null) or ((_col18 = _col8) and (_col19 <> _col9)))) THEN ('INS') ELSE ('NA') END (type: string)
@@ -968,7 +968,7 @@ STAGE PLANS:
           outputColumnNames: _col8, _col9, _col10, _col12, _col13, _col16, _col17, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col18 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col18 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col10 (type: bigint), _col16 (type: string), _col17 (type: bigint), _col13 (type: string), _col18 (type: string), _col19 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col12 >= '2016-02-05'))) THEN ('DEL') WHEN (((_col18 is not null and _col8 is null) and (_col12 <= '2016-02-05'))) THEN ('RET') WHEN (((_col18 = _col8) and (_col19 <> _col9))) THEN ('A_INS') ELSE ('NA') END (type: string)
@@ -1064,7 +1064,7 @@ STAGE PLANS:
           outputColumnNames: _col0, _col1, _col6, _col7, _col8, _col9, _col11, _col18, _col19
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
           Filter Operator
-            predicate: ((not ((if _col8 is null returns-1 = if _col18 is null returns-1) and (if _col9 is null returns-1 = if _col19 is null returns-1))) and _col8 is not null) (type: boolean)
+            predicate: (((if _col8 is null returns-1 <> if _col18 is null returns-1) or (if _col9 is null returns-1 <> if _col19 is null returns-1)) and _col8 is not null) (type: boolean)
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             Select Operator
               expressions: _col0 (type: bigint), _col6 (type: string), _col7 (type: bigint), '2099-12-31' (type: string), _col8 (type: string), _col9 (type: string), CASE WHEN (((_col18 is not null and _col8 is null) and (_col11 <= _col1))) THEN ('DEL') WHEN (((_col18 is null and _col8 is not null) or ((_col18 = _col8) and (_col19 <> _col9)))) THEN ('INS') ELSE ('NA') END (type: string)
diff --git a/ql/src/test/results/clientpositive/vector_decimal_udf.q.out b/ql/src/test/results/clientpositive/vector_decimal_udf.q.out
index 4cc3fdf..ffa3138 100644
--- a/ql/src/test/results/clientpositive/vector_decimal_udf.q.out
+++ b/ql/src/test/results/clientpositive/vector_decimal_udf.q.out
@@ -1191,15 +1191,15 @@ STAGE PLANS:
             alias: decimal_udf
             Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (key <> CAST( 0 AS decimal(20,10))) (type: boolean)
-              Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+              predicate: (key is not null and (key <> CAST( 0 AS decimal(20,10)))) (type: boolean)
+              Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: (key / key) (type: decimal(38,24))
                 outputColumnNames: _col0
-                Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1270,15 +1270,15 @@ STAGE PLANS:
             alias: decimal_udf
             Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (value <> 0) (type: boolean)
-              Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+              predicate: (value is not null and (value <> 0)) (type: boolean)
+              Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: (key / CAST( value AS decimal(10,0))) (type: decimal(31,21))
                 outputColumnNames: _col0
-                Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1339,15 +1339,15 @@ STAGE PLANS:
             alias: decimal_udf
             Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
-              predicate: (value <> 0) (type: boolean)
-              Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+              predicate: (value is not null and (value <> 0)) (type: boolean)
+              Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: (UDFToDouble(key) / (UDFToDouble(value) / 2.0)) (type: double)
                 outputColumnNames: _col0
-                Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 38 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 19 Data size: 2148 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-- 
1.7.9.5

