From 6ee9af215c9c42daf8f3156ddf59878bbb02f48a Mon Sep 17 00:00:00 2001
From: Chinna Rao L <chinnaraol@apache.org>
Date: Thu, 24 Mar 2016 14:03:16 +0530
Subject: [PATCH 0544/1164] CDH-30121 : HIVE-13217 : Replication for HoS
 mapjoin small file needs to respect
 dfs.replication.max (Chinna Rao L , via Szehon
 Ho)

Conflicts:
	ql/src/java/org/apache/hadoop/hive/ql/exec/SparkHashTableSinkOperator.java

Change-Id: I8905acd337143c3fb705916632bc053b23fe638b
---
 .../hive/ql/exec/SparkHashTableSinkOperator.java   |    9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/SparkHashTableSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/SparkHashTableSinkOperator.java
index b69d079..7d51a1b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/SparkHashTableSinkOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/SparkHashTableSinkOperator.java
@@ -44,11 +44,13 @@
 
 public class SparkHashTableSinkOperator
     extends TerminalOperator<SparkHashTableSinkDesc> implements Serializable {
-  private static final int MIN_REPLICATION = 10;
   private static final long serialVersionUID = 1L;
   private final String CLASS_NAME = this.getClass().getName();
   private final PerfLogger perfLogger = SessionState.getPerfLogger();
+
   protected static final Log LOG = LogFactory.getLog(SparkHashTableSinkOperator.class.getName());
+  public static final String DFS_REPLICATION_MAX = "dfs.replication.max";
+  private int minReplication = 10;
 
   private HashTableSinkOperator htsOperator;
 
@@ -64,6 +66,9 @@ protected void initializeOp(Configuration hconf) throws HiveException {
     ObjectInspector[] inputOIs = new ObjectInspector[conf.getTagLength()];
     inputOIs[tag] = inputObjInspectors[0];
     conf.setTagOrder(new Byte[]{ tag });
+    int dfsMaxReplication = hconf.getInt(DFS_REPLICATION_MAX, minReplication);
+    // minReplication value should not cross the value of dfs.replication.max
+    minReplication = Math.min(minReplication, dfsMaxReplication);
     htsOperator.setConf(conf);
     htsOperator.initialize(hconf, inputOIs);
   }
@@ -141,7 +146,7 @@ protected void flushToFile(MapJoinPersistableTableContainer tableContainer,
     }
     // TODO find out numOfPartitions for the big table
     int numOfPartitions = replication;
-    replication = (short) Math.max(MIN_REPLICATION, numOfPartitions);
+    replication = (short) Math.max(minReplication, numOfPartitions);
     htsOperator.console.printInfo(Utilities.now() + "\tDump the side-table for tag: " + tag
       + " with group count: " + tableContainer.size() + " into file: " + path);
     // get the hashtable file and path
-- 
1.7.9.5

