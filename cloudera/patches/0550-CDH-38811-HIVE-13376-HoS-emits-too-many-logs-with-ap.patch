From a8dbdcdd98af5dcf1fcd98376ee24aef9ea51f43 Mon Sep 17 00:00:00 2001
From: Szehon Ho <szehon@cloudera.com>
Date: Fri, 1 Apr 2016 11:47:52 -0700
Subject: [PATCH 0550/1164] CDH-38811 : HIVE-13376 : HoS emits too many logs
 with application state (Szehon, via Rui Li and
 Xuefu)

Change-Id: I7c3d0b159973b07c2669eb7c6f649de04db325fb
---
 .../hive/ql/exec/spark/HiveSparkClientFactory.java |    9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
index 99f06e7..216f2ae 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java
@@ -51,6 +51,7 @@
   private static final String SPARK_DEFAULT_APP_NAME = "Hive on Spark";
   private static final String SPARK_DEFAULT_SERIALIZER = "org.apache.spark.serializer.KryoSerializer";
   private static final String SPARK_DEFAULT_REFERENCE_TRACKING = "false";
+  private static final String SPARK_YARN_REPORT_INTERVAL = "spark.yarn.report.interval";
 
   public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Exception {
     Map<String, String> sparkConf = initiateSparkConf(hiveconf);
@@ -185,6 +186,14 @@ public static HiveSparkClient createHiveSparkClient(HiveConf hiveconf) throws Ex
       }
     }
 
+    //The application reports tend to spam the hive logs.  This is controlled by spark, and the default seems to be 1s.
+    //If it is not specified, set it to a much higher number.  It can always be overriden by user.
+    String sparkYarnReportInterval = sparkConf.get(SPARK_YARN_REPORT_INTERVAL);
+    if (sparkMaster.startsWith("yarn") && sparkYarnReportInterval == null) {
+      //the new version of spark also takes time-units, but old versions do not.
+      sparkConf.put(SPARK_YARN_REPORT_INTERVAL, "60000");
+    }
+
     return sparkConf;
   }
 
-- 
1.7.9.5

