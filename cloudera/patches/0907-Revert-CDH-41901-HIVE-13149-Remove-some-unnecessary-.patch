From 0a055f4dc064872bab04a9c1a0dac60b95943790 Mon Sep 17 00:00:00 2001
From: Aihua Xu <axu@cloudera.com>
Date: Sat, 14 Jan 2017 08:54:27 -0700
Subject: [PATCH 0907/1164] Revert "CDH-41901: HIVE-13149: Remove some
 unnecessary HMS connections from HS2 (Reviewed by
 Jimmy Xiang, Szehon Ho, Chaoyu Tang)"

This reverts commit 0586562f4048f917fde6ace996a4d1d0654f379c.

Change-Id: Id0dda17254741548afa1a0651cdc69c532c0f55f
---
 .../hive/metastore/TestMetastoreVersion.java       |    7 +++--
 .../org/apache/hive/jdbc/TestJdbcWithMiniHS2.java  |   27 +++++---------------
 .../apache/hadoop/hive/hbase/HBaseQTestUtil.java   |    7 -----
 .../apache/hadoop/hive/hbase/HBaseTestSetup.java   |    3 +++
 .../java/org/apache/hadoop/hive/ql/QTestUtil.java  |   24 +++++++----------
 .../hadoop/hive/metastore/HiveMetaStoreClient.java |    8 +++---
 .../hadoop/hive/ql/session/SessionState.java       |    6 +++--
 7 files changed, 28 insertions(+), 54 deletions(-)

diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java
index ecae3ff..5514228 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.lang.reflect.Field;
+import java.util.Random;
 
 import junit.framework.TestCase;
 
@@ -31,7 +32,6 @@
 import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.ObjectStore;
 import org.apache.hadoop.hive.ql.Driver;
-import org.apache.hadoop.hive.ql.metadata.Hive;
 import org.apache.hadoop.hive.ql.processors.CommandProcessorResponse;
 import org.apache.hadoop.hive.ql.session.SessionState;
 
@@ -99,9 +99,8 @@ public void testVersionRestriction () throws Exception {
     // session creation should fail since the schema didn't get created
     try {
       SessionState.start(new CliSessionState(hiveConf));
-      Hive.get(hiveConf).getMSC();
-      fail("An exception is expected since schema is not created.");
-    } catch (Exception re) {
+      fail("Expected exception");
+    } catch (RuntimeException re) {
       LOG.info("Exception in testVersionRestriction: " + re, re);
       String msg = HiveStringUtils.stringifyException(re);
       assertTrue("Expected 'Version information not found in metastore' in: " + msg, msg
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
index 9363ec4..9aa453c 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
@@ -82,8 +82,9 @@ public static void beforeTest() throws Exception {
     miniHS2.start(confOverlay);
   }
 
-  private Connection getConnection() throws Exception {
-    return getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
+  @Before
+  public void setUp() throws Exception {
+    hs2Conn = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
   }
 
   private Connection getConnection(String jdbcURL, String user, String pwd) throws SQLException {
@@ -94,9 +95,7 @@ private Connection getConnection(String jdbcURL, String user, String pwd) throws
 
   @After
   public void tearDown() throws Exception {
-    if (hs2Conn != null) {
-      hs2Conn.close();
-    }
+    hs2Conn.close();
   }
 
   @AfterClass
@@ -109,7 +108,6 @@ public static void afterTest() throws Exception {
   @Test
   public void testConnection() throws Exception {
     String tableName = "testTab1";
-    hs2Conn = getConnection();
     Statement stmt = hs2Conn.createStatement();
 
     // create table
@@ -131,7 +129,6 @@ public void testConnection() throws Exception {
   @Test
   public void testConcurrentStatements() throws Exception {
     String tableName = "testConcurrentStatements";
-    hs2Conn = getConnection();
     Statement stmt = hs2Conn.createStatement();
 
     // create table
@@ -310,7 +307,6 @@ public void testURIDatabaseName() throws Exception{
     stmt.execute(" drop table if exists table_in_non_default_schema");
     expected = stmt.execute("DROP DATABASE "+ dbName);
     stmt.close();
-    hs2Conn.close();
 
     hs2Conn  = getConnection(jdbcUri+"default",System.getProperty("user.name"),"bar");
     stmt = hs2Conn .createStatement();
@@ -344,7 +340,6 @@ public void testConnectionSchemaAPIs() throws Exception {
      * get/set Schema are new in JDK7 and not available in java.sql.Connection in JDK6.
      * Hence the test uses HiveConnection object to call these methods so that test will run with older JDKs
      */
-    hs2Conn = getConnection();
     HiveConnection hiveConn = (HiveConnection)hs2Conn;
 
     assertEquals("default", hiveConn.getSchema());
@@ -378,7 +373,6 @@ public void testConnectionSchemaAPIs() throws Exception {
    */
   private void verifyCurrentDB(String expectedDbName, Connection hs2Conn) throws Exception {
     String verifyTab = "miniHS2DbVerificationTable";
-    hs2Conn = getConnection();
     Statement stmt = hs2Conn.createStatement();
     stmt.execute("DROP TABLE IF EXISTS " + expectedDbName + "." + verifyTab);
     stmt.execute("CREATE TABLE " + expectedDbName + "." + verifyTab + "(id INT)");
@@ -478,7 +472,6 @@ public void testSessionScratchDirs() throws Exception {
     // Downloaded resources dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.DOWNLOADED_RESOURCES_DIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
-    hs2Conn.close();
 
     // 2. Test with doAs=true
     // Restart HiveServer2 with doAs=true
@@ -505,7 +498,6 @@ public void testSessionScratchDirs() throws Exception {
     // Downloaded resources dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.DOWNLOADED_RESOURCES_DIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, true);
-    hs2Conn.close();
 
     // Test for user "trinity"
     userName = "trinity";
@@ -537,7 +529,6 @@ public void testUdfWhiteList() throws Exception {
     HiveConf testConf = new HiveConf();
     assertTrue(testConf.getVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_WHITELIST).isEmpty());
     // verify that udf in default whitelist can be executed
-    hs2Conn = getConnection();
     Statement stmt = hs2Conn.createStatement();
     stmt.executeQuery("SELECT substr('foobar', 4) ");
     hs2Conn.close();
@@ -579,11 +570,10 @@ public void testUdfWhiteList() throws Exception {
   public void testUdfBlackList() throws Exception {
     HiveConf testConf = new HiveConf();
     assertTrue(testConf.getVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_BLACKLIST).isEmpty());
-    hs2Conn = getConnection();
+
     Statement stmt = hs2Conn.createStatement();
     // verify that udf in default whitelist can be executed
     stmt.executeQuery("SELECT substr('foobar', 4) ");
-    hs2Conn.close();
 
     miniHS2.stop();
     testConf.setVar(ConfVars.HIVE_SERVER2_BUILTIN_UDF_BLACKLIST, "reflect");
@@ -605,9 +595,6 @@ public void testUdfBlackList() throws Exception {
    */
   @Test
   public void testUdfBlackListOverride() throws Exception {
-    if (miniHS2.isStarted()) {
-      miniHS2.stop();
-    }
     // setup whitelist
     HiveConf testConf = new HiveConf();
 
@@ -662,8 +649,6 @@ public void testRootScratchDir() throws Exception {
     // HDFS scratch dir
     scratchDirPath = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR));
     verifyScratchDir(conf, fs, scratchDirPath, expectedFSPermission, userName, false);
-    hs2Conn.close();
-
     // Test with multi-level scratch dir path
     // Stop HiveServer2
     if (miniHS2.isStarted()) {
@@ -744,4 +729,4 @@ private int getReflectionUtilsCacheSize() {
     }
     return -1;
   }
-}
+}
\ No newline at end of file
diff --git a/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java b/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java
index 2740f94..9c20f90 100644
--- a/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java
+++ b/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java
@@ -39,15 +39,12 @@
   /** A handle to this harness's cluster */
   private final HConnection conn;
 
-  private HBaseTestSetup hbaseSetup = null;
-
   public HBaseQTestUtil(
     String outDir, String logDir, MiniClusterType miniMr, HBaseTestSetup setup,
     String initScript, String cleanupScript)
     throws Exception {
 
     super(outDir, logDir, miniMr, null, initScript, cleanupScript);
-    hbaseSetup = setup;
     setup.preTest(conf);
     this.conn = setup.getConnection();
     super.init();
@@ -72,10 +69,6 @@ public void init() throws Exception {
   }
 
   @Override
-  protected void initConfFromSetup() throws Exception {
-    super.initConfFromSetup();
-    hbaseSetup.preTest(conf);
-  }
   public void createSources() throws Exception {
     super.createSources();
 
diff --git a/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java b/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java
index 4f8fa05..42f85c8 100644
--- a/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java
+++ b/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java
@@ -22,6 +22,9 @@
 import java.net.ServerSocket;
 import java.util.Arrays;
 
+import junit.extensions.TestSetup;
+import junit.framework.Test;
+
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseConfiguration;
diff --git a/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java b/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
index c40663b..781eef8 100644
--- a/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
+++ b/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
@@ -464,7 +464,6 @@ public void shutdown() throws Exception {
       dfs.shutdown();
       dfs = null;
     }
-    Hive.closeCurrent();
   }
 
   public String readEntireFileIntoString(File queryFile) throws IOException {
@@ -689,9 +688,6 @@ public void clearTablesCreatedDuringTests() throws Exception {
       return;
     }
 
-    conf.set("hive.metastore.filter.hook",
-        "org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl");
-    db = Hive.get(conf);
     // Delete any tables other than the source tables
     // and any databases other than the default database.
     for (String dbName : db.getAllDatabases()) {
@@ -753,20 +749,18 @@ public void clearTestSideEffects() throws Exception {
       return;
     }
 
-    // allocate and initialize a new conf since a test can
-    // modify conf by using 'set' commands
-    conf = new HiveConf(Driver.class);
-    initConf();
-    initConfFromSetup();
-
-    // renew the metastore since the cluster type is unencrypted
-    db = Hive.get(conf);  // propagate new conf to meta store
-
     clearTablesCreatedDuringTests();
     clearKeysCreatedInTests();
-  }
 
-  protected void initConfFromSetup() throws Exception {
+    if (clusterType != MiniClusterType.encrypted) {
+      // allocate and initialize a new conf since a test can
+      // modify conf by using 'set' commands
+      conf = new HiveConf (Driver.class);
+      initConf();
+      // renew the metastore since the cluster type is unencrypted
+      db = Hive.get(conf);  // propagate new conf to meta store
+    }
+
     setup.preTest(conf);
   }
 
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
index b3ceb86..f2c00e8 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
@@ -167,7 +167,7 @@
   private boolean isConnected = false;
   private URI metastoreUris[];
   private final HiveMetaHookLoader hookLoader;
-  protected final HiveConf conf;  // Keep a copy of HiveConf so if Session conf changes, we may need to get a new HMS client.
+  protected final HiveConf conf;
   private String tokenStrForm;
   private final boolean localMetaStore;
   private final MetaStoreFilterHook filterHook;
@@ -193,10 +193,8 @@ public HiveMetaStoreClient(HiveConf conf, HiveMetaHookLoader hookLoader)
     this.hookLoader = hookLoader;
     if (conf == null) {
       conf = new HiveConf(HiveMetaStoreClient.class);
-      this.conf = conf;
-    } else {
-      this.conf = new HiveConf(conf);
     }
+    this.conf = conf;
     filterHook = loadFilterHooks();
 
     String msUri = conf.getVar(HiveConf.ConfVars.METASTOREURIS);
@@ -204,7 +202,7 @@ public HiveMetaStoreClient(HiveConf conf, HiveMetaHookLoader hookLoader)
     if (localMetaStore) {
       // instantiate the metastore server handler directly instead of connecting
       // through the network
-      client = HiveMetaStore.newRetryingHMSHandler("hive client", this.conf, true);
+      client = HiveMetaStore.newRetryingHMSHandler("hive client", conf, true);
       isConnected = true;
       snapshotActiveConf();
       return;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
index bfa0359..56afa6a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
@@ -523,6 +523,10 @@ public static SessionState start(SessionState startSs) {
     // Get the following out of the way when you start the session these take a
     // while and should be done when we start up.
     try {
+      // Hive object instance should be created with a copy of the conf object. If the conf is
+      // shared with SessionState, other parts of the code might update the config, but
+      // Hive.get(HiveConf) would not recognize the case when it needs refreshing
+      Hive.get(new HiveConf(startSs.conf)).getMSC();
       UserGroupInformation sessionUGI = Utils.getUGI();
       FileSystem.get(startSs.conf);
 
@@ -546,8 +550,6 @@ public static SessionState start(SessionState startSs) {
           throw new RuntimeException(e);
         }
       }
-    } catch (RuntimeException e) {
-      throw e;
     } catch (Exception e) {
       // Catch-all due to some exec time dependencies on session state
       // that would cause ClassNoFoundException otherwise
-- 
1.7.9.5

